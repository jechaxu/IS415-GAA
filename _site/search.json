[
  {
    "objectID": "Take-home_Ex/3/Take-home_Ex03.html",
    "href": "Take-home_Ex/3/Take-home_Ex03.html",
    "title": "take home exercise 3",
    "section": "",
    "text": "This study investigates the spatial distribution and evolution of crime in Malaysia over recent years. By employing advanced spatial analysis techniques, we aim to identify hotspots, coldspots, and emerging trends in crime patterns. Our analysis utilizes a comprehensive dataset of crime incidents, including location, type, and date of occurrence.\nThe exercise will focus only on one page consisting of all portions that I am responsible for. This includes:\n\nGlobal Spatial Autocorrelation (Moran’s I)\nLocal Spatial Autocorrelation (Local Moran’s I - LISA Map)"
  },
  {
    "objectID": "Take-home_Ex/3/Take-home_Ex03.html#datasets-being-used",
    "href": "Take-home_Ex/3/Take-home_Ex03.html#datasets-being-used",
    "title": "take home exercise 3",
    "section": "3.1 Datasets being used",
    "text": "3.1 Datasets being used\nThere are three datasets being used in this exercise.\n\nMalaysia – Crime by District and Crime Type from data.gov.my in csv format.\nMalaysia - Population Table: Administrative Districts from data.gov.my in csv format.\nMalaysia - Subnational Administrative Boundaries with included administrative regions in shapefile format.\n\n\ncrime_df &lt;- read_csv(\"data/aspatial/crime_district.csv\")\n\nRows: 19152 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): state, district, category, type\ndbl  (1): crimes\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npopulation_df &lt;- read_csv(\"data/aspatial/population_district.csv\")\n\nRows: 319200 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (5): state, district, sex, age, ethnicity\ndbl  (1): population\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNext, we import the administrative regions of Malaysia.\n\nmys_sf &lt;- read_sf(dsn = \"data/geospatial/mys_adm_unhcr_20210211_shp\", \n                 layer = \"mys_admbnda_adm2_unhcr_20210211\") %&gt;%\n          st_transform(crs = 3168)"
  },
  {
    "objectID": "Take-home_Ex/3/Take-home_Ex03.html#wrangling",
    "href": "Take-home_Ex/3/Take-home_Ex03.html#wrangling",
    "title": "take home exercise 3",
    "section": "3.2 Wrangling",
    "text": "3.2 Wrangling\n\n3.2.1 Data Preparation\nWe first identify the states in each dataset to pick out any inconsistencies to resolve.\n\nprint(\"Unique states in crime_df:\")\n\n[1] \"Unique states in crime_df:\"\n\nunique(crime_df$state)\n\n [1] \"Malaysia\"          \"Johor\"             \"Kedah\"            \n [4] \"Kelantan\"          \"Melaka\"            \"Negeri Sembilan\"  \n [7] \"Pahang\"            \"Perak\"             \"Perlis\"           \n[10] \"Pulau Pinang\"      \"Sabah\"             \"Sarawak\"          \n[13] \"Selangor\"          \"Terengganu\"        \"W.P. Kuala Lumpur\"\n\nprint(\"Unique states in population_df:\")\n\n[1] \"Unique states in population_df:\"\n\nunique(crime_df$state)\n\n [1] \"Malaysia\"          \"Johor\"             \"Kedah\"            \n [4] \"Kelantan\"          \"Melaka\"            \"Negeri Sembilan\"  \n [7] \"Pahang\"            \"Perak\"             \"Perlis\"           \n[10] \"Pulau Pinang\"      \"Sabah\"             \"Sarawak\"          \n[13] \"Selangor\"          \"Terengganu\"        \"W.P. Kuala Lumpur\"\n\nprint(\"Unique states in mys_sf:\")\n\n[1] \"Unique states in mys_sf:\"\n\nunique(mys_sf$ADM1_EN)\n\n [1] \"Johor\"             \"Kedah\"             \"Kelantan\"         \n [4] \"W.P. Kuala Lumpur\" \"W.P. Labuan\"       \"Melaka\"           \n [7] \"Negeri Sembilan\"   \"Pahang\"            \"Perak\"            \n[10] \"Perlis\"            \"Pulau Pinang\"      \"Sabah\"            \n[13] \"Sarawak\"           \"Terengganu\"        \"W.P. Putrajaya\"   \n[16] \"Selangor\"         \n\n\nWe then convert the state and district columns to upper case for matching.\n\ncrime_df &lt;- crime_df %&gt;%\n              mutate(year = year(date),\n                     state = toupper(state),\n                     district = toupper(district))\ncrime_df\n\n# A tibble: 19,152 × 7\n   state    district category type           date       crimes  year\n   &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;          &lt;date&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 MALAYSIA ALL      assault  all            2016-01-01  22327  2016\n 2 MALAYSIA ALL      assault  all            2017-01-01  21366  2017\n 3 MALAYSIA ALL      assault  all            2018-01-01  16902  2018\n 4 MALAYSIA ALL      assault  all            2019-01-01  16489  2019\n 5 MALAYSIA ALL      assault  all            2020-01-01  13279  2020\n 6 MALAYSIA ALL      assault  all            2021-01-01  11495  2021\n 7 MALAYSIA ALL      assault  all            2022-01-01  10348  2022\n 8 MALAYSIA ALL      assault  all            2023-01-01  10453  2023\n 9 MALAYSIA ALL      assault  causing_injury 2016-01-01   5531  2016\n10 MALAYSIA ALL      assault  causing_injury 2017-01-01   5024  2017\n# ℹ 19,142 more rows\n\n\n\npopulation_df &lt;- population_df %&gt;%\n              mutate(year = year(date),\n                     state = toupper(state),\n                     district = toupper(district))\npopulation_df\n\n# A tibble: 319,200 × 8\n   state district   date       sex   age     ethnicity        population  year\n   &lt;chr&gt; &lt;chr&gt;      &lt;date&gt;     &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;                 &lt;dbl&gt; &lt;dbl&gt;\n 1 JOHOR BATU PAHAT 2020-01-01 both  overall overall               495.   2020\n 2 JOHOR BATU PAHAT 2020-01-01 both  overall bumi_malay            311.   2020\n 3 JOHOR BATU PAHAT 2020-01-01 both  overall bumi_other              5.1  2020\n 4 JOHOR BATU PAHAT 2020-01-01 both  overall chinese               140.   2020\n 5 JOHOR BATU PAHAT 2020-01-01 both  overall indian                  6.9  2020\n 6 JOHOR BATU PAHAT 2020-01-01 both  overall other_citizen           1.8  2020\n 7 JOHOR BATU PAHAT 2020-01-01 both  overall other_noncitizen       30.2  2020\n 8 JOHOR BATU PAHAT 2020-01-01 both  0-4     overall                30.3  2020\n 9 JOHOR BATU PAHAT 2020-01-01 both  0-4     bumi_malay             21.3  2020\n10 JOHOR BATU PAHAT 2020-01-01 both  0-4     bumi_other              0.5  2020\n# ℹ 319,190 more rows\n\n\n\nmys_sf &lt;- mys_sf %&gt;%\n          mutate(ADM1_EN = toupper(ADM1_EN),\n                 ADM2_EN = toupper(ADM2_EN))\n\nmys_sf\n\nSimple feature collection with 144 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 184853.1 ymin: 94420.8 xmax: 2380932 ymax: 829136\nProjected CRS: Kertau (RSO) / RSO Malaya (m)\n# A tibble: 144 × 15\n   ADM2_EN  ADM2_PCODE ADM2_REF ADM2ALT1EN ADM2ALT2EN ADM1_EN ADM1_PCODE ADM0_EN\n * &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;  \n 1 BATU PA… MY0101     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 2 JOHOR B… MY0102     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 3 KLUANG   MY0103     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 4 KOTA TI… MY0104     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 5 KULAIJA… MY0105     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 6 LEDANG   MY0106     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 7 MERSING  MY0107     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 8 MUAR     MY0108     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 9 PONTIAN  MY0109     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n10 SEGAMAT  MY0110     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n# ℹ 134 more rows\n# ℹ 7 more variables: ADM0_PCODE &lt;chr&gt;, date &lt;date&gt;, validOn &lt;date&gt;,\n#   validTo &lt;date&gt;, Shape_Leng &lt;dbl&gt;, Shape_Area &lt;dbl&gt;,\n#   geometry &lt;MULTIPOLYGON [m]&gt;\n\n\n\n\n3.2.2 Checking for Mismatch (State)\n\n# Assuming you have two character vectors:\nstate_crime &lt;- unique(crime_df$state)\nstate_sf &lt;- unique(mys_sf$ADM1_EN)\n\n# Find states in crime_df that are not in mys_sf\nmissing_in_sf &lt;- setdiff(state_crime, state_sf)\n\n# Find states in mys_sf that are not in crime_df\nmissing_in_crime &lt;- setdiff(state_sf, state_crime)\n\n# Print the mismatches\nprint(\"States in crime_df not found in mys_sf:\")\n\n[1] \"States in crime_df not found in mys_sf:\"\n\nprint(missing_in_sf)\n\n[1] \"MALAYSIA\"\n\nprint(\"States in mys_sf not found in crime_df:\")\n\n[1] \"States in mys_sf not found in crime_df:\"\n\nprint(missing_in_crime)\n\n[1] \"W.P. LABUAN\"    \"W.P. PUTRAJAYA\"\n\n\n\n\n3.2.3 Cleaning (State)\nIn this case study, for ease of analysis, we choose to focus on West Malaysia, and thus will be filtering out Sarawak, Sabah and Labuan, which are not the focus of our current analysis.\n\nmys_sf &lt;- mys_sf %&gt;%\n          filter(ADM1_EN != 'W.P. LABUAN' & ADM1_EN != 'SABAH' & ADM1_EN != 'SARAWAK') %&gt;%\n          mutate(ADM1_EN = replace(ADM1_EN, ADM1_EN == 'W.P. KUALA LUMPUR', 'KUALA LUMPUR'),\n                 ADM1_EN = replace(ADM1_EN, ADM1_EN == 'W.P. PUTRAJAYA', 'KUALA LUMPUR'))\n\nmys_sf\n\nSimple feature collection with 87 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 184853.1 ymin: 139843.3 xmax: 728635.8 ymax: 744607.2\nProjected CRS: Kertau (RSO) / RSO Malaya (m)\n# A tibble: 87 × 15\n   ADM2_EN  ADM2_PCODE ADM2_REF ADM2ALT1EN ADM2ALT2EN ADM1_EN ADM1_PCODE ADM0_EN\n * &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;  \n 1 BATU PA… MY0101     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 2 JOHOR B… MY0102     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 3 KLUANG   MY0103     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 4 KOTA TI… MY0104     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 5 KULAIJA… MY0105     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 6 LEDANG   MY0106     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 7 MERSING  MY0107     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 8 MUAR     MY0108     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 9 PONTIAN  MY0109     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n10 SEGAMAT  MY0110     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n# ℹ 77 more rows\n# ℹ 7 more variables: ADM0_PCODE &lt;chr&gt;, date &lt;date&gt;, validOn &lt;date&gt;,\n#   validTo &lt;date&gt;, Shape_Leng &lt;dbl&gt;, Shape_Area &lt;dbl&gt;,\n#   geometry &lt;MULTIPOLYGON [m]&gt;\n\n\n\ncrime_df &lt;- crime_df %&gt;%\n              filter(state != 'MALAYSIA' & state != 'SABAH' & state != 'SARAWAK' & \n                     district != 'ALL' & type != 'all') %&gt;%\n              mutate(state = replace(state, state == 'W.P. KUALA LUMPUR', 'KUALA LUMPUR'))\ncrime_df\n\n# A tibble: 10,368 × 7\n   state district   category type           date       crimes  year\n   &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;          &lt;date&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 JOHOR BATU PAHAT assault  causing_injury 2016-01-01     39  2016\n 2 JOHOR BATU PAHAT assault  causing_injury 2017-01-01     41  2017\n 3 JOHOR BATU PAHAT assault  causing_injury 2018-01-01     28  2018\n 4 JOHOR BATU PAHAT assault  causing_injury 2019-01-01     41  2019\n 5 JOHOR BATU PAHAT assault  causing_injury 2020-01-01     43  2020\n 6 JOHOR BATU PAHAT assault  causing_injury 2021-01-01     22  2021\n 7 JOHOR BATU PAHAT assault  causing_injury 2022-01-01     19  2022\n 8 JOHOR BATU PAHAT assault  causing_injury 2023-01-01     22  2023\n 9 JOHOR BATU PAHAT assault  murder         2016-01-01      6  2016\n10 JOHOR BATU PAHAT assault  murder         2017-01-01      0  2017\n# ℹ 10,358 more rows\n\n\n\npopulation_df &lt;- population_df %&gt;%\n          filter(state != 'SABAH' & state != 'SARAWAK' & state != 'W.P. LABUAN' &\n                 sex == \"both\" & age == \"overall\" & ethnicity == \"overall\" ) %&gt;%\n          mutate(state = replace(state, state == 'W.P. KUALA LUMPUR', 'KUALA LUMPUR'),\n                 state = replace(state, state == 'W.P. PUTRAJAYA', 'KUALA LUMPUR')) %&gt;%\n          dplyr::select(state, district, year, population)\npopulation_df\n\n# A tibble: 276 × 4\n   state district     year population\n   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n 1 JOHOR BATU PAHAT   2020      495. \n 2 JOHOR JOHOR BAHRU  2020     1711. \n 3 JOHOR KLUANG       2020      324. \n 4 JOHOR KOTA TINGGI  2020      222. \n 5 JOHOR KULAI        2020      330. \n 6 JOHOR MERSING      2020       78.2\n 7 JOHOR MUAR         2020      315. \n 8 JOHOR PONTIAN      2020      173. \n 9 JOHOR SEGAMAT      2020      198. \n10 JOHOR TANGKAK      2020      163. \n# ℹ 266 more rows\n\n\n\n\n3.2.4 Crime (State-District)\n\n3.2.4.1 Checking for Mismatch in crime_df and mys_sf\n\ncrime_df &lt;- crime_df %&gt;% mutate(state_district = paste(state, district, sep = \"-\"))\nmys_sf &lt;- mys_sf %&gt;% mutate(state_district = paste(ADM1_EN, ADM2_EN, sep = \"-\"))\n\n\n# Assuming you have two character vectors:\nstate_district_crime &lt;- unique(crime_df$state_district)\nstate_district_sf &lt;- unique(mys_sf$state_district)\n\n# Find mismatches\nmissing_in_sf &lt;- setdiff(state_district_crime, state_district_sf)\nmissing_in_crime &lt;- setdiff(state_district_sf, state_district_crime)\n\n# Print the mismatches\nprint(\"State-District combinations in crime_df not found in mys_sf:\")\n\n[1] \"State-District combinations in crime_df not found in mys_sf:\"\n\nprint(missing_in_sf)\n\n [1] \"JOHOR-ISKANDAR PUTERI\"               \"JOHOR-JOHOR BAHRU SELATAN\"          \n [3] \"JOHOR-JOHOR BAHRU UTARA\"             \"JOHOR-NUSAJAYA\"                     \n [5] \"JOHOR-SERI ALAM\"                     \"KEDAH-BANDAR BHARU\"                 \n [7] \"NEGERI SEMBILAN-NILAI\"               \"PAHANG-CAMERON HIGHLAND\"            \n [9] \"PAHANG-KUALA LIPIS\"                  \"PERAK-BATU GAJAH\"                   \n[11] \"PERAK-GERIK\"                         \"PERAK-IPOH\"                         \n[13] \"PERAK-MANJUNG\"                       \"PERAK-PENGKALAN HULU\"               \n[15] \"PERAK-SELAMA\"                        \"PERAK-SUNGAI SIPUT\"                 \n[17] \"PERAK-TAIPING\"                       \"PERAK-TANJONG MALIM\"                \n[19] \"PERAK-TAPAH\"                         \"PERLIS-ARAU\"                        \n[21] \"PERLIS-KANGAR\"                       \"PERLIS-PADANG BESAR\"                \n[23] \"PULAU PINANG-SEBERANG PERAI SELATAN\" \"PULAU PINANG-SEBERANG PERAI TENGAH\" \n[25] \"PULAU PINANG-SEBERANG PERAI UTARA\"   \"SELANGOR-AMPANG JAYA\"               \n[27] \"SELANGOR-HULU SELANGOR\"              \"SELANGOR-KAJANG\"                    \n[29] \"SELANGOR-KLANG SELATAN\"              \"SELANGOR-KLANG UTARA\"               \n[31] \"SELANGOR-PETALING JAYA\"              \"SELANGOR-SERDANG\"                   \n[33] \"SELANGOR-SG. BULOH\"                  \"SELANGOR-SHAH ALAM\"                 \n[35] \"SELANGOR-SUBANG JAYA\"                \"SELANGOR-SUNGAI BULOH\"              \n[37] \"KUALA LUMPUR-BRICKFIELDS\"            \"KUALA LUMPUR-CHERAS\"                \n[39] \"KUALA LUMPUR-DANG WANGI\"             \"KUALA LUMPUR-SENTUL\"                \n[41] \"KUALA LUMPUR-WANGSA MAJU\"           \n\nprint(\"State-District combinations in mys_sf not found in crime_df:\")\n\n[1] \"State-District combinations in mys_sf not found in crime_df:\"\n\nprint(missing_in_crime)\n\n [1] \"JOHOR-JOHOR BAHRU\"             \"KEDAH-POKOK SENA\"             \n [3] \"KUALA LUMPUR-WP. KUALA LUMPUR\" \"PAHANG-LIPIS\"                 \n [5] \"PERAK-BATANG PADANG\"           \"PERAK-ULU PERAK\"              \n [7] \"PERAK-KINTA\"                   \"PERAK-LARUT DAN MATANG\"       \n [9] \"PERAK-MANJUNG (DINDING)\"       \"PERLIS-PERLIS\"                \n[11] \"PULAU PINANG-S.P.SELATAN\"      \"PULAU PINANG-S.P. TENGAH\"     \n[13] \"PULAU PINANG-S.P. UTARA\"       \"SELANGOR-ULU LANGAT\"          \n[15] \"SELANGOR-ULU SELANGOR\"         \"SELANGOR-KLANG\"               \n[17] \"SELANGOR-PETALING\"            \n\n\n\n\n3.2.4.2 Cleaning\n\ncrime_df &lt;- crime_df %&gt;%\n  mutate(district = case_when(\n    state == \"JOHOR\" & district %in% c(\"ISKANDAR PUTERI\", \"NUSAJAYA\", \"JOHOR BAHRU SELATAN\", \"JOHOR BAHRU UTARA\", \"SERI ALAM\") ~ \"JOHOR BAHRU\",\n    state == \"NEGERI SEMBILAN\" & district == \"NILAI\" ~ \"SEREMBAN\",\n    state == \"KEDAH\" & district == \"BANDAR BHARU\" ~ \"BANDAR BAHARU\",\n    state == \"PAHANG\" & district == \"CAMERON HIGHLAND\" ~ \"CAMERON HIGHLANDS\",\n    state == \"PAHANG\" & district == \"KUALA LIPIS\" ~ \"LIPIS\",\n    state == \"PERAK\" & district  %in% c(\"BATU GAJAH\", \"IPOH\") ~ \"KINTA\",\n    state == \"PERAK\" & district == \"GERIK\" ~ \"ULU PERAK\",\n    state == \"PERAK\" & district == \"MANJUNG\" ~ \"MANJUNG (DINDING)\",\n    state == \"PERAK\" & district == \"PENGKALAN HULU\" ~ \"ULU PERAK\",\n    state == \"PERAK\" & district %in% c(\"SELAMA\", \"TAIPING\") ~ \"LARUT DAN MATANG\",\n    state == \"PERAK\" & district == \"SUNGAI SIPUT\" ~ \"KUALA KANGSAR\",\n    state == \"PERAK\" & district %in% c(\"TANJONG MALIM\", \"TAPAH\") ~ \"BATANG PADANG\",\n    state == \"PERLIS\" & district %in% c(\"ARAU\", \"KANGAR\", \"PADANG BESAR\") ~ \"PERLIS\",\n    state == \"PULAU PINANG\" & district == \"SEBERANG PERAI SELATAN\" ~ \"S.P.SELATAN\",\n    state == \"PULAU PINANG\" & district == \"SEBERANG PERAI TENGAH\" ~ \"S.P. TENGAH\",\n    state == \"PULAU PINANG\" & district == \"SEBERANG PERAI UTARA\" ~ \"S.P. UTARA\",\n    state == \"SELANGOR\" & district == \"AMPANG JAYA\" ~ \"GOMBAK\",\n    state == \"SELANGOR\" & district == \"HULU SELANGOR\" ~ \"ULU SELANGOR\",\n    state == \"SELANGOR\" & district == \"KAJANG\" ~ \"ULU LANGAT\",\n    state == \"SELANGOR\" & district %in% c(\"KLANG SELATAN\", \"KLANG UTARA\") ~ \"KLANG\",\n    state == \"SELANGOR\" & district %in% c(\"PETALING JAYA\", \"SERDANG\", \"SG. BULOH\", \"SHAH ALAM\", \"SUBANG JAYA\", \"SUNGAI BULOH\") ~ \"PETALING\",\n    state == \"KUALA LUMPUR\" & district %in% c(\"BRICKFIELDS\", \"CHERAS\", \"DANG WANGI\", \"SENTUL\", \"WANGSA MAJU\") ~ \"WP. KUALA LUMPUR\",\n    TRUE ~ district\n  )) %&gt;%\n  group_by(state, district, year, category, type) %&gt;%\n  summarise(crimes = sum(crimes))\n\n`summarise()` has grouped output by 'state', 'district', 'year', 'category'.\nYou can override using the `.groups` argument.\n\n\n\ntm_shape(mys_sf) +\n  tm_polygons() +\n  tm_text(\"ADM2_EN\", size = 0.3)\n\n\n\n\n\n\n\n\n\n\n3.2.4.3 Visualizing Crime Distribution\n\ncrime_df_mys &lt;- crime_df %&gt;%\n  filter(year &gt;= 2019 & year &lt;= 2022) %&gt;%\n  left_join(mys_sf, by = c(\"state\" = \"ADM1_EN\", \"district\" = \"ADM2_EN\")) %&gt;%\n  dplyr::select(state, district, year, category, type, crimes, Shape_Leng, Shape_Area, geometry)\n\ncrime_df_mys &lt;- st_as_sf(crime_df_mys)\ncrime_df_mys\n\nSimple feature collection with 4128 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 184853.1 ymin: 139843.3 xmax: 728635.8 ymax: 744607.2\nProjected CRS: Kertau (RSO) / RSO Malaya (m)\n# A tibble: 4,128 × 9\n# Groups:   state, district, year, category [688]\n   state district    year category type             crimes Shape_Leng Shape_Area\n   &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;             &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 JOHOR BATU PAHAT  2019 assault  causing_injury       41       1.86      0.161\n 2 JOHOR BATU PAHAT  2019 assault  murder                3       1.86      0.161\n 3 JOHOR BATU PAHAT  2019 assault  rape                 29       1.86      0.161\n 4 JOHOR BATU PAHAT  2019 assault  robbery_gang_ar…      0       1.86      0.161\n 5 JOHOR BATU PAHAT  2019 assault  robbery_gang_un…     37       1.86      0.161\n 6 JOHOR BATU PAHAT  2019 assault  robbery_solo_ar…      0       1.86      0.161\n 7 JOHOR BATU PAHAT  2019 assault  robbery_solo_un…     29       1.86      0.161\n 8 JOHOR BATU PAHAT  2019 property break_in            157       1.86      0.161\n 9 JOHOR BATU PAHAT  2019 property theft_other         127       1.86      0.161\n10 JOHOR BATU PAHAT  2019 property theft_vehicle_l…      4       1.86      0.161\n# ℹ 4,118 more rows\n# ℹ 1 more variable: geometry &lt;MULTIPOLYGON [m]&gt;\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ncrime_df_mys_grp &lt;- crime_df_mys %&gt;%\n  summarize(total_crimes = sum(crimes))\n\n`summarise()` has grouped output by 'state', 'district', 'year'. You can\noverride using the `.groups` argument.\n\nchoro &lt;- tm_shape(crime_df_mys_grp) +\n  tm_fill(\"total_crimes\", \n          style = \"pretty\", \n          palette = \"Blues\",\n          title = \"Crimes\") +\n  tm_layout(main.title = \"Distribution of crime in West Malaysia\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\nchoro\n\n\n\n\n\n\n\n\n\n\n\n3.2.5 Population (State-District)\n\n3.2.5.1 Check for Mismatch\nThe year 2019 is missing from the population data set, hence we make the assumption that the population did not experience any drastic increase or decrease, and will thus map population from year 2020 -&gt; 2019.\n\npopulation_row &lt;- population_df %&gt;%\n  filter(year == 2020) %&gt;%\n  mutate(year = 2019) \npopulation_df &lt;- bind_rows(population_df, population_row) %&gt;% \n  mutate(state_district = paste(state, district, sep = \"-\"))\nunique(population_df$year)\n\n[1] 2020 2021 2022 2019\n\n\n\nstate_district_population &lt;- unique(population_df$state_district)\n\nmissing_in_sf &lt;- setdiff(state_district_population, state_district_sf)\nmissing_in_population &lt;- setdiff(state_district_sf, state_district_population)\n\nprint(\"State-District combinations in population_df not found in mys_sf:\")\n\n[1] \"State-District combinations in population_df not found in mys_sf:\"\n\nprint(missing_in_sf)\n\n [1] \"JOHOR-KULAI\"                         \"JOHOR-TANGKAK\"                      \n [3] \"KELANTAN-KECIL LOJING\"               \"PERAK-BAGAN DATUK\"                  \n [5] \"PERAK-HULU PERAK\"                    \"PERAK-MANJUNG\"                      \n [7] \"PERAK-MUALLIM\"                       \"PERAK-SELAMA\"                       \n [9] \"PULAU PINANG-SEBERANG PERAI SELATAN\" \"PULAU PINANG-SEBERANG PERAI TENGAH\" \n[11] \"PULAU PINANG-SEBERANG PERAI UTARA\"   \"TERENGGANU-KUALA NERUS\"             \n[13] \"KUALA LUMPUR-W.P. KUALA LUMPUR\"      \"PAHANG-CAMERON HIGHLAND\"            \n[15] \"PULAU PINANG-SP SELATAN\"             \"PULAU PINANG-SP TENGAH\"             \n[17] \"PULAU PINANG-SP UTARA\"              \n\nprint(\"State-District combinations in mys_sf not found in population_df:\")\n\n[1] \"State-District combinations in mys_sf not found in population_df:\"\n\nprint(missing_in_population)\n\n[1] \"JOHOR-KULAIJAYA\"               \"JOHOR-LEDANG\"                 \n[3] \"KUALA LUMPUR-WP. KUALA LUMPUR\" \"PERAK-ULU PERAK\"              \n[5] \"PERAK-MANJUNG (DINDING)\"       \"PULAU PINANG-S.P.SELATAN\"     \n[7] \"PULAU PINANG-S.P. TENGAH\"      \"PULAU PINANG-S.P. UTARA\"      \n\n\n\n\n3.2.5.2 Cleaning\n\npopulation_df &lt;- population_df %&gt;%\n  mutate(district = case_when(\n    state == \"JOHOR\" & district == \"KULAI\" ~ \"KULAIJAYA\",\n    state == \"JOHOR\" & district == \"TANGKAK\" ~ \"LEDANG\",\n    state == \"KELANTAN\" & district == \"KECIL LOJING\" ~ \"GUA MUSANG\",\n    state == \"PAHANG\" & district == \"CAMERON HIGHLAND\" ~ \"CAMERON HIGHLANDS\",\n    state == \"PERAK\" & district == \"HULU PERAK\" ~ \"ULU PERAK\",\n    state == \"PERAK\" & district == \"BAGAN DATUK\" ~ \"HILIR PERAK\",\n    state == \"PERAK\" & district == \"MANJUNG\" ~ \"MANJUNG (DINDING)\",\n    state == \"PERAK\" & district == \"MUALLIM\" ~ \"BATANG PADANG\",\n    state == \"PERAK\" & district == \"SELAMA\" ~ \"LARUT DAN MATANG\",\n    state == \"PULAU PINANG\" & district == \"SEBERANG PERAI SELATAN\" ~ \"S.P.SELATAN\",\n    state == \"PULAU PINANG\" & district == \"SEBERANG PERAI TENGAH\" ~ \"S.P. TENGAH\",\n    state == \"PULAU PINANG\" & district == \"SEBERANG PERAI UTARA\" ~ \"S.P. UTARA\",\n    state == \"PULAU PINANG\" & district == \"SP SELATAN\" ~ \"S.P.SELATAN\",\n    state == \"PULAU PINANG\" & district == \"SP TENGAH\" ~ \"S.P. TENGAH\",\n    state == \"PULAU PINANG\" & district == \"SP UTARA\" ~ \"S.P. UTARA\",\n    state == \"KUALA LUMPUR\" & district == \"W.P. KUALA LUMPUR\" ~ \"WP. KUALA LUMPUR\",\n    state == \"TERENGGANU\" & district == \"KUALA NERUS\" ~ \"KUALA TERENGGANU\",\n    TRUE ~ district\n  )) %&gt;%\n  group_by(state, district, year) %&gt;%\n  summarise(population = sum(population))\n\n`summarise()` has grouped output by 'state', 'district'. You can override using\nthe `.groups` argument.\n\npopulation_df\n\n# A tibble: 348 × 4\n# Groups:   state, district [87]\n   state district     year population\n   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n 1 JOHOR BATU PAHAT   2019       495.\n 2 JOHOR BATU PAHAT   2020       495.\n 3 JOHOR BATU PAHAT   2021       497.\n 4 JOHOR BATU PAHAT   2022       498.\n 5 JOHOR JOHOR BAHRU  2019      1711.\n 6 JOHOR JOHOR BAHRU  2020      1711.\n 7 JOHOR JOHOR BAHRU  2021      1715.\n 8 JOHOR JOHOR BAHRU  2022      1724.\n 9 JOHOR KLUANG       2019       324.\n10 JOHOR KLUANG       2020       324.\n# ℹ 338 more rows\n\n\n\npopulation_df_mys &lt;- population_df %&gt;%\n  left_join(mys_sf, by = c(\"state\" = \"ADM1_EN\", \"district\" = \"ADM2_EN\")) %&gt;%\n  dplyr::select(state, district, year, population, geometry)\n\npopulation_df_mys &lt;- st_as_sf(population_df_mys)\npopulation_df_mys\n\nSimple feature collection with 348 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 184853.1 ymin: 139843.3 xmax: 728635.8 ymax: 744607.2\nProjected CRS: Kertau (RSO) / RSO Malaya (m)\n# A tibble: 348 × 5\n# Groups:   state, district [87]\n   state district     year population                                   geometry\n   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;                         &lt;MULTIPOLYGON [m]&gt;\n 1 JOHOR BATU PAHAT   2019       495. (((556714.6 192051.6, 556664.6 192111.5, …\n 2 JOHOR BATU PAHAT   2020       495. (((556714.6 192051.6, 556664.6 192111.5, …\n 3 JOHOR BATU PAHAT   2021       497. (((556714.6 192051.6, 556664.6 192111.5, …\n 4 JOHOR BATU PAHAT   2022       498. (((556714.6 192051.6, 556664.6 192111.5, …\n 5 JOHOR JOHOR BAHRU  2019      1711. (((664760.7 157664.3, 664668.2 157664.3, …\n 6 JOHOR JOHOR BAHRU  2020      1711. (((664760.7 157664.3, 664668.2 157664.3, …\n 7 JOHOR JOHOR BAHRU  2021      1715. (((664760.7 157664.3, 664668.2 157664.3, …\n 8 JOHOR JOHOR BAHRU  2022      1724. (((664760.7 157664.3, 664668.2 157664.3, …\n 9 JOHOR KLUANG       2019       324. (((583499.3 195230.8, 581600.3 195991.2, …\n10 JOHOR KLUANG       2020       324. (((583499.3 195230.8, 581600.3 195991.2, …\n# ℹ 338 more rows\n\n\n\n\n\n3.2.6 Joining\n\n3.2.6.1 Join with Population Data\n\ncrime_df_mys &lt;- crime_df %&gt;% \n  filter(year &gt;= 2019 & year &lt;= 2022) %&gt;%\n  left_join(population_df, by = c(\"state\", \"district\", \"year\")) %&gt;%\n  mutate(crimes_pc = crimes/population) %&gt;%\n  dplyr::select(state, district, year, category, type, crimes, crimes_pc, population)\n\n\n\n3.2.6.2 Create for Pokok Sena District\nUnfortunately, the crime dataset we have sourced did not contain any information on the crimes in Pokok Sena District, possibility due to the scarce population in the area. To resolve this, we have taken the mean of the crime per capita in the neighbouring districts in Kedah State to apply to Pokok Sena.\n\npokok_sena_rows &lt;- crime_df_mys %&gt;%\n  filter(state == \"KEDAH\") %&gt;%\n  group_by(state, year, category, type) %&gt;%\n  summarise(crimes = mean(crimes),\n            crimes_pc = mean(crimes_pc),\n            population = mean(population)) %&gt;% \n  mutate(district = \"POKOK SENA\")\n\n`summarise()` has grouped output by 'state', 'year', 'category'. You can\noverride using the `.groups` argument.\n\npokok_sena_rows\n\n# A tibble: 48 × 8\n# Groups:   state, year, category [8]\n   state  year category type                crimes crimes_pc population district\n   &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;   \n 1 KEDAH  2019 assault  causing_injury      29.8    0.140          189. POKOK S…\n 2 KEDAH  2019 assault  murder               1.82   0.0129         189. POKOK S…\n 3 KEDAH  2019 assault  rape                13.2    0.0752         189. POKOK S…\n 4 KEDAH  2019 assault  robbery_gang_armed   0.182  0.00155        189. POKOK S…\n 5 KEDAH  2019 assault  robbery_gang_unar…  25.3    0.0992         189. POKOK S…\n 6 KEDAH  2019 assault  robbery_solo_armed   0.182  0.000410       189. POKOK S…\n 7 KEDAH  2019 assault  robbery_solo_unar…  14.7    0.0590         189. POKOK S…\n 8 KEDAH  2019 property break_in           103.     0.440          189. POKOK S…\n 9 KEDAH  2019 property theft_other         86.9    0.479          189. POKOK S…\n10 KEDAH  2019 property theft_vehicle_lor…   7.09   0.0202         189. POKOK S…\n# ℹ 38 more rows\n\ncrime_df_mys &lt;- bind_rows(crime_df_mys, pokok_sena_rows)\n\n\n\n2.3.6.3 Join with District Boundary\n\ncrime_df_mys &lt;- crime_df_mys %&gt;%\n  left_join(mys_sf, by = c(\"state\" = \"ADM1_EN\", \"district\" = \"ADM2_EN\")) %&gt;%\n  dplyr::select(state, district, year, category, type, crimes, crimes_pc, population, geometry)\n\ncrime_df_mys &lt;- st_as_sf(crime_df_mys)\ncrime_df_mys\n\nSimple feature collection with 4176 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 184853.1 ymin: 139843.3 xmax: 728635.8 ymax: 744607.2\nProjected CRS: Kertau (RSO) / RSO Malaya (m)\n# A tibble: 4,176 × 9\n# Groups:   state, district, year, category [696]\n   state district    year category type              crimes crimes_pc population\n   &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 JOHOR BATU PAHAT  2019 assault  causing_injury        41   0.0828        495.\n 2 JOHOR BATU PAHAT  2019 assault  murder                 3   0.00606       495.\n 3 JOHOR BATU PAHAT  2019 assault  rape                  29   0.0586        495.\n 4 JOHOR BATU PAHAT  2019 assault  robbery_gang_arm…      0   0             495.\n 5 JOHOR BATU PAHAT  2019 assault  robbery_gang_una…     37   0.0747        495.\n 6 JOHOR BATU PAHAT  2019 assault  robbery_solo_arm…      0   0             495.\n 7 JOHOR BATU PAHAT  2019 assault  robbery_solo_una…     29   0.0586        495.\n 8 JOHOR BATU PAHAT  2019 property break_in             157   0.317         495.\n 9 JOHOR BATU PAHAT  2019 property theft_other          127   0.256         495.\n10 JOHOR BATU PAHAT  2019 property theft_vehicle_lo…      4   0.00808       495.\n# ℹ 4,166 more rows\n# ℹ 1 more variable: geometry &lt;MULTIPOLYGON [m]&gt;\n\n\n\n\n\n3.2.7 Visualizing the distribution of crime\n\ncrime_df_mys_grp &lt;- crime_df_mys %&gt;%\n  group_by(state, district) %&gt;%\n  summarize(total_crimes_pc = sum(crimes_pc)/4)\n\n`summarise()` has grouped output by 'state'. You can override using the\n`.groups` argument.\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nchoro &lt;- tm_shape(crime_df_mys_grp) +\n  tm_fill(\"total_crimes_pc\", \n          n = 5,\n          style = \"equal\", \n          palette = \"Blues\",\n          title = \"Crime per Capita in West Malaysia\") +\n  tm_layout(main.title = \"Crime per Capita Distribution\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2, position = c(\"right\", \"top\")) +\n  tm_grid(alpha =0.2)\n\n\nchoro"
  },
  {
    "objectID": "Take-home_Ex/3/Take-home_Ex03.html#global-measures-of-spatial-autocorrelation",
    "href": "Take-home_Ex/3/Take-home_Ex03.html#global-measures-of-spatial-autocorrelation",
    "title": "take home exercise 3",
    "section": "3.4 Global Measures of Spatial Autocorrelation",
    "text": "3.4 Global Measures of Spatial Autocorrelation\n\n3.4.1 Computing Contiguity Spatial Weights\nWe now generate the neighbours list.\n\nmys_nb_q &lt;- st_contiguity(crime_df_mys_grp, queen=TRUE)\n\nWarning in spdep::poly2nb(geometry, queen = queen, ...): some observations have no neighbours;\nif this seems unexpected, try increasing the snap argument.\n\n\nWarning in spdep::poly2nb(geometry, queen = queen, ...): neighbour object has 3 sub-graphs;\nif this sub-graph count seems unexpected, try increasing the snap argument.\n\n# Langkawi has no immediate neighbours, hence its neighbour has to be manually added.\nmys_nb_q[[17]] &lt;- as.integer(c(18))\nmys_nb_q[[18]] &lt;- as.integer(sort(unique(c(mys_nb_q[[18]], 17))))\n\nmys_wm_rs &lt;- st_weights(mys_nb_q, style=\"W\")\n\nwm_q &lt;- crime_df_mys_grp %&gt;%\n  ungroup() %&gt;%\n  mutate(nb = mys_nb_q,\n         wt = mys_wm_rs,\n         .before = 1) \n\n\n\n3.4.2 Moran’s I test\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep. The primary goal of the test is to determine whether the spatial autocorrelation is positive, negative or non-existent.\nNull Hypothesis \\(H_0:I\\leq E[I]\\). This suggests that there is either no spatial autocorrelation (\\(I=E[I]\\)). or negative spatial autocorrelation (\\(I&lt;E[I]\\)).\nAlternative Hypothesis \\(H_0:I&gt; E[I]\\). This indicates the presence of positive spatial autocorrelation.\n\nmoranI &lt;- global_moran(wm_q$total_crimes_pc,\n                        wm_q$nb,\n                        wm_q$wt)\n\n\nglobal_moran_test(wm_q$total_crimes_pc,\n                  wm_q$nb,\n                  wm_q$wt,\n                  alternative = \"greater\")\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 3.9166, p-value = 4.491e-05\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.275786031      -0.011627907       0.005385229 \n\n\nBased on the Moran’s I test, we can conclude that there is evidence of significant positive spatial autocorrelation in the crime data. This suggests that the distribution of crime in Malaysia is not random and that there are clusters of high and low crime rates.\n\nThe Moran’s I statistic is positive (0.271500147), suggesting a positive spatial autocorrelation in the crime data. This means that areas with similar crime rates tend to be located near each other.\nThe standard deviate of 3.8061 indicates the significance of the Moran’s I statistic. A higher standard deviate suggests a stronger spatial pattern.\nThe p-value of 7.058e-05 is less than the significance level of 0.05, indicating that the observed spatial pattern is statistically significant. This means that it is unlikely to have occurred by chance.\n\n\n3.4.2.1 Performing Global Moran’s I permutation test\n\nset.seed(123)\n\ngmoranMC &lt;- global_moran_perm(wm_q$total_crimes_pc,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 999)\ngmoranMC\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.27579, observed rank = 999, p-value = 0.002\nalternative hypothesis: two.sided\n\n\n\nWe can observe that the Moran’s I statistic is 0.2715 with a p-value &lt; 2.2e-16, which is similar to our previous result using moran.test(). It confirms that our result is stable.\n\n\n\n3.4.2.2 Visualising Monte Carlo Moran’s I\n\nhist(gmoranMC$res, main=\"Histogram of Simulation Results\", xlab=\"Monte-Carlo Results\", ylab=\"Frequency\")\n\nabline(v = gmoranMC$statistic, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n3.4.3 Geary’s C test\nThe code chunk below performs Global Geary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\nglobal_c_test(wm_q$total_crimes_pc,\n                  wm_q$nb,\n                  wm_q$wt,\n                  alternative = \"greater\")\n\n\n    Geary C test under randomisation\n\ndata:  x \nweights: listw   \n\nGeary C statistic standard deviate = 4.1574, p-value = 1.609e-05\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n      0.645478034       1.000000000       0.007271778 \n\n\nThe calculated Geary’s C statistic of 0.649379732 deviates from the expected value of 1, indicating a potential spatial pattern in the data. The associated p-value of 2.155e-05 is statistically significant at the 0.05 level, further supporting the conclusion that the observed spatial pattern is unlikely to be due to random chance. Therefore, we reject the null hypothesis of no spatial autocorrelation.\n\n3.4.3.1 Monte Carlo Geary’s C\n\nset.seed(123)\n\nbperm &lt;- global_c_perm(wm_q$total_crimes_pc,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.64548, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nIt can be seen that the results are similar to the previous output of the code chunk. Hence our result is statistically significant.\n\n\n3.4.3.2 Visualising the Monte Carlo Geary’s C\n\nhist(bperm$res, \n     freq=TRUE, breaks=20, \n     xlab=\"Simulated Geary c\")\n\nabline(v=1, col=\"red\")"
  },
  {
    "objectID": "Take-home_Ex/3/Take-home_Ex03.html#local-measures-of-spatial-autocorrelation",
    "href": "Take-home_Ex/3/Take-home_Ex03.html#local-measures-of-spatial-autocorrelation",
    "title": "take home exercise 3",
    "section": "3.5 Local Measures of Spatial Autocorrelation",
    "text": "3.5 Local Measures of Spatial Autocorrelation\n\n3.5.1 Computing Local Moran’s I\nTo compute local Moran’s I, the local_moran() function of sfdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\n\nlisa &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    total_crimes_pc, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nlisa\n\nSimple feature collection with 87 features and 17 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 184853.1 ymin: 139843.3 xmax: 728635.8 ymax: 744607.2\nProjected CRS: Kertau (RSO) / RSO Malaya (m)\n# A tibble: 87 × 18\n        ii      eii  var_ii   z_ii   p_ii p_ii_sim p_folded_sim skewness\n     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.931   0.0733  0.224    1.81  0.0699     0.02         0.01   -0.776\n 2 -0.639   0.00450 0.437   -0.974 0.330      0.24         0.12    0.978\n 3  0.319  -0.0136  0.0529   1.44  0.148      0.04         0.02   -1.11 \n 4  0.0148 -0.00278 0.00580  0.230 0.818      0.96         0.48   -0.785\n 5  0.0716 -0.0366  0.0961   0.349 0.727      0.92         0.46   -0.596\n 6  0.779  -0.0610  0.334    1.46  0.146      0.1          0.05   -0.625\n 7  0.163   0.0101  0.0281   0.912 0.362      0.34         0.17   -0.331\n 8  1.21   -0.0341  0.646    1.55  0.121      0.04         0.02   -0.858\n 9  0.260   0.0210  0.249    0.479 0.632      0.76         0.38   -0.603\n10  0.352  -0.0139  0.0349   1.96  0.0502     0.02         0.01   -0.764\n# ℹ 77 more rows\n# ℹ 10 more variables: kurtosis &lt;dbl&gt;, mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;,\n#   nb &lt;nb&gt;, wt &lt;list&gt;, state &lt;chr&gt;, district &lt;chr&gt;, total_crimes_pc &lt;dbl&gt;,\n#   geometry &lt;MULTIPOLYGON [m]&gt;\n\n\n\n3.5.1.1 Visualising Local Moran’s I\n\ntm_shape(lisa)+\n  tm_fill(\"ii\", \n          palette = c(\"#b7dce9\",\"#e1ecbb\",\"#f5f3a6\",\n                      \"#f8d887\",\"#ec9a64\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)\n\n\n\n\n\n\n\n\n\n\n3.5.1.2 Visualising Local Moran’s I p-value\n\ntm_shape(lisa)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#b7dce9\",\"#c9e3d2\",\"#f5f3a6\",\"#ec9a64\",\"#d21b1c\"),\n          title = \"p-value\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)\n\n\n\n\n\n\n\n\n\n\n3.5.1.3 Visualising Statistically Significant Local Spatial Autocorrelation Map\nFrom the p-value map above, it appears that not every district exhibits a statistically significant Local Moran’s value. We will thus filter out to focus our analysis will focus solely on districts with statistically significant values.\n\nlisa_sig &lt;- lisa  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\n\ntm_shape(lisa)+\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6)+\ntm_shape(lisa_sig)+\n  tm_fill(\"ii\", \n          palette = c(\"#b7dce9\",\"#e1ecbb\",\"#f5f3a6\",\n                      \"#f8d887\",\"#ec9a64\",\"#d21b1c\"),\n          title = \"Local Moran's I (p &lt; 0.05)\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\n\n\n3.5.2 LISA Classification\nSpecific to our study, we may infer LISA classifications as below.\nHigh-Low Outliers: districts with a high value of crime per capita, surrounded by districts with low values of crime per capita\n\nLow-High Outliers: districts with a low value of crime per capita, surrounded by neighbouring districts with high values of crime per capita\n\nHigh-High Clusters: districts with a high value of crime per capita, surrounded by neighbouring districts with high values of crime per capita\n\nLow-Low Clusters: districts with a low value of crime per capita, surrounded by neighbouring districts with low values of crime per capita\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nstudy_area_lisa &lt;- tm_shape(lisa)+\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6)+\ntm_shape(lisa_sig)+\n  tm_fill(\"mean\", \n          palette = c(\"#b7dce9\",\"#ec9a64\",\"#e1ecbb\", \"#d21b1c\"),\n          title = \"LISA class\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)\n\nstudy_area_lisa\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "Take-home_Ex/3/Take-home_Ex03.html#hot-and-cold-spots-analysis-hcsa",
    "href": "Take-home_Ex/3/Take-home_Ex03.html#hot-and-cold-spots-analysis-hcsa",
    "title": "take home exercise 3",
    "section": "3.6 Hot and Cold Spots Analysis (HCSA)",
    "text": "3.6 Hot and Cold Spots Analysis (HCSA)\nThe Gi and Gi* measures are typically reported as a z-score where high values indicate a high-high cluster, and negative z-scores indicate a low-low cluster. There are no high-low and low-high classifications like the local Moran.\n\nwm_idw &lt;- crime_df_mys_grp %&gt;%\n  ungroup() %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There were 2 warnings in `stopifnot()`.\nThe first warning was:\nℹ In argument: `nb = include_self(st_contiguity(geometry))`.\nCaused by warning in `spdep::poly2nb()`:\n! some observations have no neighbours;\nif this seems unexpected, try increasing the snap argument.\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n\nNext, we will calculate local using local_gstart_perm() function.\n\nHCSA &lt;- wm_idw %&gt;% \n  mutate(local_Gi_star = local_gstar_perm(\n    total_crimes_pc, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi_star)\n\n\ntmap_mode(\"plot\")  \n\ntmap mode set to plotting\n\ntm_shape(HCSA)+\n  tm_fill(\"gi_star\", \n          palette = c(\"#57bfc0\", \"#7977f3\",\"#f8d673\",\"#f8b675\",\"#f67774\"),\n          title = \"Gi*\",\n          midpoint = 0) +\n  tm_borders(col = \"black\", alpha = 0.6)\n\n\n\n\n\n\n\n\nSimilar to what we did for the LISA map, we choose to narrow our focus onto districts with statistically significant Gi* values.\n\nHCSA_sig &lt;- HCSA  %&gt;%\n  filter(p_sim &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_polygons() +\ntm_shape(HCSA_sig)+\n  tm_fill(\"gi_star\", \n          palette = c(\"#57bfc0\", \"#7977f3\",\"#f8d673\",\"#f8b675\",\"#f67774\"),\n          title = \"Gi*\",\n          midpoint = 0,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)\n\n\n\n\n\n\n\n\n\nset.seed(123)\n\nthree_hotspots &lt;- (head((HCSA_sig[HCSA_sig$gi_star &gt; 2,]), 3)$district)\nthree_coldspots &lt;-  (head((HCSA_sig[HCSA_sig$gi_star &gt; -2,]), 3)$district)\n\nthree_hotspots\n\n[1] \"WP. KUALA LUMPUR\" \"S.P. UTARA\"       \"GOMBAK\"          \n\nthree_coldspots\n\n[1] \"BATU PAHAT\" \"MUAR\"       \"JELI\""
  },
  {
    "objectID": "Take-home_Ex/1/Take-home_Ex01.html",
    "href": "Take-home_Ex/1/Take-home_Ex01.html",
    "title": "Take-home_Ex01",
    "section": "",
    "text": "Millions of people have their lives shattered by armed conflict – wars – every year.\nArmed conflict has been on the rise since about 2012, after a decline in the 1990s and early 2000s. First came conflicts in Libya, Syria and Yemen, triggered by the 2011 Arab uprisings. Libya’s instability spilled south, helping set off a protracted crisis in the Sahel region. A fresh wave of major combat followed: the 2020 Azerbaijani-Armenian war over the Nagorno-Karabakh enclave, horrific fighting in Ethiopia’s northern Tigray region that began weeks later, the conflict prompted by the Myanmar army’s 2021 power grab and Russia’s 2022 assault on Ukraine. Add to those 2023’s devastation in Sudan and Gaza. Around the globe, more people are dying in fighting, being forced from their homes or in need of life-saving aid than in decades.\nSource: 10 Conflicts to Watch in 2024"
  },
  {
    "objectID": "Take-home_Ex/1/Take-home_Ex01.html#datasets",
    "href": "Take-home_Ex/1/Take-home_Ex01.html#datasets",
    "title": "Take-home_Ex01",
    "section": "3.1 Datasets",
    "text": "3.1 Datasets\n\nFor the purpose of this assignment, armed conflict data of Myanmar between January 2021 - June 2024 from Armed Conflict Location & Event Data (ACLED). In terms of event types, we are focusing on four main event types, namely: Battles, Explosion/Remote violence, Strategic developments, and Violence against civilians.\nWe will also be using geospatial data on the Myanmar National Border in ESRI Shapefile format. (Myanmar National Boundary MIMU v9.4)\nFinally, we will be utilizing OpenStreetMap of Myanmar in shapefile format. (OSM)"
  },
  {
    "objectID": "Take-home_Ex/1/Take-home_Ex01.html#importing-the-datasets",
    "href": "Take-home_Ex/1/Take-home_Ex01.html#importing-the-datasets",
    "title": "Take-home_Ex01",
    "section": "3.2 Importing the Datasets",
    "text": "3.2 Importing the Datasets\n\n3.2.1 Myanmar Armed Conflict Dataset\nThe dataset, which we downloaded from ACLED, is in csv format. To use this data in an R-environment, we need to import it as an sf object. We can do this using the st_read() function of the sf package. This function reads the csv data and returns an sf object that can be used for further analysis.\nThe data has also been transformed such that the EPSG coordinates are accurate to Myanmar.\n\nacled_sf &lt;- read_csv(\"data/2021-01-01-2024-06-30-Myanmar.csv\") %&gt;%\n  st_as_sf(coords = c(\n    \"longitude\", \"latitude\"),\n    crs=4326) %&gt;%\n  st_transform(crs = 32647) %&gt;%\n  mutate(event_date = dmy(event_date))\n\nThe event_date column is categorized by\n\nacled_sf &lt;- acled_sf %&gt;%\n  mutate(quarter = quarter(event_date))\n\n\n\n3.2.2 Myanmar Administrative Boundary Data\nThe code chunk below uses st_read() of sf package to import Myanmar shapefile into R. The imported shapefile will be simple features Object of sf.\n\nmyanmar_sf &lt;- st_read(dsn = \"data/mmr_polbnda2_adm1_250k_mimu_1\", \n                 layer = \"mmr_polbnda2_adm1_250k_mimu_1\") %&gt;%\n  st_as_sf(coords =c(\n    \"longitude\", \"latitude\"),\n           crs = 4326) %&gt;%\n  st_transform(crs = 32647)\n\n\n\n3.2.3 OpenStreetMap of Myanmar\nTo import the OpenStreetMap of Myanmar, I utilized st_read() once more.\n\nosm = st_read(\"data/myanmar-latest-free.shp\", layer=\"gis_osm_places_a_free_1\")"
  },
  {
    "objectID": "Take-home_Ex/1/Take-home_Ex01.html#mapping-the-geospatial-data-sets",
    "href": "Take-home_Ex/1/Take-home_Ex01.html#mapping-the-geospatial-data-sets",
    "title": "Take-home_Ex01",
    "section": "3.3 Mapping the geospatial data sets",
    "text": "3.3 Mapping the geospatial data sets\nIt is also useful for us to plot a map to show spatial patters.\n\ntmap_mode('plot')\n\nThe code chunk below plots the armed conflict data in Myanmar.\n\nacled_sf %&gt;%\n  tm_shape()+tm_dots()"
  },
  {
    "objectID": "Take-home_Ex/1/Take-home_Ex01.html#separating-the-data-by-year-and-quarter",
    "href": "Take-home_Ex/1/Take-home_Ex01.html#separating-the-data-by-year-and-quarter",
    "title": "Take-home_Ex01",
    "section": "4.1 Separating the data by year and quarter",
    "text": "4.1 Separating the data by year and quarter\nThe code chunk below separates the data provided into year and quarter for easier plotting.\n\n# year 2021\nacled_2021.Q1_sf &lt;- acled_sf %&gt;%\n  filter(year == '2021') %&gt;%\n  filter(quarter == '1')\n\nacled_2021.Q2_sf &lt;- acled_sf %&gt;%\n  filter(year == '2021') %&gt;%\n  filter(quarter == '2')\n\nacled_2021.Q3_sf &lt;- acled_sf %&gt;%\n  filter(year == '2021') %&gt;%\n  filter(quarter == '3')\n\nacled_2021.Q4_sf &lt;- acled_sf %&gt;%\n  filter(year == '2021') %&gt;%\n  filter(quarter == '4')\n\n# year 2022\nacled_2022.Q1_sf &lt;- acled_sf %&gt;%\n  filter(year == '2022') %&gt;%\n  filter(quarter == '1')\n\nacled_2022.Q2_sf &lt;- acled_sf %&gt;%\n  filter(year == '2022') %&gt;%\n  filter(quarter == '2')\n\nacled_2022.Q3_sf &lt;- acled_sf %&gt;%\n  filter(year == '2022') %&gt;%\n  filter(quarter == '3')\n\nacled_2022.Q4_sf &lt;- acled_sf %&gt;%\n  filter(year == '2022') %&gt;%\n  filter(quarter == '4')\n\n\n# year 2023\nacled_2023.Q1_sf &lt;- acled_sf %&gt;%\n  filter(year == '2023') %&gt;%\n  filter(quarter == '1')\n\nacled_2023.Q2_sf &lt;- acled_sf %&gt;%\n  filter(year == '2023') %&gt;%\n  filter(quarter == '2')\n\nacled_2023.Q3_sf &lt;- acled_sf %&gt;%\n  filter(year == '2023') %&gt;%\n  filter(quarter == '3')\n\nacled_2023.Q4_sf &lt;- acled_sf %&gt;%\n  filter(year == '2023') %&gt;%\n  filter(quarter == '4')\n\n\n# year 2024\nacled_2024.Q1_sf &lt;- acled_sf %&gt;%\n  filter(year == '2024') %&gt;%\n  filter(quarter == '1')\n\nacled_2024.Q2_sf &lt;- acled_sf %&gt;%\n  filter(year == '2024') %&gt;%\n  filter(quarter == '2')"
  },
  {
    "objectID": "Take-home_Ex/1/Take-home_Ex01.html#converting-sf-data-frames-to-sps-spatial-class",
    "href": "Take-home_Ex/1/Take-home_Ex01.html#converting-sf-data-frames-to-sps-spatial-class",
    "title": "Take-home_Ex01",
    "section": "4.2 Converting sf data frames to sp’s Spatial* class",
    "text": "4.2 Converting sf data frames to sp’s Spatial* class\nThe code chunk below uses as_Spatial() of sf package to convert the geospatial data from simple feature data frame to sp’s Spatial* class.\n\n# overall\nacled &lt;- as_Spatial(acled_sf)\n\n# by quarters\nacled_2021.Q1 &lt;- as_Spatial(acled_2021.Q1_sf)\nacled_2021.Q2 &lt;- as_Spatial(acled_2021.Q2_sf)\nacled_2021.Q3 &lt;- as_Spatial(acled_2021.Q3_sf)\nacled_2021.Q4 &lt;- as_Spatial(acled_2021.Q4_sf)\n\nacled_2022.Q1 &lt;- as_Spatial(acled_2022.Q1_sf)\nacled_2022.Q2 &lt;- as_Spatial(acled_2022.Q2_sf)\nacled_2022.Q3 &lt;- as_Spatial(acled_2022.Q3_sf)\nacled_2022.Q4 &lt;- as_Spatial(acled_2022.Q4_sf)\n\nacled_2023.Q1 &lt;- as_Spatial(acled_2023.Q1_sf)\nacled_2023.Q2 &lt;- as_Spatial(acled_2023.Q2_sf)\nacled_2023.Q3 &lt;- as_Spatial(acled_2023.Q3_sf)\nacled_2023.Q4 &lt;- as_Spatial(acled_2023.Q4_sf)\n\nacled_2024.Q1 &lt;- as_Spatial(acled_2024.Q1_sf)\nacled_2024.Q2 &lt;- as_Spatial(acled_2024.Q2_sf)\n\n\nacled_2021.Q1"
  },
  {
    "objectID": "Take-home_Ex/1/Take-home_Ex01.html#converting-the-simple-features-to-spatstats-ppp-planar-point-pattern-object",
    "href": "Take-home_Ex/1/Take-home_Ex01.html#converting-the-simple-features-to-spatstats-ppp-planar-point-pattern-object",
    "title": "Take-home_Ex01",
    "section": "4.3 Converting the simple features to spatstat’s ppp (planar point pattern) object",
    "text": "4.3 Converting the simple features to spatstat’s ppp (planar point pattern) object\nspatstat requires the analytical data in ppp object form. Hence we will convert sf objects to ppp objects using as.ppp() function by providing the point coordinates and the observation window.\n\n# overall\nacled_ppp &lt;- as.ppp(st_coordinates(acled_sf), st_bbox(acled_sf))\n\n# by quarters\nacled_2021.Q1_ppp &lt;- as.ppp(st_coordinates(acled_2021.Q1_sf), st_bbox(acled_2021.Q1_sf))\nacled_2021.Q2_ppp &lt;- as.ppp(st_coordinates(acled_2021.Q2_sf), st_bbox(acled_2021.Q2_sf))\nacled_2021.Q3_ppp &lt;- as.ppp(st_coordinates(acled_2021.Q3_sf), st_bbox(acled_2021.Q3_sf))\nacled_2021.Q4_ppp &lt;- as.ppp(st_coordinates(acled_2021.Q4_sf), st_bbox(acled_2021.Q4_sf))\n\nacled_2022.Q1_ppp &lt;- as.ppp(st_coordinates(acled_2022.Q1_sf), st_bbox(acled_2022.Q1_sf))\nacled_2022.Q2_ppp &lt;- as.ppp(st_coordinates(acled_2022.Q2_sf), st_bbox(acled_2022.Q2_sf))\nacled_2022.Q3_ppp &lt;- as.ppp(st_coordinates(acled_2022.Q3_sf), st_bbox(acled_2022.Q3_sf))\nacled_2022.Q4_ppp &lt;- as.ppp(st_coordinates(acled_2022.Q4_sf), st_bbox(acled_2022.Q4_sf))\n\nacled_2023.Q1_ppp &lt;- as.ppp(st_coordinates(acled_2023.Q1_sf), st_bbox(acled_2023.Q1_sf))\nacled_2023.Q2_ppp &lt;- as.ppp(st_coordinates(acled_2023.Q2_sf), st_bbox(acled_2023.Q2_sf))\nacled_2023.Q3_ppp &lt;- as.ppp(st_coordinates(acled_2023.Q3_sf), st_bbox(acled_2023.Q3_sf))\nacled_2023.Q4_ppp &lt;- as.ppp(st_coordinates(acled_2023.Q4_sf), st_bbox(acled_2023.Q4_sf))\n\nacled_2024.Q1_ppp &lt;- as.ppp(st_coordinates(acled_2024.Q1_sf), st_bbox(acled_2024.Q1_sf))\nacled_2024.Q2_ppp &lt;- as.ppp(st_coordinates(acled_2024.Q2_sf), st_bbox(acled_2024.Q2_sf))\n\nplot(acled_2021.Q1_ppp)\n\nNext, we will take a quick look at the summary statistics of the newly created ppp object.\n\nsummary(acled_2021.Q1_ppp)"
  },
  {
    "objectID": "Take-home_Ex/1/Take-home_Ex01.html#handling-duplicated-points",
    "href": "Take-home_Ex/1/Take-home_Ex01.html#handling-duplicated-points",
    "title": "Take-home_Ex01",
    "section": "4.4 Handling duplicated points",
    "text": "4.4 Handling duplicated points\nIt is previously mentioned in summary(acled_ppp) that there are duplicated points in the patterns. We can double confirm the duplication in a ppp object by using the code chunk below.\n\nany(duplicated(acled_2021.Q1_ppp))\n\nSince the above code chunk returns TRUE, we will use sum() and multiplicity() functions to see how many locations have more than one point event.\n\nsum(multiplicity(acled_2021.Q1_ppp) &gt; 1)\n\nWe can address this by using rjitter() which will add a small perturbation to the duplicate points so that they do not occupy the exact same spaces.\n\n# overall\nacled_ppp_jit &lt;- rjitter(acled_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n# by quarters\nacled_2021.Q1_ppp_jit &lt;- rjitter(acled_2021.Q1_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2021.Q2_ppp_jit &lt;- rjitter(acled_2021.Q2_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2021.Q3_ppp_jit &lt;- rjitter(acled_2021.Q3_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2021.Q4_ppp_jit &lt;- rjitter(acled_2021.Q4_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nacled_2022.Q1_ppp_jit &lt;- rjitter(acled_2022.Q1_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2022.Q2_ppp_jit &lt;- rjitter(acled_2022.Q2_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2022.Q3_ppp_jit &lt;- rjitter(acled_2022.Q3_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2022.Q4_ppp_jit &lt;- rjitter(acled_2022.Q4_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nacled_2023.Q1_ppp_jit &lt;- rjitter(acled_2023.Q1_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2023.Q2_ppp_jit &lt;- rjitter(acled_2023.Q2_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2023.Q3_ppp_jit &lt;- rjitter(acled_2023.Q3_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2023.Q4_ppp_jit &lt;- rjitter(acled_2023.Q4_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nacled_2024.Q1_ppp_jit &lt;- rjitter(acled_2024.Q1_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2024.Q2_ppp_jit &lt;- rjitter(acled_2024.Q2_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nNext, we will check if there is still any duplicate points in our dataset.\n\nany(duplicated(acled_2021.Q1_ppp_jit))"
  },
  {
    "objectID": "Take-home_Ex/1/Take-home_Ex01.html#creating-owin-object",
    "href": "Take-home_Ex/1/Take-home_Ex01.html#creating-owin-object",
    "title": "Take-home_Ex01",
    "section": "4.5 Creating owin object",
    "text": "4.5 Creating owin object\nSince we have imported the Myanmar boundary, we will now convert the myanmar_sf object into an owin object.\n\nmyanmar_owin &lt;- as.owin(myanmar_sf)\nplot(myanmar_owin)\n\n\nsummary(myanmar_owin)"
  },
  {
    "objectID": "Take-home_Ex/1/Take-home_Ex01.html#creating-point-events-objects-in-owin-object",
    "href": "Take-home_Ex/1/Take-home_Ex01.html#creating-point-events-objects-in-owin-object",
    "title": "Take-home_Ex01",
    "section": "4.6 Creating point events objects in owin Object",
    "text": "4.6 Creating point events objects in owin Object\nIn this last step of geospatial data wrangling, we will extract armed conflict events that are located within Myanmar.\n\n# overall\nacledmyanmar_ppp = acled_ppp[myanmar_owin]\n\n# by quarters\nacledmyanmar_2021.Q1_ppp = acled_2021.Q1_ppp[myanmar_owin]\nacledmyanmar_2021.Q2_ppp = acled_2021.Q2_ppp[myanmar_owin]\nacledmyanmar_2021.Q3_ppp = acled_2021.Q3_ppp[myanmar_owin]\nacledmyanmar_2021.Q4_ppp = acled_2021.Q4_ppp[myanmar_owin]\n\nacledmyanmar_2022.Q1_ppp = acled_2022.Q1_ppp[myanmar_owin]\nacledmyanmar_2022.Q2_ppp = acled_2022.Q2_ppp[myanmar_owin]\nacledmyanmar_2022.Q3_ppp = acled_2022.Q3_ppp[myanmar_owin]\nacledmyanmar_2022.Q4_ppp = acled_2022.Q4_ppp[myanmar_owin]\n\nacledmyanmar_2023.Q1_ppp = acled_2023.Q1_ppp[myanmar_owin]\nacledmyanmar_2023.Q2_ppp = acled_2023.Q2_ppp[myanmar_owin]\nacledmyanmar_2023.Q3_ppp = acled_2023.Q3_ppp[myanmar_owin]\nacledmyanmar_2023.Q4_ppp = acled_2023.Q4_ppp[myanmar_owin]\n\nacledmyanmar_2024.Q1_ppp = acled_2024.Q1_ppp[myanmar_owin]\nacledmyanmar_2024.Q2_ppp = acled_2024.Q2_ppp[myanmar_owin]\n\nThe output object combines both the point and polygon feature in one ppp object class as shown below.\n\nsummary(acledmyanmar_2021.Q1_ppp)\n\n\nplot(acledmyanmar_2021.Q1_ppp)"
  },
  {
    "objectID": "Take-home_Ex/1/Take-home_Ex01.html#kernel-density-estimation",
    "href": "Take-home_Ex/1/Take-home_Ex01.html#kernel-density-estimation",
    "title": "Take-home_Ex01",
    "section": "5.1 Kernel Density Estimation",
    "text": "5.1 Kernel Density Estimation\n\n5.1.1 Rescaling KDE Layers\nWe will use rescale() function of spatstat package to covert the unit of measurement from meter to kilometer.\n\n# overall\nacledmyanmar_ppp.km &lt;- rescale(acledmyanmar_ppp, 1000, \"km\")\n\n# by quarters\nacledmyanmar_2021.Q1_ppp.km &lt;- rescale(acledmyanmar_2021.Q1_ppp, 1000, \"km\")\nacledmyanmar_2021.Q2_ppp.km &lt;- rescale(acledmyanmar_2021.Q2_ppp, 1000, \"km\")\nacledmyanmar_2021.Q3_ppp.km &lt;- rescale(acledmyanmar_2021.Q3_ppp, 1000, \"km\")\nacledmyanmar_2021.Q4_ppp.km &lt;- rescale(acledmyanmar_2021.Q4_ppp, 1000, \"km\")\n\nacledmyanmar_2022.Q1_ppp.km &lt;- rescale(acledmyanmar_2022.Q1_ppp, 1000, \"km\")\nacledmyanmar_2022.Q2_ppp.km &lt;- rescale(acledmyanmar_2022.Q2_ppp, 1000, \"km\")\nacledmyanmar_2022.Q3_ppp.km &lt;- rescale(acledmyanmar_2022.Q3_ppp, 1000, \"km\")\nacledmyanmar_2022.Q4_ppp.km &lt;- rescale(acledmyanmar_2022.Q4_ppp, 1000, \"km\")\n\nacledmyanmar_2023.Q1_ppp.km &lt;- rescale(acledmyanmar_2023.Q1_ppp, 1000, \"km\")\nacledmyanmar_2023.Q2_ppp.km &lt;- rescale(acledmyanmar_2023.Q2_ppp, 1000, \"km\")\nacledmyanmar_2023.Q3_ppp.km &lt;- rescale(acledmyanmar_2023.Q3_ppp, 1000, \"km\")\nacledmyanmar_2023.Q4_ppp.km &lt;- rescale(acledmyanmar_2023.Q4_ppp, 1000, \"km\")\n\nacledmyanmar_2024.Q1_ppp.km &lt;- rescale(acledmyanmar_2024.Q1_ppp, 1000, \"km\")\nacledmyanmar_2024.Q2_ppp.km &lt;- rescale(acledmyanmar_2024.Q2_ppp, 1000, \"km\")"
  },
  {
    "objectID": "Take-home_Ex/1/Take-home_Ex01.html#quarterly-kde-layers",
    "href": "Take-home_Ex/1/Take-home_Ex01.html#quarterly-kde-layers",
    "title": "Take-home_Ex01",
    "section": "5.2 Quarterly KDE layers",
    "text": "5.2 Quarterly KDE layers\n\nkde_acledmyanmar_2021.Q1.bw &lt;- density(acledmyanmar_2021.Q1_ppp.km, \n                                       sigma=20, \n                                       edge=TRUE, \n                                       kernel=\"gaussian\")\nkde_acledmyanmar_2021.Q2.bw &lt;- density(acledmyanmar_2021.Q2_ppp.km, \n                                       sigma=20, \n                                       edge=TRUE, \n                                       kernel=\"gaussian\")\nkde_acledmyanmar_2021.Q3.bw &lt;- density(acledmyanmar_2021.Q3_ppp.km, \n                                       sigma=20, \n                                       edge=TRUE, \n                                       kernel=\"gaussian\")\nkde_acledmyanmar_2021.Q4.bw &lt;- density(acledmyanmar_2021.Q4_ppp.km, \n                                       sigma=20, \n                                       edge=TRUE, \n                                       kernel=\"gaussian\")\n\nkde_acledmyanmar_2022.Q1.bw &lt;- density(acledmyanmar_2022.Q1_ppp.km, \n                                       sigma=20, \n                                       edge=TRUE, \n                                       kernel=\"gaussian\")\nkde_acledmyanmar_2022.Q2.bw &lt;- density(acledmyanmar_2022.Q2_ppp.km, \n                                      sigma=20, \n                                       edge=TRUE, \n                                       kernel=\"gaussian\")\nkde_acledmyanmar_2022.Q3.bw &lt;- density(acledmyanmar_2022.Q3_ppp.km, \n                                       sigma=20, \n                                       edge=TRUE, \n                                       kernel=\"gaussian\")\nkde_acledmyanmar_2022.Q4.bw &lt;- density(acledmyanmar_2022.Q4_ppp.km, \n                                       sigma=20, \n                                       edge=TRUE, \n                                       kernel=\"gaussian\")\n\nkde_acledmyanmar_2023.Q1.bw &lt;- density(acledmyanmar_2023.Q1_ppp.km, \n                                       sigma=20, \n                                       edge=TRUE, \n                                       kernel=\"gaussian\")\nkde_acledmyanmar_2023.Q2.bw &lt;- density(acledmyanmar_2023.Q2_ppp.km, \n                                       sigma=20, \n                                       edge=TRUE, \n                                       kernel=\"gaussian\")\nkde_acledmyanmar_2023.Q3.bw &lt;- density(acledmyanmar_2023.Q3_ppp.km, \n                                       sigma=20, \n                                       edge=TRUE, \n                                       kernel=\"gaussian\")\nkde_acledmyanmar_2023.Q4.bw &lt;- density(acledmyanmar_2023.Q4_ppp.km, \n                                       sigma=20, \n                                       edge=TRUE, \n                                       kernel=\"gaussian\")\n\nkde_acledmyanmar_2024.Q1.bw &lt;- density(acledmyanmar_2024.Q1_ppp.km, \n                                       sigma=20, \n                                       edge=TRUE, \n                                       kernel=\"gaussian\")\nkde_acledmyanmar_2024.Q2.bw &lt;- density(acledmyanmar_2024.Q2_ppp.km, \n                                       sigma=20, \n                                       edge=TRUE, \n                                       kernel=\"gaussian\")\n\n\npar(mfrow=c(2,4)) \n\nplot(kde_acledmyanmar_2021.Q1.bw)\nplot(kde_acledmyanmar_2021.Q2.bw)\nplot(kde_acledmyanmar_2021.Q3.bw)\nplot(kde_acledmyanmar_2021.Q4.bw)\n\nplot(kde_acledmyanmar_2022.Q1.bw)\nplot(kde_acledmyanmar_2022.Q2.bw)\nplot(kde_acledmyanmar_2022.Q3.bw)\nplot(kde_acledmyanmar_2022.Q4.bw)\n\nplot(kde_acledmyanmar_2023.Q1.bw)\nplot(kde_acledmyanmar_2023.Q2.bw)\nplot(kde_acledmyanmar_2023.Q3.bw)\nplot(kde_acledmyanmar_2023.Q4.bw)\n\nplot(kde_acledmyanmar_2024.Q1.bw)\nplot(kde_acledmyanmar_2024.Q2.bw)"
  },
  {
    "objectID": "Take-home_Ex/1/Take-home_Ex01.html#data-wrangling-for-second-order-analysis",
    "href": "Take-home_Ex/1/Take-home_Ex01.html#data-wrangling-for-second-order-analysis",
    "title": "Take-home_Ex01",
    "section": "6.1 Data Wrangling for Second-order analysis",
    "text": "6.1 Data Wrangling for Second-order analysis\n\n6.1.1 Extracting study areas\nThe code chunk below targets the areas with the highest amount of activity.\n\nmyanmar_sf\n\n\nSGI &lt;- myanmar_sf %&gt;%\n  filter(ST == \"Sagaing\")\nKC &lt;- myanmar_sf %&gt;%\n  filter(ST == \"Kachin\")\nMW &lt;- myanmar_sf %&gt;%\n  filter(ST == \"Magway\")\nMDL &lt;- myanmar_sf %&gt;%\n  filter(ST == \"Mandalay\")\n\n\n\n6.1.2 Converting sf objects into owin objects\nNow, we will convert these sf objects into owin objects that is required by spatstat.\n\nSGI_owin &lt;- as.owin(SGI)\nKC_owin &lt;- as.owin(KC)\nMW_owin &lt;- as.owin(MW)\nMDL_owin &lt;- as.owin(MDL)\n\n\n\n6.1.3 Combining event points and the study area\nBy using the code chunk below, we are able to extract events that is within specific regions to do our analysis later on.\n\nSGI_ppp = acled_ppp_jit[SGI_owin]\nKC_ppp = acled_ppp_jit[KC_owin]\nMW_ppp = acled_ppp_jit[MW_owin]\nMDL_ppp = acled_ppp_jit[MDL_owin]\n\nrescale() is used to transform the unit of measurement from meters to kilometers.\n\nSGI_ppp.km = rescale(SGI_ppp, 1000, \"km\")\nKC_ppp.km = rescale(KC_ppp, 1000, \"km\")\nMW_ppp.km = rescale(MW_ppp, 1000, \"km\")\nMDL_ppp.km = rescale(MDL_ppp, 1000, \"km\")\n\nThe code chunk below plots the four study areas.\n\npar(mfrow=c(2,2))\nplot(SGI_ppp.km, main=\"Sagaing\")\nplot(KC_ppp.km, main=\"Kachin\")\nplot(MW_ppp.km, main=\"Magway\")\nplot(MDL_ppp.km, main=\"Mandalay\")"
  },
  {
    "objectID": "Take-home_Ex/1/Take-home_Ex01.html#analysing-spatial-point-process-using-g-function",
    "href": "Take-home_Ex/1/Take-home_Ex01.html#analysing-spatial-point-process-using-g-function",
    "title": "Take-home_Ex01",
    "section": "6.2 Analysing Spatial Point Process Using G-Function",
    "text": "6.2 Analysing Spatial Point Process Using G-Function\n\n6.2.1 Sagaing area\nThe code chunk below is used to compute G-function using Gest() of spatat package.\n\nG_SGI = Gest(SGI_ppp, correction = \"border\")\nplot(G_SGI, xlim=c(0,500))\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of events in Sagaing are randomly distributed.\nH1= The distribution of events in Sagaing are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function:\n\nG_SGI.csr &lt;- envelope(SGI_ppp, Gest, nsim = 249)\n\n\nplot(G_SGI.csr)\n\n\n\n6.2.2 Kachin area\n\nG_KC = Gest(KC_ppp, correction = \"border\")\nplot(G_KC, xlim=c(0,500))\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of events in Kachin are randomly distributed.\nH1= The distribution of events in Kachin are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function:\n\nG_KC.csr &lt;- envelope(KC_ppp, Gest, nsim = 249)\n\n\nplot(G_KC.csr)\n\n\n\n6.2.3 Magway area\n\nG_MW = Gest(MW_ppp, correction = \"border\")\nplot(G_MW, xlim=c(0,500))\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of events in Magway are randomly distributed.\nH1= The distribution of events in Magway are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function:\n\nG_MW.csr &lt;- envelope(MW_ppp, Gest, nsim = 249)\n\n\nplot(G_MW.csr)\n\n\n\n6.2.4 Mandalay area\n\nG_MDL = Gest(MDL_ppp, correction = \"border\")\nplot(G_MDL, xlim=c(0,500))\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\nHo = The distribution of events in Mandalay are randomly distributed.\nH1= The distribution of events in Mandalay are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function:\n\nG_MDL.csr &lt;- envelope(MDL_ppp, Gest, nsim = 249)\n\n\nplot(G_MDL.csr)"
  },
  {
    "objectID": "Take-home_Ex/1/Take-home_Ex01.html#computing-spatio-temporal-kde-by-quarters",
    "href": "Take-home_Ex/1/Take-home_Ex01.html#computing-spatio-temporal-kde-by-quarters",
    "title": "Take-home_Ex01",
    "section": "7.2 Computing spatio-temporal KDE by quarters",
    "text": "7.2 Computing spatio-temporal KDE by quarters\nspattemp.density() of sparr package is used to compute the STKDE.\n\nacledmyanmar_2021_kde &lt;- spattemp.density(acled_quarter_2021_owin)\nacledmyanmar_2022_kde &lt;- spattemp.density(acled_quarter_2022_owin)\nacledmyanmar_2023_kde &lt;- spattemp.density(acled_quarter_2023_owin)\nacledmyanmar_2024_kde &lt;- spattemp.density(acled_quarter_2024_owin)\n\n\n7.2.1 Plotting the spatio-temporal KDE object\n\nquarters &lt;- c(1,2,3,4)\npar(mfcol=c(1,4))\nfor(i in quarters){ \n  plot(acledmyanmar_2021_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2021 Q\",i))\n}\n\n\npar(mfcol=c(1,4))\nfor(i in quarters){ \n  plot(acledmyanmar_2022_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2022 Q\",i))\n}\n\n\npar(mfcol=c(1,4))\nfor(i in quarters){ \n  plot(acledmyanmar_2023_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2023 Q\",i))\n}\n\n\nquarters &lt;- c(1,2)\npar(mfcol=c(1,2))\nfor(i in quarters){ \n  plot(acledmyanmar_2024_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2024 Q\",i))\n}"
  },
  {
    "objectID": "Take-home_Ex/1/Take-home_Ex01.html#displaying-kde-layers",
    "href": "Take-home_Ex/1/Take-home_Ex01.html#displaying-kde-layers",
    "title": "Take-home_Ex01",
    "section": "9.1 Displaying KDE layers",
    "text": "9.1 Displaying KDE layers\n\nosm &lt;- osm %&gt;% \n  dplyr::select('osm_id', 'fclass')\nosm &lt;- st_transform(osm, crs = 32647)\n\n\nmerged_myanmar &lt;- st_union(myanmar_sf)\nosm_myanmar &lt;- st_intersection(osm, merged_myanmar)\n\n# splitting MULTILINESTRING into individual LINESTRING as it may cause issues with KDE calculations\nosm_myanmar &lt;- st_cast(st_cast(osm_myanmar, \"MULTILINESTRING\"),\"LINESTRING\")\n\n\nwrite_rds(osm_myanmar, \"data/rds/osm_myanmar.rds\")\n\n\ntest_density &lt;- density(acledmyanmar_ppp, \n             sigma=25, \n             edge=TRUE, \n             kernel=\"gaussian\")\n\ndensity_raster &lt;- raster(test_density)\nprojection(density_raster) &lt;- CRS(\"+init=EPSG:32647\")\n\nplot(osm_myanmar)"
  },
  {
    "objectID": "Take-home_Ex/1/Take-home_Ex01.html#displaying-stkde-layers",
    "href": "Take-home_Ex/1/Take-home_Ex01.html#displaying-stkde-layers",
    "title": "Take-home_Ex01",
    "section": "9.2 Displaying STKDE layers",
    "text": "9.2 Displaying STKDE layers\nAs the calculation will be large, I have created a function to lessen code duplication.\n\nplot_stkde &lt;- function(kde) {\n  test_density &lt;- density(kde, \n               sigma=25, \n               edge=TRUE, \n               kernel=\"gaussian\")\n  \n  density_raster &lt;- raster(test_density)\n  projection(density_raster) &lt;- CRS(\"+init=EPSG:32647\")\n  \n  plot(osm_myanmar)\n}\n\n\nplot_stkde(acled_quarter_2021_ppp)\n\n\nplot_stkde(acled_quarter_2022_ppp)\n\n\nplot_stkde(acled_quarter_2023_ppp)\n\n\nplot_stkde(acled_quarter_2024_ppp)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10.html",
    "href": "In-class_Ex/In-class_Ex10.html",
    "title": "in class exercise 10",
    "section": "",
    "text": "pacman::p_load(olsrr, ggstatsplot, sf,tmap, tidyverse, gtsummary, performance, see, sfdep)\n\n\ncondo_resale &lt;- read_csv(\"data/Condo_resale_2015.csv\")\n\nmpsz &lt;- read_rds(\"data/rds/mpsz.rds\")\n\ncondo_resale_sf &lt;- read_rds(\"data/rds/condo_resale_sf.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10.html#linearity-assumption-test",
    "href": "In-class_Ex/In-class_Ex10.html#linearity-assumption-test",
    "title": "in class exercise 10",
    "section": "Linearity assumption test",
    "text": "Linearity assumption test\n\nout &lt;- plot(check_model(condo_sb_mlr$model, \n                        panel = FALSE))\nout[[2]]\n\nthe r/s btwn the dep var and indep. vars are linear"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10.html#normality-assumption-test",
    "href": "In-class_Ex/In-class_Ex10.html#normality-assumption-test",
    "title": "in class exercise 10",
    "section": "Normality assumption test",
    "text": "Normality assumption test\n\nplot(check_normality(condo_sb_mlr$model))\n\nresidual resembles normal distribution"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10.html#checking-outliers",
    "href": "In-class_Ex/In-class_Ex10.html#checking-outliers",
    "title": "in class exercise 10",
    "section": "Checking outliers",
    "text": "Checking outliers\n\noutliers &lt;- check_outliers(condo_sb_mlr$model,\n                           method = \"cook\")\noutliers\n\n\nplot(check_outliers(condo_sb_mlr$model,\n                           method = \"cook\"))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05.html",
    "title": "In class exercise 5",
    "section": "",
    "text": "Getting Started\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr, GWmodel)\n\n\nImport shapefile into r environment\n\nhunan &lt;- st_read(dsn = \"data\",\n                 layer = \"Hunan\")\n\n\n\nImport csv file into r environment\n\nhunan2012 &lt;- read_csv(\"data/Hunan_2012.csv\")\n\n\n\nPerforming relational join\n\nhunan_sf &lt;- left_join(hunan, hunan2012)%&gt;%\n  dplyr::select(1:3, 7, 15, 16, 31, 32)\n\n\nwrite_rds(hunan_sf, \"data/rds/hunan_sf.rds\")\n\n\nhunan_sf &lt;- read_rds(\"data/rds/hunan_sf.rds\")\n\n\nhunan_sp &lt;- hunan_sf %&gt;%\n  as_Spatial()\n\nDetermine adaptive bandwidth\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1, \n                 data = hunan_sp, \n                 approach = \"AIC\", \n                 adaptive = TRUE, \n                 kernel = \"bisquare\", \n                 longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\n\n\nbw_AIC\n\n[1] 22\n\n\nDetermine fixed bandwidth\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = 'CV',\n                 adaptive = FALSE,\n                 kernel = 'bisquare',\n                 longlat = T)\n\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n\n\n\nbw_CV\n\n[1] 76.29126\n\n\ncomputing geographically weighted summary statistics\n\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC,\n               kernel = 'bisquare',\n               adaptive = TRUE,\n               longlat = T)\n\n\n# view(gwstat[[\"SDF\"]]@data)\n\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\n\n\nhunan_gstat &lt;- cbind(hunan_sf, gwstat_df)\n\n\ntm_shape(hunan_gstat) +\n  tm_fill(\"GDPPC_LM\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) + \n  tm_layout(main.title = \"Distribution of geographically weighted mean\",\n            main.title.position = \"center\",\n            main.title.size = 2.0,\n            legend.text.size = 1.20,\n            legend.height = 1.50,\n            legend.width = 1.50,\n            frame = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03.html",
    "title": "In-class_Ex03",
    "section": "",
    "text": "To obtain reproducible results for monte carlo simulation, use set.seed (can place it at the very top of the document to standardize throughout)\n\ninstall.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse, maptools, sp)\n\n\nacled_sf &lt;- st_read(\"data/ACLED_Myanmar.csv\") %&gt;%\n  st_as_sf(coords = c(\n    \"longitude\", \"latitude\"),\n    crs=4326) %&gt;%\n  st_transform(crs = 32647) %&gt;%\n  mutate(event_date = dmy(event_date))\n\nReading layer `ACLED_Myanmar' from data source \n  `C:\\jechaxu\\IS415-GAA\\In-class_Ex\\data\\ACLED_Myanmar.csv' using driver `CSV'\n\n\nWarning: no simple feature geometries present: returning a data.frame or tbl_df\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\nacled_sf %&gt;%\n  filter(year == 2023 |\n           event_type == \"Political Violence\") %&gt;%\n  tm_shape()+tm_dots()\n\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01.html",
    "title": "In Class Exercise 1: IS415-GAA",
    "section": "",
    "text": "pacman::p_load(sf, tidyverse)\n\nedited 20 August: i used an absolute path instead of a relative path in this code chunk. I have replaced it.\n\nmpsz = st_read(dsn = \"data/MPSZ-2019\", \n                  layer = \"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source \n  `C:\\jechaxu\\IS415-GAA\\In-class_Ex\\data\\MPSZ-2019' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nThe column in the sf data.frame that contains the geometries is a list. We retrieve the geometry list-column using st_geometry() as shown in the code chunk below.\n\nst_geometry(mpsz)\n\nGeometry set for 332 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((103.8802 1.283859, 103.8802 1.2...\n\n\nMULTIPOLYGON (((103.8376 1.295599, 103.8377 1.2...\n\n\nMULTIPOLYGON (((103.8341 1.292476, 103.8341 1.2...\n\n\nMULTIPOLYGON (((103.7125 1.291625, 103.7126 1.2...\n\n\nMULTIPOLYGON (((103.8472 1.297, 103.8473 1.2969...\n\n\n\nglimpse(mpsz)\n\nRows: 332\nColumns: 7\n$ SUBZONE_N  &lt;chr&gt; \"MARINA EAST\", \"INSTITUTION HILL\", \"ROBERTSON QUAY\", \"JURON…\n$ SUBZONE_C  &lt;chr&gt; \"MESZ01\", \"RVSZ05\", \"SRSZ01\", \"WISZ01\", \"MUSZ02\", \"MPSZ05\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA EAST\", \"RIVER VALLEY\", \"SINGAPORE RIVER\", \"WESTERN …\n$ PLN_AREA_C &lt;chr&gt; \"ME\", \"RV\", \"SR\", \"WI\", \"MU\", \"MP\", \"WI\", \"WI\", \"SI\", \"SI\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"WEST…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"WR\", \"CR\", \"CR\", \"WR\", \"WR\", \"CR\", \"CR\",…\n$ geometry   &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((103.8802 1...., MULTIPOLYGON (…\n\n\n\nhead(mpsz, n=5)  \n\nSimple feature collection with 5 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6537 ymin: 1.216215 xmax: 103.8811 ymax: 1.29742\nGeodetic CRS:  WGS 84\n                SUBZONE_N SUBZONE_C      PLN_AREA_N PLN_AREA_C       REGION_N\n1             MARINA EAST    MESZ01     MARINA EAST         ME CENTRAL REGION\n2        INSTITUTION HILL    RVSZ05    RIVER VALLEY         RV CENTRAL REGION\n3          ROBERTSON QUAY    SRSZ01 SINGAPORE RIVER         SR CENTRAL REGION\n4 JURONG ISLAND AND BUKOM    WISZ01 WESTERN ISLANDS         WI    WEST REGION\n5            FORT CANNING    MUSZ02          MUSEUM         MU CENTRAL REGION\n  REGION_C                       geometry\n1       CR MULTIPOLYGON (((103.8802 1....\n2       CR MULTIPOLYGON (((103.8376 1....\n3       CR MULTIPOLYGON (((103.8341 1....\n4       WR MULTIPOLYGON (((103.7125 1....\n5       CR MULTIPOLYGON (((103.8472 1....\n\n\nPlotting the geospatial data\n\nplot(mpsz)"
  },
  {
    "objectID": "In-class_Ex/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "href": "In-class_Ex/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10.html",
    "href": "Hands-on_Ex/Hands-on_Ex10.html",
    "title": "hands on exercise 10",
    "section": "",
    "text": "pacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10.html#updating-crs-information",
    "href": "Hands-on_Ex/Hands-on_Ex10.html#updating-crs-information",
    "title": "hands on exercise 10",
    "section": "Updating CRS information",
    "text": "Updating CRS information\n\nmpsz_svy21 &lt;- st_transform(mpsz, 3414)\n\n\nst_crs(mpsz_svy21)\n\n\nst_bbox(mpsz_svy21) #view extent"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10.html#aspatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex10.html#aspatial-data-wrangling",
    "title": "hands on exercise 10",
    "section": "Aspatial Data Wrangling",
    "text": "Aspatial Data Wrangling\n\nImporting the aspatial data\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\n\nglimpse(condo_resale)\n\n\nhead(condo_resale$LONGITUDE) #see the data in XCOORD column\n\n\nhead(condo_resale$LATITUDE) #see the data in YCOORD column\n\n\nsummary(condo_resale)\n\n\n\nConverting aspatial data frame into a sf object\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %&gt;%\n  st_transform(crs=3414)\n\n\nhead(condo_resale.sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex10.html#exploratory-data-analysis-eda",
    "title": "hands on exercise 10",
    "section": "Exploratory Data Analysis (EDA)",
    "text": "Exploratory Data Analysis (EDA)\n\nEDA using statistical graphics\n\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nThe figure above reveals a right skewed distribution. This means that more condominium units were transacted at relative lower prices.\nStatistically, the skewed dsitribution can be normalised by using log transformation. The code chunk below is used to derive a new variable called LOG_SELLING_PRICE by using a log transformation on the variable SELLING_PRICE. It is performed using mutate() of dplyr package.\n\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\nMultiple Histogram Plots distribution of variables\n\nAREA_SQM &lt;- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE &lt;- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)\n\n\n\nDrawing Statistical Point Map\n\ntmap_mode(\"view\")\n\n\ntmap_options(check.and.fix = TRUE) +\ntm_shape(mpsz_svy21)+\n  tm_polygons() +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +1\n  tm_view(set.zoom.limits = c(11,14))\n\nNotice that tm_dots() is used instead of tm_bubbles()."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10.html#hedonic-pricing-modelling-in-r",
    "href": "Hands-on_Ex/Hands-on_Ex10.html#hedonic-pricing-modelling-in-r",
    "title": "hands on exercise 10",
    "section": "Hedonic Pricing Modelling in R",
    "text": "Hedonic Pricing Modelling in R\n\nSimple Linear Regression Method\n\ncondo.slr &lt;- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\n\nsummary(condo.slr)\n\nThe artificial R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince p-value is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.\nThe Coefficients: section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\nMultiple Linear Regression Method\n\nVisualising the relationships of the independent variables\nBefore building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other. If these highly correlated independent variables are used in building a regression model by mistake, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. Beside the pairs() of R, there are many packages support the display of a correlation matrix. In this section, the corrplot package will be used.\nThe code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in condo_resale data.frame.\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\nMatrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, LEASE_99YEAR is excluded in the subsequent model building.\n\n\n\nBuilding a hedonic pricing model using multiple linear regression method\n\ncondo.mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\n\nPreparing Publication Quality Table: olsrr method\nNot all the independent variables are statistically significant. We will remove those variables not statistically significant.\n\ncondo.mlr1 &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n\n\nPreparing Publication Quality Table: gtsummary method\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\nmodel statistics can be included in the report by either appending them to the report table by using add_glance_table() or adding as a table source note by using add_glance_source_note() as shown in the code chunk below\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %&gt;% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\nChecking for multicollinearity\n\nols_vif_tol(condo.mlr1)\n\nSince the VIF of the independent variables are less than 10. We can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n\nTest for Non-Linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\n\nols_plot_resid_fit(condo.mlr1)\n\nThe figure above reveals that most of the data poitns are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\nTest for Normality Assumption\n\nols_plot_resid_hist(condo.mlr1)\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\n\nols_test_normality(condo.mlr1)\n\n\n\nTesting for Spatial Autocorrelation\nIn order to perform spatial autocorrelation test, we need to convert condo_resale.sf from sf data frame into a SpatialPointsDataFrame.\n\nmlr.output &lt;- as.data.frame(condo.mlr1$residuals)\n\n\ncondo_resale.res.sf &lt;- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %&gt;%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\n\ncondo_resale.sp &lt;- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\n\ntmap_mode(\"view\")\n\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\nTo prove that our observation is indeed true, the Moran’s I test will be performed\nFirst, we will compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\nnb &lt;- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNext, nb2listw() of spdep packge will be used to convert the output neighbours lists (i.e. nb) into a spatial weights.\n\n\nnb_lw &lt;- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nNext, lm.morantest() of spdep package will be used to perform Moran’s I test for residual spatial autocorrelation\n\nlm.morantest(condo.mlr1, nb_lw)\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.1424418 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08.html",
    "title": "Hands On Exercise 8",
    "section": "",
    "text": "pacman::p_load(BiocManager, spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)\n\n\n\n\n\nshan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"myanmar_township_boundaries\") %&gt;%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  select(c(2:7))\n\n\nshan_sf\n\n\n\n\nict &lt;- read_csv (\"data/aspatial/Shan-ICT.csv\")\nsummary(ict)\n\n\n\n\nThe unit of measurement of the values are number of household. Using these values directly will be bias by the underlying total number of households. In general, the townships with relatively higher total number of households will also have higher number of households owning radio, TV, etc.\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %&gt;%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\nsummary(ict_derived)\n\n\n\n\n\n\n\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nBoxplot is useful to detect if there are outliers.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\nBoxplot is useful to detect if there are outliers.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\nIn the figure below, multiple histograms are plotted to reveal the distribution of the selected variables in the ict_derived data.frame.\nThe code chunks below are used to create the data visualisation. They consist of two main parts. First, we will create the individual histograms using the code chunk below.\n\nradio &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ntv &lt;- ggplot(data=ict_derived, \n             aes(x= `TV_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nllphone &lt;- ggplot(data=ict_derived, \n             aes(x= `LLPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nmphone &lt;- ggplot(data=ict_derived, \n             aes(x= `MPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ncomputer &lt;- ggplot(data=ict_derived, \n             aes(x= `COMPUTER_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ninternet &lt;- ggplot(data=ict_derived, \n             aes(x= `INTERNET_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nNext, the ggarrange() function of ggpubr package is used to group these histograms together.\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)\n\n\n\n\n\n\nBefore we can prepare the choropleth map, we need to combine both the geospatial data object (i.e. shan_sf) and aspatial data.frame object (i.e. ict_derived) into one. This will be performed by using the left_join function of dplyr package. The shan_sf simple feature data.frame will be used as the base data object and the ict_derived data.frame will be used as the join table.\nThe code chunks below is used to perform the task. The unique identifier used to join both data objects is TS_PCODE.\nCombining both datasets.\n\nshan_sf &lt;- left_join(shan_sf, \n                     ict_derived, by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n  \nwrite_rds(shan_sf, \"data/rds/shan_sf.rds\")\n\n\nshan_sf &lt;- read_rds(\"data/rds/shan_sf.rds\")\n\n\n\n\nTo have a quick look at the distribution of Radio penetration rate of Shan State at township level, a choropleth map will be prepared.\nThe code chunks below are used to prepare the choroplethby using the qtm() function of tmap package.\n\nqtm(shan_sf, \"RADIO_PR\")\n\nWe will create two choropleth maps, one for the total number of households (i.e. TT_HOUSEHOLDS.map) and one for the total number of household with Radio (RADIO.map) to reveal the distribution.\n\nTT_HOUSEHOLDS.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp=NA, ncol=2)\n\nThe choropleth maps above clearly show that townships with relatively larger number ot households are also showing relatively higher number of radio ownership.\nPlotting the choropleth maps showing the dsitribution of total number of households and Radio penetration rate.\n\ntm_shape(shan_sf) +\n    tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n                style=\"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins=0, asp=0)\n\n\n\n\n\n\nBefore we perform cluster analysis, it is important for us to ensure that the cluster variables are not highly correlated.\n\ncluster_vars.cor = cor(ict_derived[,12:17])\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\nThe above shows that COMPUTER_PR and INTERNET_PR are highly correlated. This suggest that only one of them should be used in the cluster analysis.\n\n\n\nExtracting clustering variables\nThe code chunk below will be used to extract the clustering variables from the shan_sf simple feature object into data.frame.\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\nRemoved INTERNET_PR because it is highly correlated with COMPUTER_PR.\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n\nshan_ict &lt;- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n\n\nMultiple variables will be used in cluster analysis. In order to avoid the a result biased toward variables with large values, it is useful to standardise the input variables before performing cluster analysis.\n\n\n\n\nshan_ict.std &lt;- normalize(shan_ict)\nsummary(shan_ict.std)\n\n\n\n\n\nshan_ict.z &lt;- scale(shan_ict)\ndescribe(shan_ict.z)\n\nNotice the mean and standard deviation of the Z-score standardised clustering variables are 0 and 1 respectively.\nNote: describe() of psych package is used here instead of summary() of Base R because the earlier provides standard deviation.\nWarning: Z-score standardisation method should only be used if we would assume all variables come from some normal distribution.\n\n\n\nIt is also a good practice to visualise their distribution graphical.\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\ndist() supports six distance proximity calculations, they are: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is euclidean proximity matrix.\n\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\n\n\nproxmat\n\n\n\n\nhclust() employed agglomeration method to compute the cluster. Eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC).\nThe code chunk below performs hierarchical cluster analysis using ward.D method. The hierarchical clustering output is stored in an object of class hclust which describes the tree produced by the clustering process.\n\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\n\nplot(hclust_ward, cex = 0.6)\n\n\n\n\nOne of the challenge in performing hierarchical clustering is to identify stronger clustering structures. The issue can be resolved using use agnes() function of cluster package. It functions like hclus(), however, with the agnes() function you can also get the agglomerative coefficient, which measures the amount of clustering structure found (values closer to 1 suggest strong clustering structure).\nThe code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.\n\nm &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\nWard’s method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward’s method will be used.\n\n\n\nAnother technical challenge face by data analyst in performing clustering analysis is to determine the optimal clusters to retain.\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow Method\nAverage Silhouette Method\nGap Statistic Method\n\n\n\nThe gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.\n\nset.seed(12345)\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\n\nfviz_gap_stat(gap_stat)\n\nReferencing to the gap statistic graph above, the recommended number of cluster to retain is 1. However, the 6-cluster gives the largest gap statistic and should be the next best cluster to pick.\n\n\n\n\nIn the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.\nThe height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Note that, conclusions about the proximity of two observations can be drawn only based on the height where branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.\nIt’s also possible to draw the dendrogram with a border around the selected clusters by using rect.hclust() of R stats. The argument border is used to specify the border colors for the rectangles.\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\nWith heatmaply, we are able to build both highly interactive cluster heatmap or static cluster heatmap.\n\n\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap\n\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\n\n\n\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )\n\n\n\n\n\ncutree() of R Base will be used in the code chunk below to derive a 6-cluster model.\n\ngroups &lt;- as.factor(cutree(hclust_ward, k=6))\n\nThe output is called groups. It is a list object.\nIn order to visualise the clusters, the groups object need to be appended onto shan_sf simple feature object.\nThe code chunk below form the join in three steps:\n\nthe groups list object will be converted into a matrix;\ncbind() is used to append groups matrix onto shan_sf to produce an output simple feature object called shan_sf_cluster; and\nrename of dplyr package is used to rename as.matrix.groups field as CLUSTER.\n\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\nThe choropleth map above reveals the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08.html#getting-started",
    "title": "Hands On Exercise 8",
    "section": "",
    "text": "pacman::p_load(BiocManager, spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08.html#data-import-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex08.html#data-import-and-preparation",
    "title": "Hands On Exercise 8",
    "section": "",
    "text": "shan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"myanmar_township_boundaries\") %&gt;%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  select(c(2:7))\n\n\nshan_sf\n\n\n\n\nict &lt;- read_csv (\"data/aspatial/Shan-ICT.csv\")\nsummary(ict)\n\n\n\n\nThe unit of measurement of the values are number of household. Using these values directly will be bias by the underlying total number of households. In general, the townships with relatively higher total number of households will also have higher number of households owning radio, TV, etc.\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %&gt;%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\nsummary(ict_derived)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex08.html#exploratory-data-analysis-eda",
    "title": "Hands On Exercise 8",
    "section": "",
    "text": "ggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nBoxplot is useful to detect if there are outliers.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\nBoxplot is useful to detect if there are outliers.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\nIn the figure below, multiple histograms are plotted to reveal the distribution of the selected variables in the ict_derived data.frame.\nThe code chunks below are used to create the data visualisation. They consist of two main parts. First, we will create the individual histograms using the code chunk below.\n\nradio &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ntv &lt;- ggplot(data=ict_derived, \n             aes(x= `TV_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nllphone &lt;- ggplot(data=ict_derived, \n             aes(x= `LLPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nmphone &lt;- ggplot(data=ict_derived, \n             aes(x= `MPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ncomputer &lt;- ggplot(data=ict_derived, \n             aes(x= `COMPUTER_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ninternet &lt;- ggplot(data=ict_derived, \n             aes(x= `INTERNET_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nNext, the ggarrange() function of ggpubr package is used to group these histograms together.\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)\n\n\n\n\n\n\nBefore we can prepare the choropleth map, we need to combine both the geospatial data object (i.e. shan_sf) and aspatial data.frame object (i.e. ict_derived) into one. This will be performed by using the left_join function of dplyr package. The shan_sf simple feature data.frame will be used as the base data object and the ict_derived data.frame will be used as the join table.\nThe code chunks below is used to perform the task. The unique identifier used to join both data objects is TS_PCODE.\nCombining both datasets.\n\nshan_sf &lt;- left_join(shan_sf, \n                     ict_derived, by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n  \nwrite_rds(shan_sf, \"data/rds/shan_sf.rds\")\n\n\nshan_sf &lt;- read_rds(\"data/rds/shan_sf.rds\")\n\n\n\n\nTo have a quick look at the distribution of Radio penetration rate of Shan State at township level, a choropleth map will be prepared.\nThe code chunks below are used to prepare the choroplethby using the qtm() function of tmap package.\n\nqtm(shan_sf, \"RADIO_PR\")\n\nWe will create two choropleth maps, one for the total number of households (i.e. TT_HOUSEHOLDS.map) and one for the total number of household with Radio (RADIO.map) to reveal the distribution.\n\nTT_HOUSEHOLDS.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp=NA, ncol=2)\n\nThe choropleth maps above clearly show that townships with relatively larger number ot households are also showing relatively higher number of radio ownership.\nPlotting the choropleth maps showing the dsitribution of total number of households and Radio penetration rate.\n\ntm_shape(shan_sf) +\n    tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n                style=\"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins=0, asp=0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08.html#correlation-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex08.html#correlation-analysis",
    "title": "Hands On Exercise 8",
    "section": "",
    "text": "Before we perform cluster analysis, it is important for us to ensure that the cluster variables are not highly correlated.\n\ncluster_vars.cor = cor(ict_derived[,12:17])\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\nThe above shows that COMPUTER_PR and INTERNET_PR are highly correlated. This suggest that only one of them should be used in the cluster analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08.html#hierarchy-cluster-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex08.html#hierarchy-cluster-analysis",
    "title": "Hands On Exercise 8",
    "section": "",
    "text": "Extracting clustering variables\nThe code chunk below will be used to extract the clustering variables from the shan_sf simple feature object into data.frame.\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\nRemoved INTERNET_PR because it is highly correlated with COMPUTER_PR.\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n\nshan_ict &lt;- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n\n\nMultiple variables will be used in cluster analysis. In order to avoid the a result biased toward variables with large values, it is useful to standardise the input variables before performing cluster analysis.\n\n\n\n\nshan_ict.std &lt;- normalize(shan_ict)\nsummary(shan_ict.std)\n\n\n\n\n\nshan_ict.z &lt;- scale(shan_ict)\ndescribe(shan_ict.z)\n\nNotice the mean and standard deviation of the Z-score standardised clustering variables are 0 and 1 respectively.\nNote: describe() of psych package is used here instead of summary() of Base R because the earlier provides standard deviation.\nWarning: Z-score standardisation method should only be used if we would assume all variables come from some normal distribution.\n\n\n\nIt is also a good practice to visualise their distribution graphical.\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\ndist() supports six distance proximity calculations, they are: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is euclidean proximity matrix.\n\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\n\n\nproxmat\n\n\n\n\nhclust() employed agglomeration method to compute the cluster. Eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC).\nThe code chunk below performs hierarchical cluster analysis using ward.D method. The hierarchical clustering output is stored in an object of class hclust which describes the tree produced by the clustering process.\n\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\n\nplot(hclust_ward, cex = 0.6)\n\n\n\n\nOne of the challenge in performing hierarchical clustering is to identify stronger clustering structures. The issue can be resolved using use agnes() function of cluster package. It functions like hclus(), however, with the agnes() function you can also get the agglomerative coefficient, which measures the amount of clustering structure found (values closer to 1 suggest strong clustering structure).\nThe code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.\n\nm &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\nWard’s method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward’s method will be used.\n\n\n\nAnother technical challenge face by data analyst in performing clustering analysis is to determine the optimal clusters to retain.\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow Method\nAverage Silhouette Method\nGap Statistic Method\n\n\n\nThe gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.\n\nset.seed(12345)\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\n\nfviz_gap_stat(gap_stat)\n\nReferencing to the gap statistic graph above, the recommended number of cluster to retain is 1. However, the 6-cluster gives the largest gap statistic and should be the next best cluster to pick.\n\n\n\n\nIn the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.\nThe height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Note that, conclusions about the proximity of two observations can be drawn only based on the height where branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.\nIt’s also possible to draw the dendrogram with a border around the selected clusters by using rect.hclust() of R stats. The argument border is used to specify the border colors for the rectangles.\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\nWith heatmaply, we are able to build both highly interactive cluster heatmap or static cluster heatmap.\n\n\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap\n\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\n\n\n\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )\n\n\n\n\n\ncutree() of R Base will be used in the code chunk below to derive a 6-cluster model.\n\ngroups &lt;- as.factor(cutree(hclust_ward, k=6))\n\nThe output is called groups. It is a list object.\nIn order to visualise the clusters, the groups object need to be appended onto shan_sf simple feature object.\nThe code chunk below form the join in three steps:\n\nthe groups list object will be converted into a matrix;\ncbind() is used to append groups matrix onto shan_sf to produce an output simple feature object called shan_sf_cluster; and\nrename of dplyr package is used to rename as.matrix.groups field as CLUSTER.\n\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\nThe choropleth map above reveals the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "pacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex05.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 5",
    "section": "Visualising Regional Development Indicator",
    "text": "Visualising Regional Development Indicator\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\ngdppc &lt;- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 5",
    "section": "Computing Contiguity Spatial Weights",
    "text": "Computing Contiguity Spatial Weights\n\nComputing (QUEEN) contiguity based neighbours\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbour.\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, type:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\nWe can retrive the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\nComputing ROOK contiguity based neighbours\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connect area unit has 10 neighbours. There are two area units with only one neighbours.\n\n\nVisualising Contiguity Weights\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\n\ncoords &lt;- cbind(longitude, latitude)\n\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\nPlotting QUEEN contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"grey\")\n\n\n\n\n\n\n\n\n\n\nPlotting ROOK contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"grey\")\n\n\n\n\n\n\n\n\n\n\nPlotting QUEEN and ROOK contiguity based neighbours map\n\npar(mar = c(0,0,1,0),mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"grey\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"grey\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.html#computing-distance-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex05.html#computing-distance-based-neighbours",
    "title": "Hands-on Exercise 5",
    "section": "Computing Distance Based Neighbours",
    "text": "Computing Distance Based Neighbours\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\nComputing fixed distance weight matrix\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nQuiz: What is the meaning of “Average number of links: 3.681818” shown above?\n\nOn average, each region is connected to 3.681818 other regions in the distance weight matrix. i.e. if you randomly select a region, it will be expected to have approximately 3.68 neighboring regions within the specified distance threshold.\n\nNext, we will use str() to display the content of wm_d62 weight matrix.\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\nAnother way of displaying the structure ofthe weight matrix is to combine table() and card() of spdep.\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\nPlotting fixed distance weight matrix\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\n\nComputing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\nNotice that each county has six neighbours, no less no more\n\nPlotting distance based neighbours\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.html#weights-based-on-inverse-distance-weighted-idw",
    "href": "Hands-on_Ex/Hands-on_Ex05.html#weights-based-on-inverse-distance-weighted-idw",
    "title": "Hands-on Exercise 5",
    "section": "Weights based on Inverse Distance Weighted (IDW)",
    "text": "Weights based on Inverse Distance Weighted (IDW)\nFirst, we will compute the distances between areas by using nbdists() of spdep.\n\ndist &lt;- nbdists(wm_q, coords, longlat = TRUE)\nids &lt;- lapply(dist, function(x) 1/(x))\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05.html#row-standardised-weights-matrix",
    "title": "Hands-on Exercise 5",
    "section": "Row-standardised Weights Matrix",
    "text": "Row-standardised Weights Matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values.\nWhile this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data.\nFor this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error.\nTo see the weight of the first polygon’s eight neighbors type:\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nEach neighbor is assigned a 0.125 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.125 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix by using the code chunk below.\n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05.html#application-of-spatial-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05.html#application-of-spatial-weight-matrix",
    "title": "Hands-on Exercise 5",
    "section": "Application of Spatial Weight Matrix",
    "text": "Application of Spatial Weight Matrix\n\nSpatial lag with row-standardised weights\nwe’ll compute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nWe will retrieve the GDPPC values for the five neighboring regions of Anxiang county.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nWe can append the spatially lag GDPPC values onto hunan sf data frame by using the code chunk below.\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nWe will now look at a few values of the newly created column in hunan called lag GDPPC.\n\nhead(hunan)\n\nSimple feature collection with 6 features and 9 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3  County GDPPC     GIO    Agri Service lag GDPPC\n1 Changde 21098 Anxiang Anxiang 23667  5108.9 4524.41   14100  24847.20\n2 Changde 21100 Hanshou Hanshou 20981 13491.0 6545.35   17727  22724.80\n3 Changde 21101  Jinshi  Jinshi 34592 10935.0 2562.46    7525  24143.25\n4 Changde 21102      Li      Li 24473 18402.0 7562.34   53160  27737.50\n5 Changde 21103   Linli   Linli 25554  8214.0 3583.91    7031  27270.25\n6 Changde 21104  Shimen  Shimen 27137 17795.0 5266.51    6981  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nSpatial lag as a sum of neighbouring values\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist argument in the nb2listw function to explicitly assign these weights.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nNext, we will append the lag_sum GDPPC field into hunan dataframe by using left_join.\n\nhunan &lt;- left_join(hunan, lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nSpatial Window Average\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\n\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\n\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\n\nhunan %&gt;%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nSpatial window sum\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\n\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\n\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "The code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\nTwo data sets will be used to create the choropleth map.\n\nGEOSPATIAL: Master Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format [ data.gov.sg ]\nASPATIAL: Singapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). [ Department of Statistics, Singapore ]\n\n\n\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\jechaxu\\IS415-GAA\\Hands-on_Ex\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou may examine the contents of mpsz using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nWhen printing a large dataset, only a subset of the records is displayed by default to prevent an information overload. In this case, only 10 rows have been displayed.\n\n\n\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02.html#getting-started",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "The code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\nTwo data sets will be used to create the choropleth map.\n\nGEOSPATIAL: Master Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format [ data.gov.sg ]\nASPATIAL: Singapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). [ Department of Statistics, Singapore ]\n\n\n\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\jechaxu\\IS415-GAA\\Hands-on_Ex\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou may examine the contents of mpsz using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nWhen printing a large dataset, only a subset of the records is displayed by default to prevent an information overload. In this case, only 10 rows have been displayed.\n\n\n\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex02.html#data-wrangling",
    "title": "Hands-on Exercise 2",
    "section": "Data wrangling",
    "text": "Data wrangling\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6]) + rowSums(.[14])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:13]) +rowSums(.[15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\nThis code chunk filters the data for the year 2020, groups population data by certain categories and creates new calculated columns representing different age groups and economic activity. It also calculates a dependency ratio before outputting relevant columns.Joining the attribute data and geospatial data\nThis code chunk ensures that all values are in uppercase for consistency before joining the data.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nThis code chunk joins the geographical data and attribute table.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\nWhat is rds? -&gt; R also has two native data formats— Rdata and Rds. These formats are used when R objects are saved for later use. Rdata is used to save multiple R objects, while Rds is used to save a single R object."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 2",
    "section": "Choropleth Mapping Geospatial Data Using tmap",
    "text": "Choropleth Mapping Geospatial Data Using tmap\nThe code chunk below will draw a cartographic standard choropleth map.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\n\nCreating a choropleth map by using tmap’s elements\nTo draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.outside.size = 0.5,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\nDrawing a base map\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\nDrawing a choropleth map using tm_polygons()\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nBy default, missing values will be grey.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\ntm_borders is used to add the boundary of the planning subzones.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html#data-classification-methods-of-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02.html#data-classification-methods-of-tmap",
    "title": "Hands-on Exercise 2",
    "section": "Data classification methods of tmap",
    "text": "Data classification methods of tmap\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\n\nPlotting choropleth maps with built-in classification methods\nThe code chunk below shows a quantile data classification using 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\nQuantile Classification creates classes with an equal number of data points but potentially unequal intervals.\nEqual Classification creates classes with equal intervals but potentially unequal numbers of data points in each class.\n\n\n\nDIY\n\nJenks classification\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 5, style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\nJenks groups similar values together.\n\n\n\nStandard Deviation Classification\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 5, style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\nStandard Deviation shows how much each area deviates from the average.\n\n\n\nPreparing Choropleth Maps with Different Numbers of Classes\n2 classes\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 2, style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n6 classes\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 6, style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n10 classes\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 10, style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n20 classes\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", n = 20, style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n2 classes is simpler but lacks details.\n20 classes shows more detail but can become harder to interpret.\n\n\n\nPlotting choropleth map with custom breaks\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6519  0.7025  0.7742  0.7645 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.50, 0.60, 0.70, 0.80, and 0.90.\nWe also include minimum 0 and maximum 1.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.50, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n\n\n\n\n\nColour Schemes\n\nUsing ColourBrewer palette\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe map above is shaded in blue.\nTo reverse the colour shading, put a “-” in front.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html#map-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex02.html#map-layouts",
    "title": "Hands-on Exercise 2",
    "section": "Map Layouts",
    "text": "Map Layouts\n\nMap Legend\nIn tmap, legend options are provided to change the placement, format and appearance.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45,\n            legend.outside.size = 0.5,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nMap style\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\nCartographic Furniture\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.outside.size = 0.5,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nDrawing Small Multiple Choropleth Maps\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the aesthetic arguments,\nby faceting the map based on a categorical variable. each level of the variable is plotted in a separate map. [ tm_facet ]\nby creating multiple stand-alone maps with tmap_arrange().\n\n\nAssigning multiple values to at least one of the aesthetic arguments\nSmall choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nsmall multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nUsing tm_facets()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.units=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nUsing tmap_arrange()\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nMapping Spatial Object Meeting a Selection Criterion\nyou can use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.outside.size = 0.5,\n            legend.height = 0.45,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to IS415 Geospatial Analytics and Applications.\nIn this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Getting Started\nInstall and launching R packages\nThe code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(sf, tidyverse)\n\nThe code chunk below uses st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a polygon feature data frame.\n\nmpsz = st_read(dsn = \"data/geospatial\", \n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\jechaxu\\IS415-GAA\\Hands-on_Ex\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe code chunk below uses st_read() function of sf package to import CyclingPath shapefile into R as line feature data frame.\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                      layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\jechaxu\\IS415-GAA\\Hands-on_Ex\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThe PreSchoolsLocation is in kml format. The code chunk below will be used to import the kml into R.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\jechaxu\\IS415-GAA\\Hands-on_Ex\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe column in the sf data.frame that contains the geometries is a list, of class sfc. We can retrieve the geometry list-column in this case by mpsz$geom or mpsz[[1]], but the more general way uses st_geometry() as shown in the code chunk below.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\n\n\n\nOne of the common issue that can happen during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package as shown in the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in svy21 but when we read until the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414.\nIn order to assign the correct EPSG code to mpsz data frame, st_set_crs() of sf package is used as shown in the code chunk below.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG code is 3414 now.\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nLet us take preschool simple feature data frame as an example. The print below reveals that it is in wgs84 coordinate system.\nGeometry set for 2290 features  \nGeometry type: POINT \nDimension:     XYZ \nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134 \nz_range:       zmin: 0 zmax: 0 \nGeodetic CRS:  WGS 84 \nFirst 5 geometries:\nThis is a scenario that st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathemetically.\nLet us perform the projection transformation by using the code chunk below.\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\n\nSince listings data set is in csv file format, we will use read_csv() of readr package to import listing.csv as shown the code chunk below. The output R object is called listings and it is a tibble data frame.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3540 Columns: 75\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (26): listing_url, source, name, description, neighborhood_overview, pi...\ndbl  (38): id, scrape_id, host_id, host_listings_count, host_total_listings_...\nlgl   (6): host_is_superhost, host_has_profile_pic, host_identity_verified, ...\ndate  (5): last_scraped, host_since, calendar_last_scraped, first_review, la...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,540 × 75\n       id listing_url            scrape_id last_scraped source name  description\n    &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt; &lt;date&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      \n 1  71609 https://www.airbnb.co…   2.02e13 2024-06-29   previ… Ensu… For 3 room…\n 2  71896 https://www.airbnb.co…   2.02e13 2024-06-29   city … B&B … &lt;NA&gt;       \n 3  71903 https://www.airbnb.co…   2.02e13 2024-06-29   city … Room… Like your …\n 4 275343 https://www.airbnb.co…   2.02e13 2024-06-29   city … 10mi… **IMPORTAN…\n 5 275344 https://www.airbnb.co…   2.02e13 2024-06-29   city … 15 m… Lovely hom…\n 6 289234 https://www.airbnb.co…   2.02e13 2024-06-29   previ… Book… This whole…\n 7 294281 https://www.airbnb.co…   2.02e13 2024-06-29   city … 5 mi… I have 3 b…\n 8 324945 https://www.airbnb.co…   2.02e13 2024-06-29   city … Comf… **IMPORTAN…\n 9 330095 https://www.airbnb.co…   2.02e13 2024-06-29   city … Rela… **IMPORTAN…\n10 344803 https://www.airbnb.co…   2.02e13 2024-06-29   city … Budg… Direct bus…\n# ℹ 3,530 more rows\n# ℹ 68 more variables: neighborhood_overview &lt;chr&gt;, picture_url &lt;chr&gt;,\n#   host_id &lt;dbl&gt;, host_url &lt;chr&gt;, host_name &lt;chr&gt;, host_since &lt;date&gt;,\n#   host_location &lt;chr&gt;, host_about &lt;chr&gt;, host_response_time &lt;chr&gt;,\n#   host_response_rate &lt;chr&gt;, host_acceptance_rate &lt;chr&gt;,\n#   host_is_superhost &lt;lgl&gt;, host_thumbnail_url &lt;chr&gt;, host_picture_url &lt;chr&gt;,\n#   host_neighbourhood &lt;chr&gt;, host_listings_count &lt;dbl&gt;, …\n\n\nThe code chunk below converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 74\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.024063e+13, 2.024063e+1…\n$ last_scraped                                 &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ source                                       &lt;chr&gt; \"previous scrape\", \"city …\n$ name                                         &lt;chr&gt; \"Ensuite Room (Room 1 & 2…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1 …\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within an hour\", \"within…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"N/A\", \"N/A\", \"N/A\", \"99%…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ host_total_listings_count                    &lt;dbl&gt; 11, 11, 11, 73, 73, 11, 8…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 3, 1, 2, 1, 1, 4, 2, 1, 1…\n$ bathrooms                                    &lt;dbl&gt; NA, 0.5, 0.5, 2.0, 2.5, N…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; 2, 1, 1, 1, 1, 3, 2, 1, 1…\n$ beds                                         &lt;dbl&gt; NA, 1, 2, 1, 1, NA, 1, 1,…\n$ amenities                                    &lt;chr&gt; \"[\\\"Free parking on premi…\n$ price                                        &lt;chr&gt; NA, \"$80.00\", \"$80.00\", \"…\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 30, 30, 30, 28, 0, 29, 30…\n$ availability_60                              &lt;dbl&gt; 59, 53, 60, 58, 0, 58, 60…\n$ availability_90                              &lt;dbl&gt; 89, 83, 90, 62, 0, 88, 90…\n$ availability_365                             &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 3…\n$ calendar_last_scraped                        &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ number_of_reviews                            &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 1…\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 6, 49…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…\n\n\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\nwe will plot a histogram to reveal the distribution of PreSch Density. Conventionally, hist() of R Graphics will be used as shown in the code chunk below.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\n\n\nDIY: Using ggplot2 method, plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "In this exercise, we will use the following datasets:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from Data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format.\n\n\n\n\ninstall.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse, maptools, sp)\n\n\nmpsz_sf &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\jechaxu\\IS415-GAA\\Hands-on_Ex\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\n\nchildcare_sf &lt;- st_read(\"data/aspatial/child-care-services-geojson.geojson\") %&gt;% st_transform(crs =3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\jechaxu\\IS415-GAA\\Hands-on_Ex\\data\\aspatial\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\jechaxu\\IS415-GAA\\Hands-on_Ex\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nsg_sf &lt;- st_read(dsn = \"data/geospatial\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\jechaxu\\IS415-GAA\\Hands-on_Ex\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\n\n\n\nDIY: Using the method you learned in Lesson 2, assign the correct crs to mpsz_sf and sg_sf simple feature data frames.\n\nchildcare_sf &lt;- st_transform(childcare_sf, crs = 3414)\nmpsz_sf &lt;- st_transform(mpsz_sf, crs = 3414)\n\n\n\nDIY: Using the mapping methods you learned in Hands-on Exercise 3, prepare a map as shown below.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\n# tmap_mode('plot')\n# edited: interactive mode causes rendering to take a long time, hence i have commented it out\n\nNotice that at the interactive mode, tmap is using leaflet for R API. The advantage of this interactive pin map is it allows us to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, you can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\n\nReminder: Always remember to switch back to plot mode after the interactive map. This is because, each interactive mode will consume a connection. You should also avoid displaying ecessive numbers of interactive maps (i.e. not more than 10) in one RMarkdown document when publish on Netlify.\n\n\n\n\n\n\n\nThe code chunk below uses as_Spatial() of sf package to convert the three geospatial data from simple feature data frame to sp’s Spatial* class.\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\nDIY: Using appropriate function, display the information of these three Spatial* classes as shown below.\n\nsummary(childcare)\n\nObject of class SpatialPointsDataFrame\nCoordinates:\n               min      max\ncoords.x1 11203.01 45404.24\ncoords.x2 25667.60 49300.88\ncoords.x3     0.00     0.00\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0\n+units=m +no_defs]\nNumber of points: 1545\nData attributes:\n     Name           Description       \n Length:1545        Length:1545       \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n\n\n\nsummary(mpsz)\n\nObject of class SpatialPolygonsDataFrame\nCoordinates:\n        min      max\nx  2667.538 56396.44\ny 15748.721 50256.33\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0\n+units=m +no_defs]\nData attributes:\n    OBJECTID       SUBZONE_NO      SUBZONE_N          SUBZONE_C        \n Min.   :  1.0   Min.   : 1.000   Length:323         Length:323        \n 1st Qu.: 81.5   1st Qu.: 2.000   Class :character   Class :character  \n Median :162.0   Median : 4.000   Mode  :character   Mode  :character  \n Mean   :162.0   Mean   : 4.625                                        \n 3rd Qu.:242.5   3rd Qu.: 6.500                                        \n Max.   :323.0   Max.   :17.000                                        \n    CA_IND           PLN_AREA_N         PLN_AREA_C          REGION_N        \n Length:323         Length:323         Length:323         Length:323        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   REGION_C           INC_CRC            FMEL_UPD_D             X_ADDR     \n Length:323         Length:323         Min.   :2014-12-05   Min.   : 5093  \n Class :character   Class :character   1st Qu.:2014-12-05   1st Qu.:21864  \n Mode  :character   Mode  :character   Median :2014-12-05   Median :28465  \n                                       Mean   :2014-12-05   Mean   :27257  \n                                       3rd Qu.:2014-12-05   3rd Qu.:31674  \n                                       Max.   :2014-12-05   Max.   :50425  \n     Y_ADDR        SHAPE_Leng        SHAPE_Area      \n Min.   :19579   Min.   :  871.5   Min.   :   39438  \n 1st Qu.:31776   1st Qu.: 3709.6   1st Qu.:  628261  \n Median :35113   Median : 5211.9   Median : 1229894  \n Mean   :36106   Mean   : 6524.4   Mean   : 2420882  \n 3rd Qu.:39869   3rd Qu.: 6942.6   3rd Qu.: 2106483  \n Max.   :49553   Max.   :68083.9   Max.   :69748299  \n\n\n\nsummary(sg)\n\nObject of class SpatialPolygonsDataFrame\nCoordinates:\n        min      max\nx  2663.926 56047.79\ny 16357.981 50244.03\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs]\nData attributes:\n    GDO_GID          MSLINK          MAPID    COSTAL_NAM       \n Min.   : 1.00   Min.   : 1.00   Min.   :0   Length:60         \n 1st Qu.:15.75   1st Qu.:17.75   1st Qu.:0   Class :character  \n Median :30.50   Median :33.50   Median :0   Mode  :character  \n Mean   :30.50   Mean   :33.77   Mean   :0                     \n 3rd Qu.:45.25   3rd Qu.:49.25   3rd Qu.:0                     \n Max.   :60.00   Max.   :67.00   Max.   :0                     \n\n\n\n\nspatstat requires the data in ppp object form. We need to convert the Spatial classes* into Spatial object first, then into ppp.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\n\nchildcare_ppp &lt;- as.ppp(st_coordinates(childcare_sf), st_bbox(childcare_sf))\n\nWarning: data contain duplicated points\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0       0       0       0       0       0 \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nNotice the warning message about duplicates. In spatial point patterns analysis, a significant issue is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident.\n\n\n\nWe can check the duplication in a ppp object by using the code chunk below.\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nTo count the number of co-indicence point, we will use the multiplicity() function.\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\nIf we want to know how many locations have more than one point event, we can use the code chunk below.\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 128\n\n\nThe output shows that there are 128 duplicated point events.\nTo view the locations of these duplicate point events, we will plot childcare data\n\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\n\n\nChallenge: Do you know how to spot the duplicate points from the map shown above?\n\nSome points have a greater opacity than the others, indicating that there are overlaps.\nThere are three ways to overcome this problem. The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nDIY: Using the method you learned in previous section, check if there are any duplicated points in this geospatial data.\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\n\n\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\n\nsg_owin &lt;- as.owin(sg_sf)\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n\n\nThis code chunk will extract childcare events that are located within Singapore.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0       0       0       0       0       0 \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nDIY: Using the method you learned in previous exercise, plot the newly derived childcareSG_ppp as shown below.\n\nplot(childcareSG_ppp)\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to perform first-order SPPA by using spatstat package. The hands-on exercise will focus on:\n\nderiving kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes,\nperforming Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics.\n\n\n\nThe code chunk below computes a kernel density by using the following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\nThe default smoothing kernel used is gaussian. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nAnalyzing from the output map above, the density values of the output range from 0 to 0.000035 which is way too small to comprehend. This is because the default unit of measurement of SVY21 is in meter.\nrescale() function of spatstat converts the unit of measurement from meter to kilometer.\n\nchildcareSG_ppp.km &lt;- rescale(childcareSG_ppp, 1000, \"km\")\n\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\nThe changes can only be seen on the legend. The output image has virtually no difference.\n\n\n\nBesides bw.diggle(), there are three other spatstat functions can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\n\nbw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because in ther experience it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of once study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\nThe code chunk beow will be used to compare the output of using bw.diggle and bw.ppl methods.\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\nIf you zoom in, you can tell a difference between the level of smoothing. undefinedThe bw.ppl method typically selects a smaller bandwidth than the bw.diggle method, resulting in a more detailed and localized KDE.\n\n\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics.\n\npar(mfrow = c(2,2))\npar(mar = c(3,2,2,1))\n\nplot(density(childcareSG_ppp.km, \n             sigma = bw.ppl, \n             edge = TRUE, \n             kernel = \"gaussian\"), \n     main = \"Gaussian\")\n\nplot(density(childcareSG_ppp.km, \n             sigma = bw.ppl, \n             edge = TRUE, \n             kernel = \"epanechnikov\"), \n     main = \"Epanechnikov\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma = bw.ppl, \n             edge = TRUE, \n             kernel = \"quartic\"), \n     main = \"Quartic\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma = bw.ppl, \n             edge = TRUE, \n             kernel = \"disc\"), \n     main = \"Disc\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\n\n\n\n\nFixed bandwidth method is very sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\n\nConversion of KDE output into a grid object can be done to make it compatible with mapping applications. It is important to note that the result remains unchanged.\n\ngridded_kde_childcareSG_bw &lt;- as.SpatialGridDataFrame.im(kde_childcareSG.bw)\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nConverting gridded output into raster\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nAssigning projection systems\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\n\n\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\nlegend.postion is used for plot mode. Use view.legend.position in tm_view to set the legend position in view mode.\n\n\n\n\n\n\n\n\n\nExtracting study area\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Punggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\n\nWarning: Berman-Diggle Cross-Validation criterion was minimised at right-hand\nend of interval [0, 0.281]; use argument 'hmax' to specify a wider interval for\nbandwidth 'sigma'\n\n\n\n\n\n\n\n\n\nComputing fixed bandwidth KDE\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat.\nThe test hypotheses are:\nHo = The distribution of childcare services are randomly distributed.\nH1= The distribution of childcare services are not randomly distributed.\nThe 95% confident interval will be used.\n\n\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\nR = 0.55631: The R value is significantly less than 1, indicating clustering.\np-value &lt; 2.2e-16: The p-value is very small, which means that the observed clustering is highly unlikely to be due to chance.\n\nThe childcare centers in Singapore are clustered, meaning that they are located closer together than would be expected.\n\n\n\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.96048, p-value = 0.5549\nalternative hypothesis: two-sided\n\n\n\n\n\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.80243, p-value = 0.0003628\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#getting-started",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "In this exercise, we will use the following datasets:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from Data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format.\n\n\n\n\ninstall.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse, maptools, sp)\n\n\nmpsz_sf &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\jechaxu\\IS415-GAA\\Hands-on_Ex\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\n\nchildcare_sf &lt;- st_read(\"data/aspatial/child-care-services-geojson.geojson\") %&gt;% st_transform(crs =3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\jechaxu\\IS415-GAA\\Hands-on_Ex\\data\\aspatial\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\jechaxu\\IS415-GAA\\Hands-on_Ex\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nsg_sf &lt;- st_read(dsn = \"data/geospatial\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\jechaxu\\IS415-GAA\\Hands-on_Ex\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#spatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#spatial-data-wrangling",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "DIY: Using the method you learned in Lesson 2, assign the correct crs to mpsz_sf and sg_sf simple feature data frames.\n\nchildcare_sf &lt;- st_transform(childcare_sf, crs = 3414)\nmpsz_sf &lt;- st_transform(mpsz_sf, crs = 3414)\n\n\n\nDIY: Using the mapping methods you learned in Hands-on Exercise 3, prepare a map as shown below.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\n# tmap_mode('plot')\n# edited: interactive mode causes rendering to take a long time, hence i have commented it out\n\nNotice that at the interactive mode, tmap is using leaflet for R API. The advantage of this interactive pin map is it allows us to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, you can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\n\nReminder: Always remember to switch back to plot mode after the interactive map. This is because, each interactive mode will consume a connection. You should also avoid displaying ecessive numbers of interactive maps (i.e. not more than 10) in one RMarkdown document when publish on Netlify."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "The code chunk below uses as_Spatial() of sf package to convert the three geospatial data from simple feature data frame to sp’s Spatial* class.\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\nDIY: Using appropriate function, display the information of these three Spatial* classes as shown below.\n\nsummary(childcare)\n\nObject of class SpatialPointsDataFrame\nCoordinates:\n               min      max\ncoords.x1 11203.01 45404.24\ncoords.x2 25667.60 49300.88\ncoords.x3     0.00     0.00\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0\n+units=m +no_defs]\nNumber of points: 1545\nData attributes:\n     Name           Description       \n Length:1545        Length:1545       \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n\n\n\nsummary(mpsz)\n\nObject of class SpatialPolygonsDataFrame\nCoordinates:\n        min      max\nx  2667.538 56396.44\ny 15748.721 50256.33\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0\n+units=m +no_defs]\nData attributes:\n    OBJECTID       SUBZONE_NO      SUBZONE_N          SUBZONE_C        \n Min.   :  1.0   Min.   : 1.000   Length:323         Length:323        \n 1st Qu.: 81.5   1st Qu.: 2.000   Class :character   Class :character  \n Median :162.0   Median : 4.000   Mode  :character   Mode  :character  \n Mean   :162.0   Mean   : 4.625                                        \n 3rd Qu.:242.5   3rd Qu.: 6.500                                        \n Max.   :323.0   Max.   :17.000                                        \n    CA_IND           PLN_AREA_N         PLN_AREA_C          REGION_N        \n Length:323         Length:323         Length:323         Length:323        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   REGION_C           INC_CRC            FMEL_UPD_D             X_ADDR     \n Length:323         Length:323         Min.   :2014-12-05   Min.   : 5093  \n Class :character   Class :character   1st Qu.:2014-12-05   1st Qu.:21864  \n Mode  :character   Mode  :character   Median :2014-12-05   Median :28465  \n                                       Mean   :2014-12-05   Mean   :27257  \n                                       3rd Qu.:2014-12-05   3rd Qu.:31674  \n                                       Max.   :2014-12-05   Max.   :50425  \n     Y_ADDR        SHAPE_Leng        SHAPE_Area      \n Min.   :19579   Min.   :  871.5   Min.   :   39438  \n 1st Qu.:31776   1st Qu.: 3709.6   1st Qu.:  628261  \n Median :35113   Median : 5211.9   Median : 1229894  \n Mean   :36106   Mean   : 6524.4   Mean   : 2420882  \n 3rd Qu.:39869   3rd Qu.: 6942.6   3rd Qu.: 2106483  \n Max.   :49553   Max.   :68083.9   Max.   :69748299  \n\n\n\nsummary(sg)\n\nObject of class SpatialPolygonsDataFrame\nCoordinates:\n        min      max\nx  2663.926 56047.79\ny 16357.981 50244.03\nIs projected: TRUE \nproj4string :\n[+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1\n+x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs]\nData attributes:\n    GDO_GID          MSLINK          MAPID    COSTAL_NAM       \n Min.   : 1.00   Min.   : 1.00   Min.   :0   Length:60         \n 1st Qu.:15.75   1st Qu.:17.75   1st Qu.:0   Class :character  \n Median :30.50   Median :33.50   Median :0   Mode  :character  \n Mean   :30.50   Mean   :33.77   Mean   :0                     \n 3rd Qu.:45.25   3rd Qu.:49.25   3rd Qu.:0                     \n Max.   :60.00   Max.   :67.00   Max.   :0                     \n\n\n\n\nspatstat requires the data in ppp object form. We need to convert the Spatial classes* into Spatial object first, then into ppp.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\n\nchildcare_ppp &lt;- as.ppp(st_coordinates(childcare_sf), st_bbox(childcare_sf))\n\nWarning: data contain duplicated points\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0       0       0       0       0       0 \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nNotice the warning message about duplicates. In spatial point patterns analysis, a significant issue is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident.\n\n\n\nWe can check the duplication in a ppp object by using the code chunk below.\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nTo count the number of co-indicence point, we will use the multiplicity() function.\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\nIf we want to know how many locations have more than one point event, we can use the code chunk below.\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 128\n\n\nThe output shows that there are 128 duplicated point events.\nTo view the locations of these duplicate point events, we will plot childcare data\n\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\n\n\nChallenge: Do you know how to spot the duplicate points from the map shown above?\n\nSome points have a greater opacity than the others, indicating that there are overlaps.\nThere are three ways to overcome this problem. The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nDIY: Using the method you learned in previous section, check if there are any duplicated points in this geospatial data.\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\n\n\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\n\nsg_owin &lt;- as.owin(sg_sf)\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n\n\nThis code chunk will extract childcare events that are located within Singapore.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0       0       0       0       0       0 \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nDIY: Using the method you learned in previous exercise, plot the newly derived childcareSG_ppp as shown below.\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "In this section, you will learn how to perform first-order SPPA by using spatstat package. The hands-on exercise will focus on:\n\nderiving kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes,\nperforming Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics.\n\n\n\nThe code chunk below computes a kernel density by using the following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\nThe default smoothing kernel used is gaussian. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nAnalyzing from the output map above, the density values of the output range from 0 to 0.000035 which is way too small to comprehend. This is because the default unit of measurement of SVY21 is in meter.\nrescale() function of spatstat converts the unit of measurement from meter to kilometer.\n\nchildcareSG_ppp.km &lt;- rescale(childcareSG_ppp, 1000, \"km\")\n\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\nThe changes can only be seen on the legend. The output image has virtually no difference.\n\n\n\nBesides bw.diggle(), there are three other spatstat functions can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\n\nbw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because in ther experience it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of once study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\nThe code chunk beow will be used to compare the output of using bw.diggle and bw.ppl methods.\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\nIf you zoom in, you can tell a difference between the level of smoothing. undefinedThe bw.ppl method typically selects a smaller bandwidth than the bw.diggle method, resulting in a more detailed and localized KDE.\n\n\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics.\n\npar(mfrow = c(2,2))\npar(mar = c(3,2,2,1))\n\nplot(density(childcareSG_ppp.km, \n             sigma = bw.ppl, \n             edge = TRUE, \n             kernel = \"gaussian\"), \n     main = \"Gaussian\")\n\nplot(density(childcareSG_ppp.km, \n             sigma = bw.ppl, \n             edge = TRUE, \n             kernel = \"epanechnikov\"), \n     main = \"Epanechnikov\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma = bw.ppl, \n             edge = TRUE, \n             kernel = \"quartic\"), \n     main = \"Quartic\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma = bw.ppl, \n             edge = TRUE, \n             kernel = \"disc\"), \n     main = \"Disc\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#fixed-and-adaptive-kde",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#fixed-and-adaptive-kde",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "Notice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\n\n\n\n\nFixed bandwidth method is very sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\n\nConversion of KDE output into a grid object can be done to make it compatible with mapping applications. It is important to note that the result remains unchanged.\n\ngridded_kde_childcareSG_bw &lt;- as.SpatialGridDataFrame.im(kde_childcareSG.bw)\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nConverting gridded output into raster\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nAssigning projection systems\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\n\n\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\nlegend.postion is used for plot mode. Use view.legend.position in tm_view to set the legend position in view mode.\n\n\n\n\n\n\n\n\n\nExtracting study area\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Punggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\n\nWarning: Berman-Diggle Cross-Validation criterion was minimised at right-hand\nend of interval [0, 0.281]; use argument 'hmax' to specify a wider interval for\nbandwidth 'sigma'\n\n\n\n\n\n\n\n\n\nComputing fixed bandwidth KDE\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#nearest-neighbour-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#nearest-neighbour-analysis",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "In this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat.\nThe test hypotheses are:\nHo = The distribution of childcare services are randomly distributed.\nH1= The distribution of childcare services are not randomly distributed.\nThe 95% confident interval will be used.\n\n\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\nR = 0.55631: The R value is significantly less than 1, indicating clustering.\np-value &lt; 2.2e-16: The p-value is very small, which means that the observed clustering is highly unlikely to be due to chance.\n\nThe childcare centers in Singapore are clustered, meaning that they are located closer together than would be expected.\n\n\n\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.96048, p-value = 0.5549\nalternative hypothesis: two-sided\n\n\n\n\n\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.80243, p-value = 0.0003628\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-f-function",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-f-function",
    "title": "Hands-on Exercise 3",
    "section": "Analysing Spatial Point Process Using F-Function",
    "text": "Analysing Spatial Point Process Using F-Function\nThe F function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape. In this section, you will learn how to compute F-function estimation by using Fest() of spatstat package. You will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\n\nChoa Chu Kang planning area\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\n\n\nTampines planning area\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-k-function",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-k-function",
    "title": "Hands-on Exercise 3",
    "section": "Analysing Spatial Point Process Using K-Function",
    "text": "Analysing Spatial Point Process Using K-Function\nK-function measures the number of events found up to a given distance of any particular event. In this section, you will learn how to compute K-function estimates by using Kest() of spatstat package. You will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\n\nChoa Chu Kang planning area\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, global=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\nTampines planning area\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, global=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-l-function",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-l-function",
    "title": "Hands-on Exercise 3",
    "section": "Analysing Spatial Point Process Using L-Function",
    "text": "Analysing Spatial Point Process Using L-Function\n\nChoa Chu Kang planning area\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, global=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n\n\n\nTampines planning area\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, global=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06.html",
    "title": "Hands on exercise 6",
    "section": "",
    "text": "pacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n\n\n\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\jechaxu\\IS415-GAA\\Hands-on_Ex\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  dplyr::select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\n\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep.\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nQuestion: What statistical conclustion can you draw from the output above?\n\nThere is a significant positive spatial autocorrelation in the GDP per capita data across the Hunan region. This suggests that neighboring regions tend to have similar levels of GDP per capita, which could be due to factors such as geographical proximity.\n\n\n\n\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\n\n\n\nQuestion: What statistical observation can you draw from the output above?\n\nthe observed value appears to be significantly different from the simulated values. This suggests that there is strong evidence of positive spatial autocorrelation in the data.\n\n\n\n\n\n\n\nThe code chunk below performs Geary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n\n\nThe code chunk below performs permutation test for Geary’s C statistic by using geary.mc() of spdep.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\nA low value of Geary’s C indicates a positive spatial autocorrelation, thus implying that neighbouring regions tend to have similar levels of GDP per capita\n\n\n\n\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\nBy plotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06.html#getting-started",
    "title": "Hands on exercise 6",
    "section": "",
    "text": "pacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06.html#importing-data-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex06.html#importing-data-into-r-environment",
    "title": "Hands on exercise 6",
    "section": "",
    "text": "hunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\jechaxu\\IS415-GAA\\Hands-on_Ex\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  dplyr::select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-1",
    "href": "Hands-on_Ex/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-1",
    "title": "Hands on exercise 6",
    "section": "",
    "text": "wm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\n\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-morans-i",
    "title": "Hands on exercise 6",
    "section": "",
    "text": "The code chunk below performs Moran’s I statistical testing using moran.test() of spdep.\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nQuestion: What statistical conclustion can you draw from the output above?\n\nThere is a significant positive spatial autocorrelation in the GDP per capita data across the Hunan region. This suggests that neighboring regions tend to have similar levels of GDP per capita, which could be due to factors such as geographical proximity.\n\n\n\n\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\n\n\n\nQuestion: What statistical observation can you draw from the output above?\n\nthe observed value appears to be significantly different from the simulated values. This suggests that there is strong evidence of positive spatial autocorrelation in the data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "title": "Hands on exercise 6",
    "section": "",
    "text": "The code chunk below performs Geary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n\n\nThe code chunk below performs permutation test for Geary’s C statistic by using geary.mc() of spdep.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\nA low value of Geary’s C indicates a positive spatial autocorrelation, thus implying that neighbouring regions tend to have similar levels of GDP per capita\n\n\n\n\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex06.html#spatial-correlogram",
    "title": "Hands on exercise 6",
    "section": "",
    "text": "MI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\nBy plotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06.html#creating-a-lisa-cluster-map",
    "href": "Hands-on_Ex/Hands-on_Ex06.html#creating-a-lisa-cluster-map",
    "title": "Hands on exercise 6",
    "section": "Creating a LISA Cluster Map",
    "text": "Creating a LISA Cluster Map\nThe LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.\n\nPlotting Moran Scatterplot\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\nPlotting Moran scatterplot with standardised variable\nWe will use scale() to center and scale the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \n\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\nPreparing LISA map classes\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\nderive the spatially lagged variable of interest (i.e. GDPPC) and center the spatially lagged variable around its mean.\n\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \n\ncentering the local Moran’s around the mean.\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\n\nsignif &lt;- 0.05\n\n\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4      \n\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\n\n\nPlotting LISA map\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06.html#hot-spot-and-cold-spot-area-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06.html#hot-spot-and-cold-spot-area-analysis",
    "title": "Hands on exercise 6",
    "section": "Hot Spot and Cold Spot Area Analysis",
    "text": "Hot Spot and Cold Spot Area Analysis\nBeside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.\nThe term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).\n\nGetis and Ord’s G-Statistics\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics\n\n\n\nDeriving distance-based weight matrix\nFirst, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\n\nDeriving the centroid\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid(). We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid() function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\n\ncoords &lt;- cbind(longitude, latitude)\n\n\n\nDetermine the cut-off distance\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\nComputing fixed distance weight matrix\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\n\n\nComputing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06.html#computing-gi-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex06.html#computing-gi-statistics",
    "title": "Hands on exercise 6",
    "section": "Computing Gi statistics",
    "text": "Computing Gi statistics\n\nGi statistics using fixed distance\n\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding hunan sf data frame by using the code chunk below.\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nIn fact, the code chunk above performs three tasks. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join hunan@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().\n\n\nMapping Gi values with fixed distance weights\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\nGi statistics using adaptive distance\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\nMapping Gi values with adaptive distance weights\n\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html",
    "href": "Hands-on_Ex/Hands-on_Ex09.html",
    "title": "hands on exercise 9",
    "section": "",
    "text": "pacman::p_load(BiocManager, spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)\n\n\n\n\n\nshan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"myanmar_township_boundaries\") %&gt;%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  select(c(2:7))\n\nReading layer `myanmar_township_boundaries' from data source \n  `C:\\jechaxu\\IS415-GAA\\Hands-on_Ex\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\n\nshan_sf\n\nSimple feature collection with 55 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 96.15107 ymin: 19.29932 xmax: 101.1699 ymax: 24.15907\nGeodetic CRS:  WGS 84\nFirst 10 features:\n             ST ST_PCODE       DT   DT_PCODE        TS  TS_PCODE\n1  Shan (North)   MMR015  Mongmit MMR015D008   Mongmit MMR015017\n2  Shan (South)   MMR014 Taunggyi MMR014D001   Pindaya MMR014006\n3  Shan (South)   MMR014 Taunggyi MMR014D001   Ywangan MMR014007\n4  Shan (South)   MMR014 Taunggyi MMR014D001  Pinlaung MMR014009\n5  Shan (North)   MMR015  Mongmit MMR015D008    Mabein MMR015018\n6  Shan (South)   MMR014 Taunggyi MMR014D001     Kalaw MMR014005\n7  Shan (South)   MMR014 Taunggyi MMR014D001     Pekon MMR014010\n8  Shan (South)   MMR014 Taunggyi MMR014D001  Lawksawk MMR014008\n9  Shan (North)   MMR015  Kyaukme MMR015D003 Nawnghkio MMR015013\n10 Shan (North)   MMR015  Kyaukme MMR015D003   Kyaukme MMR015012\n                         geometry\n1  MULTIPOLYGON (((96.96001 23...\n2  MULTIPOLYGON (((96.7731 21....\n3  MULTIPOLYGON (((96.78483 21...\n4  MULTIPOLYGON (((96.49518 20...\n5  MULTIPOLYGON (((96.66306 24...\n6  MULTIPOLYGON (((96.49518 20...\n7  MULTIPOLYGON (((97.14738 19...\n8  MULTIPOLYGON (((96.94981 22...\n9  MULTIPOLYGON (((96.75648 22...\n10 MULTIPOLYGON (((96.95498 22...\n\n\n\nict &lt;- read_csv (\"data/aspatial/Shan-ICT.csv\")\n\nRows: 55 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): District Pcode, District Name, Township Pcode, Township Name\ndbl (7): Total households, Radio, Television, Land line phone, Mobile phone,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsummary(ict)\n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %&gt;%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\nsummary(ict_derived)\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 21.05  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:138.95  \n Median : 3559   Median : 244.0   Median : 316.0   Median :210.95  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :215.68  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:268.07  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :484.52  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :116.0   Min.   :  2.78   Min.   : 36.42   Min.   : 3.278  \n 1st Qu.:450.2   1st Qu.: 22.84   1st Qu.:190.14   1st Qu.:11.832  \n Median :517.2   Median : 37.59   Median :305.27   Median :18.970  \n Mean   :509.5   Mean   : 51.09   Mean   :314.05   Mean   :24.393  \n 3rd Qu.:606.4   3rd Qu.: 69.72   3rd Qu.:428.43   3rd Qu.:29.897  \n Max.   :842.5   Max.   :181.49   Max.   :735.43   Max.   :92.402  \n  INTERNET_PR     \n Min.   :  1.041  \n 1st Qu.:  8.617  \n Median : 22.829  \n Mean   : 30.644  \n 3rd Qu.: 41.281  \n Max.   :117.985  \n\n\n\nshan_sf &lt;- left_join(shan_sf, \n                     ict_derived, by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n  \nwrite_rds(shan_sf, \"data/rds/shan_sf.rds\")\n\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\n\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\nshan_ict &lt;- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n   RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1  286.1852 554.1313   35.30618  260.6944    12.15939\n2  417.4647 505.1300   19.83584  162.3917    12.88190\n3  484.5215 260.5734   11.93591  120.2856     4.41465\n4  231.6499 541.7189   28.54454  249.4903    13.76255\n5  449.4903 708.6423   72.75255  392.6089    16.45042\n6  280.7624 611.6204   42.06478  408.7951    29.63160\n7  318.6118 535.8494   39.83270  214.8476    18.97032\n8  387.1017 630.0035   31.51366  320.5686    21.76677\n9  349.3359 547.9456   38.44960  323.0201    15.76465\n10 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\n\n\n\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\n\n\nproxmat\n\n           1         2         3         4         5         6         7\n2  171.86828                                                            \n3  381.88259 257.31610                                                  \n4   57.46286 208.63519 400.05492                                        \n5  263.37099 313.45776 529.14689 312.66966                              \n6  160.05997 302.51785 499.53297 181.96406 198.14085                    \n7   59.61977 117.91580 336.50410  94.61225 282.26877 211.91531          \n8  140.11550 204.32952 432.16535 192.57320 130.36525 140.01101 157.51129\n9   89.07103 180.64047 377.87702 139.27495 204.63154 127.74787 113.15370\n10 144.02475 311.01487 505.89191 139.67966 264.88283  79.42225 202.12206\n11 563.01629 704.11252 899.44137 571.58335 453.27410 412.46033 614.56144\n12 141.87227 298.61288 491.83321 101.10150 345.00222 197.34633 182.23667\n13 115.86190 258.49346 422.71934  64.52387 358.86053 200.34668 151.60031\n14 434.92968 437.99577 397.03752 398.11227 693.24602 562.59200 416.00669\n15  97.61092 212.81775 360.11861  78.07733 340.55064 204.93018 114.98048\n16 192.67961 283.35574 361.23257 163.42143 425.16902 267.87522 208.14888\n17 256.72744 287.41816 333.12853 220.56339 516.40426 386.74701 242.52301\n18 503.61965 481.71125 364.98429 476.29056 747.17454 625.24500 480.23965\n19 251.29457 398.98167 602.17475 262.51735 231.28227 106.69059 303.80011\n20 193.32063 335.72896 483.68125 192.78316 301.52942 114.69105 243.30037\n21 401.25041 354.39039 255.22031 382.40610 637.53975 537.63884 368.25761\n22 529.63213 635.51774 807.44220 555.01039 365.32538 373.64459 573.39528\n23 406.15714 474.50209 452.95769 371.26895 630.34312 463.53759 416.84901\n24 349.45980 391.74783 408.97731 305.86058 610.30557 465.52013 342.08722\n25 118.18050 245.98884 388.63147  76.55260 366.42787 212.36711 145.37542\n26 214.20854 314.71506 432.98028 160.44703 470.48135 317.96188 225.64279\n27 242.54541 402.21719 542.85957 217.58854 384.91867 195.18913 293.70625\n28 104.91839 275.44246 472.77637  85.49572 287.92364 124.30500 160.37607\n29 568.27732 726.85355 908.82520 563.81750 520.67373 427.77791 624.82399\n30 272.67383 428.24958 556.82263 244.47146 418.54016 224.03998 321.81214\n31 179.62251 225.40822 444.66868 170.04533 366.16094 307.27427 165.02707\n32 177.76325 221.30579 367.44835 222.20020 212.69450 167.08436 190.93173\n33 403.39082 500.86933 528.12533 365.44693 613.51206 444.75859 421.48797\n34 265.12574 310.64850 337.94020 229.75261 518.16310 375.64739 259.68288\n35 136.93111 223.06050 352.85844  98.14855 398.00917 264.16294 138.86577\n36  99.38590 216.52463 407.11649 138.12050 210.21337  95.66782 139.31874\n37 131.49728 172.00796 342.91035 111.61846 381.20187 287.11074 105.30573\n38 384.30076 549.42389 728.16301 372.59678 406.09124 260.26411 441.20998\n39 189.37188 337.98982 534.44679 204.47572 213.61240  38.52842 243.98001\n40 224.12169 355.47066 531.63089 194.76257 396.61508 273.01375 249.36301\n41 281.05362 443.26362 596.19312 265.96924 368.55167 185.14704 336.38582\n42 386.02794 543.81859 714.43173 382.78835 379.56035 246.39577 442.77120\n43 246.45691 385.68322 573.23173 263.48638 219.47071  88.29335 297.67761\n44 164.26299 323.28133 507.78892 168.44228 253.84371  67.19580 219.21623\n45 109.15790 198.35391 340.42789  80.86834 367.19820 237.34578 113.84636\n46 399.84278 503.75471 697.98323 429.54386 226.24011 252.26066 440.66133\n47 381.51246 512.13162 580.13146 356.37963 523.44632 338.35194 423.81347\n48 202.92551 175.54012 287.29358 189.47065 442.07679 360.17247 162.43575\n49 145.48666 293.61143 469.51621  91.56527 375.06406 217.19877 181.94596\n50 430.64070 402.42888 306.16379 405.83081 674.01120 560.16577 403.82131\n51 309.51302 475.93982 630.71590 286.03834 411.88352 233.56349 363.58788\n52 173.50424 318.23811 449.67218 141.58836 375.82140 197.63683 213.46379\n53 214.21738 332.92193 570.56521 235.55497 193.49994 173.43078 248.43910\n54 195.92520 208.43740 324.77002 169.50567 448.59948 348.06617 167.79937\n55 237.78494 228.41073 286.16305 214.33352 488.33873 385.88676 207.16559\n           8         9        10        11        12        13        14\n2                                                                       \n3                                                                       \n4                                                                       \n5                                                                       \n6                                                                       \n7                                                                       \n8                                                                       \n9   90.82891                                                            \n10 186.29066 157.04230                                                  \n11 510.13288 533.68806 434.75768                                        \n12 246.74469 211.88187 128.24979 526.65211                              \n13 241.71260 182.21245 142.45669 571.97975 100.53457                    \n14 567.52693 495.15047 512.02846 926.93007 429.96554 374.50873          \n15 224.64646 147.44053 170.93318 592.90743 144.67198  91.15307 364.95519\n16 311.07742 225.81118 229.28509 634.71074 212.07320 131.67061 313.35220\n17 391.26989 319.57938 339.27780 763.91399 264.13364 203.23607 178.70499\n18 625.18712 546.69447 586.05094 995.66496 522.96309 456.00842 133.29995\n19 220.75270 230.55346 129.95255 313.15288 238.64533 270.86983 638.60773\n20 228.54223 172.84425 110.37831 447.49969 210.76951 178.09554 509.99632\n21 515.39711 444.05061 505.52285 929.11283 443.25453 376.33870 147.83545\n22 441.82621 470.45533 429.15493 221.19950 549.08985 563.95232 919.38755\n23 523.69580 435.59661 420.30003 770.40234 392.32592 329.31700 273.75350\n24 487.41102 414.10280 409.03553 816.44931 324.97428 275.76855 115.58388\n25 249.35081 176.09570 163.95741 591.03355 128.42987  52.68195 351.34601\n26 352.31496 289.83220 253.25370 663.76026 158.93517 125.25968 275.09705\n27 314.64777 257.76465 146.09228 451.82530 185.99082 188.29603 485.52853\n28 188.78869 151.13185  60.32773 489.35308  78.78999  92.79567 462.41938\n29 548.83928 552.65554 428.74978 149.26996 507.39700 551.56800 882.51110\n30 345.91486 287.10769 175.35273 460.24292 214.19291 204.25746 484.14757\n31 260.95300 257.52713 270.87277 659.16927 185.86794 209.35473 427.95451\n32 142.31691  93.03711 217.64419 539.43485 293.22640 253.26470 536.71695\n33 520.31264 439.34272 393.79911 704.86973 351.75354 328.82831 339.01411\n34 396.47081 316.14719 330.28984 744.44948 272.82761 202.99615 194.31049\n35 274.91604 204.88286 218.84211 648.68011 157.48857  91.53795 302.84362\n36 104.17830  43.26545 126.50414 505.88581 201.71653 169.63695 502.99026\n37 257.11202 209.88026 250.27059 677.66886 175.89761 142.36728 329.29477\n38 393.18472 381.40808 241.58966 256.80556 315.93218 354.10985 686.88950\n39 171.50398 164.05304  81.20593 381.30567 204.49010 216.81639 582.53670\n40 318.30406 285.04608 215.63037 547.24297 122.68682 202.92529 446.53763\n41 321.16462 279.84188 154.91633 377.44407 230.78652 243.00945 561.24281\n42 379.41126 367.33575 247.81990 238.67060 342.43665 370.05669 706.47792\n43 209.38215 208.29647 136.23356 330.08211 258.23950 272.28711 632.54638\n44 190.30257 156.51662  51.67279 413.64173 160.94435 174.67678 531.08019\n45 242.04063 170.09168 200.77712 633.21624 163.28926  84.11238 332.07962\n46 304.96838 344.79200 312.60547 250.81471 425.36916 448.55282 810.74692\n47 453.02765 381.67478 308.31407 541.97887 351.78203 312.13429 500.68857\n48 317.74604 267.21607 328.14177 757.16745 255.83275 210.50453 278.85535\n49 265.29318 219.26405 146.92675 560.43400  59.69478  58.41263 388.73386\n50 551.13000 475.77296 522.86003 941.49778 458.30232 391.54062 109.08779\n51 363.37684 323.32123 188.59489 389.59919 229.71502 260.39387 558.83162\n52 278.68953 206.15773 145.00266 533.00162 142.03682 110.55197 398.43973\n53 179.07229 220.61209 181.55295 422.37358 211.99976 275.77546 620.04321\n54 323.14701 269.07880 306.78359 736.93741 224.29176 180.37471 262.66006\n55 362.84062 299.74967 347.85944 778.52971 273.79672 218.10003 215.19289\n          15        16        17        18        19        20        21\n2                                                                       \n3                                                                       \n4                                                                       \n5                                                                       \n6                                                                       \n7                                                                       \n8                                                                       \n9                                                                       \n10                                                                      \n11                                                                      \n12                                                                      \n13                                                                      \n14                                                                      \n15                                                                      \n16 107.06341                                                            \n17 188.94166 159.79790                                                  \n18 428.96133 365.50032 262.84016                                        \n19 289.82513 347.11584 466.36472 708.65819                              \n20 185.18173 200.31803 346.39710 563.56780 172.33279                    \n21 340.86349 303.04574 186.95158 135.51424 628.11049 494.81014          \n22 568.99109 608.76740 750.29555 967.14087 311.95286 411.03849 890.12935\n23 314.27683 215.97925 248.82845 285.65085 525.63854 371.13393 312.05193\n24 273.91673 223.22828 104.98924 222.60577 534.44463 412.17123 203.02855\n25  51.46282  90.69766 177.33790 423.77868 290.86435 179.52054 344.45451\n26 154.32012 150.98053 127.35225 375.60376 377.86793 283.30992 313.59911\n27 204.69232 206.57001 335.61300 552.31959 214.23677 131.59966 501.59903\n28 130.04549 199.58124 288.55962 542.16609 184.47950 144.77393 458.06573\n29 580.38112 604.66190 732.68347 954.11795 334.65738 435.58047 903.72094\n30 228.33583 210.77938 343.30638 548.40662 236.72516 140.23910 506.29940\n31 225.28268 308.71751 278.02761 525.04057 365.88437 352.91394 416.65397\n32 206.61627 258.04282 370.01575 568.21089 262.09281 187.85699 470.46845\n33 310.60810 248.25265 287.87384 380.92091 485.51312 365.87588 392.40306\n34 182.75266 119.86993  65.38727 257.18572 454.52548 318.47482 201.65224\n35  73.45899 106.21031 124.62791 379.37916 345.31042 239.43845 291.84351\n36 152.15482 219.72196 327.13541 557.32112 201.58191 137.29734 460.91883\n37 128.21054 194.64317 162.27126 411.59788 369.00833 295.87811 304.02806\n38 388.40984 411.06668 535.28615 761.48327 179.95877 253.20001 708.17595\n39 229.37894 286.75945 408.23212 648.04408  79.41836 120.66550 564.64051\n40 204.54010 270.02165 299.36066 539.91284 295.23103 288.03320 468.27436\n41 263.31986 273.50305 408.73288 626.17673 170.63913 135.62913 573.55355\n42 392.48568 414.53594 550.62819 771.39688 173.27153 240.34131 715.42102\n43 279.19573 329.38387 460.39706 692.74693  59.85893 142.21554 613.01033\n44 180.51419 236.70878 358.95672 597.42714 115.18145  94.98486 518.86151\n45  62.60859 107.04894 154.86049 400.71816 325.71557 216.25326 308.13805\n46 450.33382 508.40925 635.94105 866.21117 195.14541 319.81385 778.45810\n47 321.80465 257.50434 394.07696 536.95736 362.45608 232.52209 523.43600\n48 184.23422 222.52947 137.79420 352.06533 447.10266 358.89620 233.83079\n49 131.56529 176.16001 224.79239 482.18190 268.92310 207.25000 406.56282\n50 361.82684 310.20581 195.59882  81.75337 646.66493 507.96808  59.52318\n51 285.33223 295.60023 414.31237 631.91325 209.33700 194.93467 585.61776\n52 108.84990 114.03609 238.99570 465.03971 255.10832 137.85278 403.66587\n53 281.03383 375.22688 445.78964 700.98284 172.70139 275.15989 601.80824\n54 166.61820 198.88460 109.08506 348.56123 429.84475 340.39128 242.78233\n55 191.32762 196.76188  77.35900 288.66231 472.04024 364.77086 180.09747\n          22        23        24        25        26        27        28\n2                                                                       \n3                                                                       \n4                                                                       \n5                                                                       \n6                                                                       \n7                                                                       \n8                                                                       \n9                                                                       \n10                                                                      \n11                                                                      \n12                                                                      \n13                                                                      \n14                                                                      \n15                                                                      \n16                                                                      \n17                                                                      \n18                                                                      \n19                                                                      \n20                                                                      \n21                                                                      \n22                                                                      \n23 760.29566                                                            \n24 820.50164 217.28718                                                  \n25 576.18780 295.40170 253.80950                                        \n26 677.09508 278.21548 167.98445 121.78922                              \n27 472.95568 331.42618 375.35820 185.99483 247.17708                    \n28 486.77266 398.13308 360.99219 120.24428 201.92690 164.99494          \n29 325.06329 708.82887 769.06406 569.06099 626.44910 404.00848 480.60074\n30 481.31907 316.30314 375.58139 205.04337 256.37933  57.60801 193.36162\n31 659.56458 494.36143 355.99713 229.44658 231.78673 365.03882 217.61884\n32 444.04411 448.40651 462.63265 237.67919 356.84917 291.88846 227.52638\n33 730.92980 158.82353 254.24424 296.74316 268.25060 281.87425 374.70456\n34 727.08969 188.64567 113.80917 168.92101 140.95392 305.57166 287.36626\n35 632.45718 294.40441 212.99485  62.86179 100.45714 244.16253 167.66291\n36 445.81335 427.94086 417.08639 169.92664 286.37238 230.45003 131.18943\n37 658.87060 377.52977 256.70338 136.54610 153.49551 311.98001 193.53779\n38 347.33155 531.46949 574.40292 373.47509 429.00536 216.24705 289.45119\n39 354.90063 474.12297 481.88406 231.48538 331.22632 184.67099 136.45492\n40 595.70536 413.07823 341.68641 205.10051 202.31862 224.43391 183.01388\n41 403.82035 397.85908 451.51070 248.72536 317.64824  78.29342 196.47091\n42 295.91660 536.85519 596.19944 382.79302 455.10875 223.32205 302.89487\n43 295.90429 505.40025 531.35998 284.08582 383.72138 207.58055 193.67980\n44 402.33622 420.65204 428.08061 183.05109 279.52329 134.50170  99.39859\n45 605.02113 311.92379 247.73318  58.55724 137.24737 242.43599 153.59962\n46 150.84117 684.20905 712.80752 462.31183 562.88102 387.33906 365.04897\n47 540.60474 264.64997 407.02947 298.12447 343.53898 187.40057 326.12960\n48 728.87329 374.90376 233.25039 195.17677 190.50609 377.89657 273.02385\n49 573.75476 354.79137 284.76895  98.04789 118.65144 190.26490  94.23028\n50 910.23039 280.26395 181.33894 359.60008 317.15603 503.79786 476.55544\n51 448.79027 401.39475 445.40621 267.10497 312.64797  91.06281 218.49285\n52 532.26397 281.62645 292.49814  90.77517 165.38834 103.91040 128.20940\n53 432.10118 572.76394 522.91815 294.70967 364.40429 296.40789 191.11990\n54 719.84066 348.84991 201.49393 167.69794 144.59626 347.14183 249.70235\n55 754.03913 316.54695 170.90848 194.47928 169.56962 371.71448 294.16284\n          29        30        31        32        33        34        35\n2                                                                       \n3                                                                       \n4                                                                       \n5                                                                       \n6                                                                       \n7                                                                       \n8                                                                       \n9                                                                       \n10                                                                      \n11                                                                      \n12                                                                      \n13                                                                      \n14                                                                      \n15                                                                      \n16                                                                      \n17                                                                      \n18                                                                      \n19                                                                      \n20                                                                      \n21                                                                      \n22                                                                      \n23                                                                      \n24                                                                      \n25                                                                      \n26                                                                      \n27                                                                      \n28                                                                      \n29                                                                      \n30 408.04016                                                            \n31 664.06286 392.97391                                                  \n32 565.84279 315.11651 346.57799                                        \n33 635.92043 274.81900 478.37690 463.39594                              \n34 708.13447 308.33123 321.66441 354.76537 242.02901                    \n35 628.48557 261.51075 206.82668 267.95563 304.49287 134.00139          \n36 520.24345 257.77823 271.41464 103.97300 432.35040 319.32583 209.32532\n37 670.74564 335.52974 131.89940 285.37627 383.49700 199.64389  91.65458\n38 202.55831 217.88123 483.49434 408.03397 468.09747 512.61580 432.31105\n39 391.74585 214.66375 327.41448 200.26876 448.84563 395.58453 286.41193\n40 521.88657 258.49342 233.60474 357.44661 329.11433 309.05385 219.06817\n41 331.67199  92.57672 408.24516 304.26577 348.18522 379.27212 309.77356\n42 196.46063 231.38484 506.32466 379.50202 481.59596 523.74815 444.13246\n43 351.48520 229.85484 385.33554 221.47613 474.82621 442.80821 340.47382\n44 410.41270 167.65920 305.03473 200.27496 386.95022 343.96455 239.63685\n45 619.01766 260.52971 209.64684 232.17823 331.72187 158.90478  43.40665\n46 345.98041 405.59730 518.72748 334.17439 650.56905 621.53039 513.76415\n47 470.63605 157.48757 517.03554 381.95144 263.97576 340.37881 346.00673\n48 749.99415 396.89963 186.90932 328.16234 400.10989 187.43974 136.49038\n49 535.57527 207.94433 194.24075 296.99681 334.19820 231.99959 124.74445\n50 907.38406 504.75214 448.58230 502.20840 366.66876 200.48082 310.58885\n51 326.19219 108.37735 413.26052 358.17599 329.39338 387.80686 323.35704\n52 500.41640 123.18870 296.43996 250.74435 253.74202 212.59619 145.15617\n53 454.80044 336.16703 262.24331 285.56475 522.38580 455.59190 326.59925\n54 722.40954 364.76893 178.69483 335.26416 367.46064 161.67411 106.82328\n55 760.45960 385.65526 240.95555 352.70492 352.20115 130.23777 132.70541\n          36        37        38        39        40        41        42\n2                                                                       \n3                                                                       \n4                                                                       \n5                                                                       \n6                                                                       \n7                                                                       \n8                                                                       \n9                                                                       \n10                                                                      \n11                                                                      \n12                                                                      \n13                                                                      \n14                                                                      \n15                                                                      \n16                                                                      \n17                                                                      \n18                                                                      \n19                                                                      \n20                                                                      \n21                                                                      \n22                                                                      \n23                                                                      \n24                                                                      \n25                                                                      \n26                                                                      \n27                                                                      \n28                                                                      \n29                                                                      \n30                                                                      \n31                                                                      \n32                                                                      \n33                                                                      \n34                                                                      \n35                                                                      \n36                                                                      \n37 225.80242                                                            \n38 347.60273 478.66210                                                  \n39 130.86310 312.74375 226.82048                                        \n40 285.13095 231.85967 346.46200 276.19175                              \n41 247.19891 370.01334 147.02444 162.80878 271.34451                    \n42 333.32428 492.09476  77.21355 212.11323 375.73885 146.18632          \n43 177.75714 370.72441 202.45004  66.12817 317.14187 164.29921 175.63015\n44 128.26577 276.27441 229.01675  66.66133 224.52741 134.24847 224.40029\n45 173.82799  97.82470 424.51868 262.28462 239.89665 301.84458 431.32637\n46 325.09619 528.14240 297.09863 238.19389 471.29032 329.95252 257.29147\n47 352.92324 433.06326 319.18643 330.70182 392.45403 206.98364 310.44067\n48 288.06872  84.04049 556.02500 388.33498 298.55859 440.48114 567.86202\n49 206.40432 158.84853 338.67408 227.10984 166.53599 242.89326 364.90647\n50 488.79874 334.87758 712.51416 584.63341 479.76855 577.52046 721.86149\n51 294.29500 382.59743 146.66661 210.19929 247.22785  69.25859 167.72448\n52 189.97131 220.15490 306.47566 206.47448 193.77551 172.96164 314.92119\n53 218.12104 309.51462 315.57550 173.86004 240.39800 290.51360 321.21112\n54 284.14692  70.27241 526.80849 373.07575 268.07983 412.22167 542.64078\n55 315.91750 125.74240 564.02740 411.96125 310.40560 440.51555 576.42717\n          43        44        45        46        47        48        49\n2                                                                       \n3                                                                       \n4                                                                       \n5                                                                       \n6                                                                       \n7                                                                       \n8                                                                       \n9                                                                       \n10                                                                      \n11                                                                      \n12                                                                      \n13                                                                      \n14                                                                      \n15                                                                      \n16                                                                      \n17                                                                      \n18                                                                      \n19                                                                      \n20                                                                      \n21                                                                      \n22                                                                      \n23                                                                      \n24                                                                      \n25                                                                      \n26                                                                      \n27                                                                      \n28                                                                      \n29                                                                      \n30                                                                      \n31                                                                      \n32                                                                      \n33                                                                      \n34                                                                      \n35                                                                      \n36                                                                      \n37                                                                      \n38                                                                      \n39                                                                      \n40                                                                      \n41                                                                      \n42                                                                      \n43                                                                      \n44 107.16213                                                            \n45 316.91914 221.84918                                                  \n46 186.28225 288.27478 486.91951                                        \n47 337.48335 295.38434 343.38498 497.61245                              \n48 444.26274 350.91512 146.61572 599.57407 476.62610                    \n49 282.22935 184.10672 131.55208 455.91617 331.69981 232.32965          \n50 631.99123 535.95620 330.76503 803.08034 510.79265 272.03299 419.06087\n51 217.08047 175.35413 323.95988 374.58247 225.25026 453.86726 246.76592\n52 245.95083 146.38284 146.78891 429.98509 229.09986 278.95182 130.39336\n53 203.87199 186.11584 312.85089 287.73864 475.33116 387.71518 261.75211\n54 429.95076 332.02048 127.42203 592.65262 447.05580  47.79331 196.60826\n55 466.20497 368.20978 153.22576 631.49232 448.58030  68.67929 242.15271\n          50        51        52        53        54\n2                                                   \n3                                                   \n4                                                   \n5                                                   \n6                                                   \n7                                                   \n8                                                   \n9                                                   \n10                                                  \n11                                                  \n12                                                  \n13                                                  \n14                                                  \n15                                                  \n16                                                  \n17                                                  \n18                                                  \n19                                                  \n20                                                  \n21                                                  \n22                                                  \n23                                                  \n24                                                  \n25                                                  \n26                                                  \n27                                                  \n28                                                  \n29                                                  \n30                                                  \n31                                                  \n32                                                  \n33                                                  \n34                                                  \n35                                                  \n36                                                  \n37                                                  \n38                                                  \n39                                                  \n40                                                  \n41                                                  \n42                                                  \n43                                                  \n44                                                  \n45                                                  \n46                                                  \n47                                                  \n48                                                  \n49                                                  \n50                                                  \n51 585.70558                                        \n52 410.49230 188.89405                              \n53 629.43339 304.21734 295.35984                    \n54 271.82672 421.06366 249.74161 377.52279          \n55 210.48485 450.97869 270.79121 430.02019  63.67613\n\n\n\n\n\n\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\n\nplot(hclust_ward, cex = 0.6)\n\n\n\n\n\n\n\n\nFind the optimal clustering algorithm:\n\nm &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\n\n\n\n\nset.seed(12345)\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\n\nfviz_gap_stat(gap_stat)\n\n\n\n\n\n\n\n\n\n\n\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n\n\n\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )\n\n\n\n\n\n\n\n\n\ngroups &lt;- as.factor(cutree(hclust_ward, k=6))\n\n(retain the 6 as suggested earlier on by optimal cluster count where cluster count != 1)\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nFirst, we need to convert shan_sf into SpatialPolygonsDataFrame. This is because SKATER function only support sp objects such as SpatialPolygonDataFrame.\n\nshan_sp &lt;- as_Spatial(shan_sf)\n\n\nshan.nb &lt;- poly2nb(shan_sp)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\n\ncoords &lt;- st_coordinates(\n  st_centroid(st_geometry(shan_sf)))\n\n\nplot(st_geometry(shan_sf), \n     border=grey(.5))\nplot(shan.nb,\n     coords, \n     col=\"blue\", \n     add=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nlcosts &lt;- nbcosts(shan.nb, shan_ict)\n\n\nshan.w &lt;- nb2listw(shan.nb, \n                   lcosts, \n                   style=\"B\")\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n\n\n\nshan.mst &lt;- mstree(shan.w)\n\n\nclass(shan.mst)\n\n[1] \"mst\"    \"matrix\"\n\n\n\ndim(shan.mst)\n\n[1] 54  3\n\n\n\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]   54   48  47.79331\n[2,]   54   17 109.08506\n[3,]   54   45 127.42203\n[4,]   45   52 146.78891\n[5,]   52   13 110.55197\n[6,]   13   28  92.79567\n\n\n\nplot(st_geometry(shan_sf), \n                 border=gray(.5))\nplot.mst(shan.mst, \n         coords, \n         col=\"blue\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)\n\n\n\n\n\n\n\n\n\nclust6 &lt;- spdep::skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\n\n\nstr(clust6)\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 52 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 25 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 1458\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\n\nccs6 &lt;- clust6$groups\nccs6\n\n [1] 3 3 6 3 3 3 3 3 3 3 2 1 1 1 2 1 1 1 2 4 1 2 5 1 1 1 2 1 2 2 1 2 2 1 1 3 1 2\n[39] 2 2 2 2 2 4 1 3 2 1 1 1 2 1 2 1 1\n\n\n\ntable(ccs6)\n\nccs6\n 1  2  3  4  5  6 \n22 18 11  2  1  1 \n\n\nplot the pruned tree based off mst:\n\nplot(st_geometry(shan_sf), \n     border=gray(.5))\nplot(clust6, \n     coords, \n     cex.lab=.7,\n     groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"pink\"),\n     cex.circles=0.005, \n     add=TRUE)\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\n\n\n\n\n\n\n\n\n\n\n\n\n\ngroups_mat &lt;- as.matrix(clust6$groups)\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\n\n\n\n\n\n\nhclust.map &lt;- qtm(shan_sf_cluster,\n                  \"CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\nshclust.map &lt;- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(hclust.map, shclust.map,\n             asp=NA, ncol=2)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo perform non-spatially constrained hierarchical clustering, we only need to provide the function a dissimilarity matrix.\n\nnongeo_cluster &lt;- hclustgeo(proxmat)\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n\n\n\ngroups &lt;- as.factor(cutree(nongeo_cluster, k=6))\n\n\nshan_sf_ngeo_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\n\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\n\ndist &lt;- st_distance(shan_sf, shan_sf)\ndistmat &lt;- as.dist(dist)\n\n\ncr &lt;- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclustG &lt;- hclustgeo(proxmat, distmat, alpha = 0.2)\n\n\ngroups &lt;- as.factor(cutree(clustG, k=6))\n\n\nshan_sf_Gcluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\n\nqtm(shan_sf_Gcluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = shan_sf_ngeo_cluster,\n       aes(x = CLUSTER, y = RADIO_PR)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nCluster 3 displays the highest mean Radio Ownership Per Thousand Household.\n\nggparcoord(data = shan_sf_ngeo_cluster, \n           columns = c(17:21), \n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\nThe parallel coordinate plot above reveals that households in Cluster 4 townships tend to own the highest number of TV and mobile-phone. On the other hand, households in Cluster 5 tends to own the lowest of all the five ICT.\nThe scale argument of ggparcoor() provide several methods to scale the clustering variables.\n\nstd: univariately, subtract mean and divide by standard deviation.\nrobust: univariately, subtract median and divide by median absolute deviation.\nuniminmax: univariately, scale so the minimum of the variable is zero, and the maximum is one.\nglobalminmax: no scaling is done; the range of the graphs is defined by the global minimum and the global maximum.\ncenter: use uniminmax to standardize vertical height, then center each variable at a value specified by the scaleSummary param.\ncenterObs: use uniminmax to standardize vertical height, then center each variable at the value of the observation specified by the centerObsID param\n\n\nshan_sf_ngeo_cluster %&gt;% \n  st_set_geometry(NULL) %&gt;%\n  group_by(CLUSTER) %&gt;%\n  summarise(mean_RADIO_PR = mean(RADIO_PR),\n            mean_TV_PR = mean(TV_PR),\n            mean_LLPHONE_PR = mean(LLPHONE_PR),\n            mean_MPHONE_PR = mean(MPHONE_PR),\n            mean_COMPUTER_PR = mean(COMPUTER_PR))\n\n# A tibble: 6 × 6\n  CLUSTER mean_RADIO_PR mean_TV_PR mean_LLPHONE_PR mean_MPHONE_PR\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n1 1               221.        521.            44.2           246.\n2 2               237.        402.            23.9           134.\n3 3               300.        611.            52.2           392.\n4 4               196.        744.            99.0           651.\n5 5               124.        224.            38.0           132.\n6 6                98.6       499.            74.5           468.\n# ℹ 1 more variable: mean_COMPUTER_PR &lt;dbl&gt;"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#getting-started",
    "title": "hands on exercise 9",
    "section": "",
    "text": "pacman::p_load(BiocManager, spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#data-import-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#data-import-and-preparation",
    "title": "hands on exercise 9",
    "section": "",
    "text": "shan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"myanmar_township_boundaries\") %&gt;%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  select(c(2:7))\n\nReading layer `myanmar_township_boundaries' from data source \n  `C:\\jechaxu\\IS415-GAA\\Hands-on_Ex\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\n\nshan_sf\n\nSimple feature collection with 55 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 96.15107 ymin: 19.29932 xmax: 101.1699 ymax: 24.15907\nGeodetic CRS:  WGS 84\nFirst 10 features:\n             ST ST_PCODE       DT   DT_PCODE        TS  TS_PCODE\n1  Shan (North)   MMR015  Mongmit MMR015D008   Mongmit MMR015017\n2  Shan (South)   MMR014 Taunggyi MMR014D001   Pindaya MMR014006\n3  Shan (South)   MMR014 Taunggyi MMR014D001   Ywangan MMR014007\n4  Shan (South)   MMR014 Taunggyi MMR014D001  Pinlaung MMR014009\n5  Shan (North)   MMR015  Mongmit MMR015D008    Mabein MMR015018\n6  Shan (South)   MMR014 Taunggyi MMR014D001     Kalaw MMR014005\n7  Shan (South)   MMR014 Taunggyi MMR014D001     Pekon MMR014010\n8  Shan (South)   MMR014 Taunggyi MMR014D001  Lawksawk MMR014008\n9  Shan (North)   MMR015  Kyaukme MMR015D003 Nawnghkio MMR015013\n10 Shan (North)   MMR015  Kyaukme MMR015D003   Kyaukme MMR015012\n                         geometry\n1  MULTIPOLYGON (((96.96001 23...\n2  MULTIPOLYGON (((96.7731 21....\n3  MULTIPOLYGON (((96.78483 21...\n4  MULTIPOLYGON (((96.49518 20...\n5  MULTIPOLYGON (((96.66306 24...\n6  MULTIPOLYGON (((96.49518 20...\n7  MULTIPOLYGON (((97.14738 19...\n8  MULTIPOLYGON (((96.94981 22...\n9  MULTIPOLYGON (((96.75648 22...\n10 MULTIPOLYGON (((96.95498 22...\n\n\n\nict &lt;- read_csv (\"data/aspatial/Shan-ICT.csv\")\n\nRows: 55 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): District Pcode, District Name, Township Pcode, Township Name\ndbl (7): Total households, Radio, Television, Land line phone, Mobile phone,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsummary(ict)\n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %&gt;%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\nsummary(ict_derived)\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 21.05  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:138.95  \n Median : 3559   Median : 244.0   Median : 316.0   Median :210.95  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :215.68  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:268.07  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :484.52  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :116.0   Min.   :  2.78   Min.   : 36.42   Min.   : 3.278  \n 1st Qu.:450.2   1st Qu.: 22.84   1st Qu.:190.14   1st Qu.:11.832  \n Median :517.2   Median : 37.59   Median :305.27   Median :18.970  \n Mean   :509.5   Mean   : 51.09   Mean   :314.05   Mean   :24.393  \n 3rd Qu.:606.4   3rd Qu.: 69.72   3rd Qu.:428.43   3rd Qu.:29.897  \n Max.   :842.5   Max.   :181.49   Max.   :735.43   Max.   :92.402  \n  INTERNET_PR     \n Min.   :  1.041  \n 1st Qu.:  8.617  \n Median : 22.829  \n Mean   : 30.644  \n 3rd Qu.: 41.281  \n Max.   :117.985  \n\n\n\nshan_sf &lt;- left_join(shan_sf, \n                     ict_derived, by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n  \nwrite_rds(shan_sf, \"data/rds/shan_sf.rds\")\n\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\n\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\nshan_ict &lt;- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n   RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1  286.1852 554.1313   35.30618  260.6944    12.15939\n2  417.4647 505.1300   19.83584  162.3917    12.88190\n3  484.5215 260.5734   11.93591  120.2856     4.41465\n4  231.6499 541.7189   28.54454  249.4903    13.76255\n5  449.4903 708.6423   72.75255  392.6089    16.45042\n6  280.7624 611.6204   42.06478  408.7951    29.63160\n7  318.6118 535.8494   39.83270  214.8476    18.97032\n8  387.1017 630.0035   31.51366  320.5686    21.76677\n9  349.3359 547.9456   38.44960  323.0201    15.76465\n10 210.9548 601.1773   39.58267  372.4930    30.94709"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#plotting-clusters",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#plotting-clusters",
    "title": "hands on exercise 9",
    "section": "",
    "text": "proxmat &lt;- dist(shan_ict, method = 'euclidean')\n\n\nproxmat\n\n           1         2         3         4         5         6         7\n2  171.86828                                                            \n3  381.88259 257.31610                                                  \n4   57.46286 208.63519 400.05492                                        \n5  263.37099 313.45776 529.14689 312.66966                              \n6  160.05997 302.51785 499.53297 181.96406 198.14085                    \n7   59.61977 117.91580 336.50410  94.61225 282.26877 211.91531          \n8  140.11550 204.32952 432.16535 192.57320 130.36525 140.01101 157.51129\n9   89.07103 180.64047 377.87702 139.27495 204.63154 127.74787 113.15370\n10 144.02475 311.01487 505.89191 139.67966 264.88283  79.42225 202.12206\n11 563.01629 704.11252 899.44137 571.58335 453.27410 412.46033 614.56144\n12 141.87227 298.61288 491.83321 101.10150 345.00222 197.34633 182.23667\n13 115.86190 258.49346 422.71934  64.52387 358.86053 200.34668 151.60031\n14 434.92968 437.99577 397.03752 398.11227 693.24602 562.59200 416.00669\n15  97.61092 212.81775 360.11861  78.07733 340.55064 204.93018 114.98048\n16 192.67961 283.35574 361.23257 163.42143 425.16902 267.87522 208.14888\n17 256.72744 287.41816 333.12853 220.56339 516.40426 386.74701 242.52301\n18 503.61965 481.71125 364.98429 476.29056 747.17454 625.24500 480.23965\n19 251.29457 398.98167 602.17475 262.51735 231.28227 106.69059 303.80011\n20 193.32063 335.72896 483.68125 192.78316 301.52942 114.69105 243.30037\n21 401.25041 354.39039 255.22031 382.40610 637.53975 537.63884 368.25761\n22 529.63213 635.51774 807.44220 555.01039 365.32538 373.64459 573.39528\n23 406.15714 474.50209 452.95769 371.26895 630.34312 463.53759 416.84901\n24 349.45980 391.74783 408.97731 305.86058 610.30557 465.52013 342.08722\n25 118.18050 245.98884 388.63147  76.55260 366.42787 212.36711 145.37542\n26 214.20854 314.71506 432.98028 160.44703 470.48135 317.96188 225.64279\n27 242.54541 402.21719 542.85957 217.58854 384.91867 195.18913 293.70625\n28 104.91839 275.44246 472.77637  85.49572 287.92364 124.30500 160.37607\n29 568.27732 726.85355 908.82520 563.81750 520.67373 427.77791 624.82399\n30 272.67383 428.24958 556.82263 244.47146 418.54016 224.03998 321.81214\n31 179.62251 225.40822 444.66868 170.04533 366.16094 307.27427 165.02707\n32 177.76325 221.30579 367.44835 222.20020 212.69450 167.08436 190.93173\n33 403.39082 500.86933 528.12533 365.44693 613.51206 444.75859 421.48797\n34 265.12574 310.64850 337.94020 229.75261 518.16310 375.64739 259.68288\n35 136.93111 223.06050 352.85844  98.14855 398.00917 264.16294 138.86577\n36  99.38590 216.52463 407.11649 138.12050 210.21337  95.66782 139.31874\n37 131.49728 172.00796 342.91035 111.61846 381.20187 287.11074 105.30573\n38 384.30076 549.42389 728.16301 372.59678 406.09124 260.26411 441.20998\n39 189.37188 337.98982 534.44679 204.47572 213.61240  38.52842 243.98001\n40 224.12169 355.47066 531.63089 194.76257 396.61508 273.01375 249.36301\n41 281.05362 443.26362 596.19312 265.96924 368.55167 185.14704 336.38582\n42 386.02794 543.81859 714.43173 382.78835 379.56035 246.39577 442.77120\n43 246.45691 385.68322 573.23173 263.48638 219.47071  88.29335 297.67761\n44 164.26299 323.28133 507.78892 168.44228 253.84371  67.19580 219.21623\n45 109.15790 198.35391 340.42789  80.86834 367.19820 237.34578 113.84636\n46 399.84278 503.75471 697.98323 429.54386 226.24011 252.26066 440.66133\n47 381.51246 512.13162 580.13146 356.37963 523.44632 338.35194 423.81347\n48 202.92551 175.54012 287.29358 189.47065 442.07679 360.17247 162.43575\n49 145.48666 293.61143 469.51621  91.56527 375.06406 217.19877 181.94596\n50 430.64070 402.42888 306.16379 405.83081 674.01120 560.16577 403.82131\n51 309.51302 475.93982 630.71590 286.03834 411.88352 233.56349 363.58788\n52 173.50424 318.23811 449.67218 141.58836 375.82140 197.63683 213.46379\n53 214.21738 332.92193 570.56521 235.55497 193.49994 173.43078 248.43910\n54 195.92520 208.43740 324.77002 169.50567 448.59948 348.06617 167.79937\n55 237.78494 228.41073 286.16305 214.33352 488.33873 385.88676 207.16559\n           8         9        10        11        12        13        14\n2                                                                       \n3                                                                       \n4                                                                       \n5                                                                       \n6                                                                       \n7                                                                       \n8                                                                       \n9   90.82891                                                            \n10 186.29066 157.04230                                                  \n11 510.13288 533.68806 434.75768                                        \n12 246.74469 211.88187 128.24979 526.65211                              \n13 241.71260 182.21245 142.45669 571.97975 100.53457                    \n14 567.52693 495.15047 512.02846 926.93007 429.96554 374.50873          \n15 224.64646 147.44053 170.93318 592.90743 144.67198  91.15307 364.95519\n16 311.07742 225.81118 229.28509 634.71074 212.07320 131.67061 313.35220\n17 391.26989 319.57938 339.27780 763.91399 264.13364 203.23607 178.70499\n18 625.18712 546.69447 586.05094 995.66496 522.96309 456.00842 133.29995\n19 220.75270 230.55346 129.95255 313.15288 238.64533 270.86983 638.60773\n20 228.54223 172.84425 110.37831 447.49969 210.76951 178.09554 509.99632\n21 515.39711 444.05061 505.52285 929.11283 443.25453 376.33870 147.83545\n22 441.82621 470.45533 429.15493 221.19950 549.08985 563.95232 919.38755\n23 523.69580 435.59661 420.30003 770.40234 392.32592 329.31700 273.75350\n24 487.41102 414.10280 409.03553 816.44931 324.97428 275.76855 115.58388\n25 249.35081 176.09570 163.95741 591.03355 128.42987  52.68195 351.34601\n26 352.31496 289.83220 253.25370 663.76026 158.93517 125.25968 275.09705\n27 314.64777 257.76465 146.09228 451.82530 185.99082 188.29603 485.52853\n28 188.78869 151.13185  60.32773 489.35308  78.78999  92.79567 462.41938\n29 548.83928 552.65554 428.74978 149.26996 507.39700 551.56800 882.51110\n30 345.91486 287.10769 175.35273 460.24292 214.19291 204.25746 484.14757\n31 260.95300 257.52713 270.87277 659.16927 185.86794 209.35473 427.95451\n32 142.31691  93.03711 217.64419 539.43485 293.22640 253.26470 536.71695\n33 520.31264 439.34272 393.79911 704.86973 351.75354 328.82831 339.01411\n34 396.47081 316.14719 330.28984 744.44948 272.82761 202.99615 194.31049\n35 274.91604 204.88286 218.84211 648.68011 157.48857  91.53795 302.84362\n36 104.17830  43.26545 126.50414 505.88581 201.71653 169.63695 502.99026\n37 257.11202 209.88026 250.27059 677.66886 175.89761 142.36728 329.29477\n38 393.18472 381.40808 241.58966 256.80556 315.93218 354.10985 686.88950\n39 171.50398 164.05304  81.20593 381.30567 204.49010 216.81639 582.53670\n40 318.30406 285.04608 215.63037 547.24297 122.68682 202.92529 446.53763\n41 321.16462 279.84188 154.91633 377.44407 230.78652 243.00945 561.24281\n42 379.41126 367.33575 247.81990 238.67060 342.43665 370.05669 706.47792\n43 209.38215 208.29647 136.23356 330.08211 258.23950 272.28711 632.54638\n44 190.30257 156.51662  51.67279 413.64173 160.94435 174.67678 531.08019\n45 242.04063 170.09168 200.77712 633.21624 163.28926  84.11238 332.07962\n46 304.96838 344.79200 312.60547 250.81471 425.36916 448.55282 810.74692\n47 453.02765 381.67478 308.31407 541.97887 351.78203 312.13429 500.68857\n48 317.74604 267.21607 328.14177 757.16745 255.83275 210.50453 278.85535\n49 265.29318 219.26405 146.92675 560.43400  59.69478  58.41263 388.73386\n50 551.13000 475.77296 522.86003 941.49778 458.30232 391.54062 109.08779\n51 363.37684 323.32123 188.59489 389.59919 229.71502 260.39387 558.83162\n52 278.68953 206.15773 145.00266 533.00162 142.03682 110.55197 398.43973\n53 179.07229 220.61209 181.55295 422.37358 211.99976 275.77546 620.04321\n54 323.14701 269.07880 306.78359 736.93741 224.29176 180.37471 262.66006\n55 362.84062 299.74967 347.85944 778.52971 273.79672 218.10003 215.19289\n          15        16        17        18        19        20        21\n2                                                                       \n3                                                                       \n4                                                                       \n5                                                                       \n6                                                                       \n7                                                                       \n8                                                                       \n9                                                                       \n10                                                                      \n11                                                                      \n12                                                                      \n13                                                                      \n14                                                                      \n15                                                                      \n16 107.06341                                                            \n17 188.94166 159.79790                                                  \n18 428.96133 365.50032 262.84016                                        \n19 289.82513 347.11584 466.36472 708.65819                              \n20 185.18173 200.31803 346.39710 563.56780 172.33279                    \n21 340.86349 303.04574 186.95158 135.51424 628.11049 494.81014          \n22 568.99109 608.76740 750.29555 967.14087 311.95286 411.03849 890.12935\n23 314.27683 215.97925 248.82845 285.65085 525.63854 371.13393 312.05193\n24 273.91673 223.22828 104.98924 222.60577 534.44463 412.17123 203.02855\n25  51.46282  90.69766 177.33790 423.77868 290.86435 179.52054 344.45451\n26 154.32012 150.98053 127.35225 375.60376 377.86793 283.30992 313.59911\n27 204.69232 206.57001 335.61300 552.31959 214.23677 131.59966 501.59903\n28 130.04549 199.58124 288.55962 542.16609 184.47950 144.77393 458.06573\n29 580.38112 604.66190 732.68347 954.11795 334.65738 435.58047 903.72094\n30 228.33583 210.77938 343.30638 548.40662 236.72516 140.23910 506.29940\n31 225.28268 308.71751 278.02761 525.04057 365.88437 352.91394 416.65397\n32 206.61627 258.04282 370.01575 568.21089 262.09281 187.85699 470.46845\n33 310.60810 248.25265 287.87384 380.92091 485.51312 365.87588 392.40306\n34 182.75266 119.86993  65.38727 257.18572 454.52548 318.47482 201.65224\n35  73.45899 106.21031 124.62791 379.37916 345.31042 239.43845 291.84351\n36 152.15482 219.72196 327.13541 557.32112 201.58191 137.29734 460.91883\n37 128.21054 194.64317 162.27126 411.59788 369.00833 295.87811 304.02806\n38 388.40984 411.06668 535.28615 761.48327 179.95877 253.20001 708.17595\n39 229.37894 286.75945 408.23212 648.04408  79.41836 120.66550 564.64051\n40 204.54010 270.02165 299.36066 539.91284 295.23103 288.03320 468.27436\n41 263.31986 273.50305 408.73288 626.17673 170.63913 135.62913 573.55355\n42 392.48568 414.53594 550.62819 771.39688 173.27153 240.34131 715.42102\n43 279.19573 329.38387 460.39706 692.74693  59.85893 142.21554 613.01033\n44 180.51419 236.70878 358.95672 597.42714 115.18145  94.98486 518.86151\n45  62.60859 107.04894 154.86049 400.71816 325.71557 216.25326 308.13805\n46 450.33382 508.40925 635.94105 866.21117 195.14541 319.81385 778.45810\n47 321.80465 257.50434 394.07696 536.95736 362.45608 232.52209 523.43600\n48 184.23422 222.52947 137.79420 352.06533 447.10266 358.89620 233.83079\n49 131.56529 176.16001 224.79239 482.18190 268.92310 207.25000 406.56282\n50 361.82684 310.20581 195.59882  81.75337 646.66493 507.96808  59.52318\n51 285.33223 295.60023 414.31237 631.91325 209.33700 194.93467 585.61776\n52 108.84990 114.03609 238.99570 465.03971 255.10832 137.85278 403.66587\n53 281.03383 375.22688 445.78964 700.98284 172.70139 275.15989 601.80824\n54 166.61820 198.88460 109.08506 348.56123 429.84475 340.39128 242.78233\n55 191.32762 196.76188  77.35900 288.66231 472.04024 364.77086 180.09747\n          22        23        24        25        26        27        28\n2                                                                       \n3                                                                       \n4                                                                       \n5                                                                       \n6                                                                       \n7                                                                       \n8                                                                       \n9                                                                       \n10                                                                      \n11                                                                      \n12                                                                      \n13                                                                      \n14                                                                      \n15                                                                      \n16                                                                      \n17                                                                      \n18                                                                      \n19                                                                      \n20                                                                      \n21                                                                      \n22                                                                      \n23 760.29566                                                            \n24 820.50164 217.28718                                                  \n25 576.18780 295.40170 253.80950                                        \n26 677.09508 278.21548 167.98445 121.78922                              \n27 472.95568 331.42618 375.35820 185.99483 247.17708                    \n28 486.77266 398.13308 360.99219 120.24428 201.92690 164.99494          \n29 325.06329 708.82887 769.06406 569.06099 626.44910 404.00848 480.60074\n30 481.31907 316.30314 375.58139 205.04337 256.37933  57.60801 193.36162\n31 659.56458 494.36143 355.99713 229.44658 231.78673 365.03882 217.61884\n32 444.04411 448.40651 462.63265 237.67919 356.84917 291.88846 227.52638\n33 730.92980 158.82353 254.24424 296.74316 268.25060 281.87425 374.70456\n34 727.08969 188.64567 113.80917 168.92101 140.95392 305.57166 287.36626\n35 632.45718 294.40441 212.99485  62.86179 100.45714 244.16253 167.66291\n36 445.81335 427.94086 417.08639 169.92664 286.37238 230.45003 131.18943\n37 658.87060 377.52977 256.70338 136.54610 153.49551 311.98001 193.53779\n38 347.33155 531.46949 574.40292 373.47509 429.00536 216.24705 289.45119\n39 354.90063 474.12297 481.88406 231.48538 331.22632 184.67099 136.45492\n40 595.70536 413.07823 341.68641 205.10051 202.31862 224.43391 183.01388\n41 403.82035 397.85908 451.51070 248.72536 317.64824  78.29342 196.47091\n42 295.91660 536.85519 596.19944 382.79302 455.10875 223.32205 302.89487\n43 295.90429 505.40025 531.35998 284.08582 383.72138 207.58055 193.67980\n44 402.33622 420.65204 428.08061 183.05109 279.52329 134.50170  99.39859\n45 605.02113 311.92379 247.73318  58.55724 137.24737 242.43599 153.59962\n46 150.84117 684.20905 712.80752 462.31183 562.88102 387.33906 365.04897\n47 540.60474 264.64997 407.02947 298.12447 343.53898 187.40057 326.12960\n48 728.87329 374.90376 233.25039 195.17677 190.50609 377.89657 273.02385\n49 573.75476 354.79137 284.76895  98.04789 118.65144 190.26490  94.23028\n50 910.23039 280.26395 181.33894 359.60008 317.15603 503.79786 476.55544\n51 448.79027 401.39475 445.40621 267.10497 312.64797  91.06281 218.49285\n52 532.26397 281.62645 292.49814  90.77517 165.38834 103.91040 128.20940\n53 432.10118 572.76394 522.91815 294.70967 364.40429 296.40789 191.11990\n54 719.84066 348.84991 201.49393 167.69794 144.59626 347.14183 249.70235\n55 754.03913 316.54695 170.90848 194.47928 169.56962 371.71448 294.16284\n          29        30        31        32        33        34        35\n2                                                                       \n3                                                                       \n4                                                                       \n5                                                                       \n6                                                                       \n7                                                                       \n8                                                                       \n9                                                                       \n10                                                                      \n11                                                                      \n12                                                                      \n13                                                                      \n14                                                                      \n15                                                                      \n16                                                                      \n17                                                                      \n18                                                                      \n19                                                                      \n20                                                                      \n21                                                                      \n22                                                                      \n23                                                                      \n24                                                                      \n25                                                                      \n26                                                                      \n27                                                                      \n28                                                                      \n29                                                                      \n30 408.04016                                                            \n31 664.06286 392.97391                                                  \n32 565.84279 315.11651 346.57799                                        \n33 635.92043 274.81900 478.37690 463.39594                              \n34 708.13447 308.33123 321.66441 354.76537 242.02901                    \n35 628.48557 261.51075 206.82668 267.95563 304.49287 134.00139          \n36 520.24345 257.77823 271.41464 103.97300 432.35040 319.32583 209.32532\n37 670.74564 335.52974 131.89940 285.37627 383.49700 199.64389  91.65458\n38 202.55831 217.88123 483.49434 408.03397 468.09747 512.61580 432.31105\n39 391.74585 214.66375 327.41448 200.26876 448.84563 395.58453 286.41193\n40 521.88657 258.49342 233.60474 357.44661 329.11433 309.05385 219.06817\n41 331.67199  92.57672 408.24516 304.26577 348.18522 379.27212 309.77356\n42 196.46063 231.38484 506.32466 379.50202 481.59596 523.74815 444.13246\n43 351.48520 229.85484 385.33554 221.47613 474.82621 442.80821 340.47382\n44 410.41270 167.65920 305.03473 200.27496 386.95022 343.96455 239.63685\n45 619.01766 260.52971 209.64684 232.17823 331.72187 158.90478  43.40665\n46 345.98041 405.59730 518.72748 334.17439 650.56905 621.53039 513.76415\n47 470.63605 157.48757 517.03554 381.95144 263.97576 340.37881 346.00673\n48 749.99415 396.89963 186.90932 328.16234 400.10989 187.43974 136.49038\n49 535.57527 207.94433 194.24075 296.99681 334.19820 231.99959 124.74445\n50 907.38406 504.75214 448.58230 502.20840 366.66876 200.48082 310.58885\n51 326.19219 108.37735 413.26052 358.17599 329.39338 387.80686 323.35704\n52 500.41640 123.18870 296.43996 250.74435 253.74202 212.59619 145.15617\n53 454.80044 336.16703 262.24331 285.56475 522.38580 455.59190 326.59925\n54 722.40954 364.76893 178.69483 335.26416 367.46064 161.67411 106.82328\n55 760.45960 385.65526 240.95555 352.70492 352.20115 130.23777 132.70541\n          36        37        38        39        40        41        42\n2                                                                       \n3                                                                       \n4                                                                       \n5                                                                       \n6                                                                       \n7                                                                       \n8                                                                       \n9                                                                       \n10                                                                      \n11                                                                      \n12                                                                      \n13                                                                      \n14                                                                      \n15                                                                      \n16                                                                      \n17                                                                      \n18                                                                      \n19                                                                      \n20                                                                      \n21                                                                      \n22                                                                      \n23                                                                      \n24                                                                      \n25                                                                      \n26                                                                      \n27                                                                      \n28                                                                      \n29                                                                      \n30                                                                      \n31                                                                      \n32                                                                      \n33                                                                      \n34                                                                      \n35                                                                      \n36                                                                      \n37 225.80242                                                            \n38 347.60273 478.66210                                                  \n39 130.86310 312.74375 226.82048                                        \n40 285.13095 231.85967 346.46200 276.19175                              \n41 247.19891 370.01334 147.02444 162.80878 271.34451                    \n42 333.32428 492.09476  77.21355 212.11323 375.73885 146.18632          \n43 177.75714 370.72441 202.45004  66.12817 317.14187 164.29921 175.63015\n44 128.26577 276.27441 229.01675  66.66133 224.52741 134.24847 224.40029\n45 173.82799  97.82470 424.51868 262.28462 239.89665 301.84458 431.32637\n46 325.09619 528.14240 297.09863 238.19389 471.29032 329.95252 257.29147\n47 352.92324 433.06326 319.18643 330.70182 392.45403 206.98364 310.44067\n48 288.06872  84.04049 556.02500 388.33498 298.55859 440.48114 567.86202\n49 206.40432 158.84853 338.67408 227.10984 166.53599 242.89326 364.90647\n50 488.79874 334.87758 712.51416 584.63341 479.76855 577.52046 721.86149\n51 294.29500 382.59743 146.66661 210.19929 247.22785  69.25859 167.72448\n52 189.97131 220.15490 306.47566 206.47448 193.77551 172.96164 314.92119\n53 218.12104 309.51462 315.57550 173.86004 240.39800 290.51360 321.21112\n54 284.14692  70.27241 526.80849 373.07575 268.07983 412.22167 542.64078\n55 315.91750 125.74240 564.02740 411.96125 310.40560 440.51555 576.42717\n          43        44        45        46        47        48        49\n2                                                                       \n3                                                                       \n4                                                                       \n5                                                                       \n6                                                                       \n7                                                                       \n8                                                                       \n9                                                                       \n10                                                                      \n11                                                                      \n12                                                                      \n13                                                                      \n14                                                                      \n15                                                                      \n16                                                                      \n17                                                                      \n18                                                                      \n19                                                                      \n20                                                                      \n21                                                                      \n22                                                                      \n23                                                                      \n24                                                                      \n25                                                                      \n26                                                                      \n27                                                                      \n28                                                                      \n29                                                                      \n30                                                                      \n31                                                                      \n32                                                                      \n33                                                                      \n34                                                                      \n35                                                                      \n36                                                                      \n37                                                                      \n38                                                                      \n39                                                                      \n40                                                                      \n41                                                                      \n42                                                                      \n43                                                                      \n44 107.16213                                                            \n45 316.91914 221.84918                                                  \n46 186.28225 288.27478 486.91951                                        \n47 337.48335 295.38434 343.38498 497.61245                              \n48 444.26274 350.91512 146.61572 599.57407 476.62610                    \n49 282.22935 184.10672 131.55208 455.91617 331.69981 232.32965          \n50 631.99123 535.95620 330.76503 803.08034 510.79265 272.03299 419.06087\n51 217.08047 175.35413 323.95988 374.58247 225.25026 453.86726 246.76592\n52 245.95083 146.38284 146.78891 429.98509 229.09986 278.95182 130.39336\n53 203.87199 186.11584 312.85089 287.73864 475.33116 387.71518 261.75211\n54 429.95076 332.02048 127.42203 592.65262 447.05580  47.79331 196.60826\n55 466.20497 368.20978 153.22576 631.49232 448.58030  68.67929 242.15271\n          50        51        52        53        54\n2                                                   \n3                                                   \n4                                                   \n5                                                   \n6                                                   \n7                                                   \n8                                                   \n9                                                   \n10                                                  \n11                                                  \n12                                                  \n13                                                  \n14                                                  \n15                                                  \n16                                                  \n17                                                  \n18                                                  \n19                                                  \n20                                                  \n21                                                  \n22                                                  \n23                                                  \n24                                                  \n25                                                  \n26                                                  \n27                                                  \n28                                                  \n29                                                  \n30                                                  \n31                                                  \n32                                                  \n33                                                  \n34                                                  \n35                                                  \n36                                                  \n37                                                  \n38                                                  \n39                                                  \n40                                                  \n41                                                  \n42                                                  \n43                                                  \n44                                                  \n45                                                  \n46                                                  \n47                                                  \n48                                                  \n49                                                  \n50                                                  \n51 585.70558                                        \n52 410.49230 188.89405                              \n53 629.43339 304.21734 295.35984                    \n54 271.82672 421.06366 249.74161 377.52279          \n55 210.48485 450.97869 270.79121 430.02019  63.67613"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#hierachial-clustering",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#hierachial-clustering",
    "title": "hands on exercise 9",
    "section": "",
    "text": "hclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\n\nplot(hclust_ward, cex = 0.6)\n\n\n\n\n\n\n\n\nFind the optimal clustering algorithm:\n\nm &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#optimal-cluster",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#optimal-cluster",
    "title": "hands on exercise 9",
    "section": "",
    "text": "set.seed(12345)\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\n\nfviz_gap_stat(gap_stat)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#dendrograms",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#dendrograms",
    "title": "hands on exercise 9",
    "section": "",
    "text": "plot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n\n\n\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#cluster-mapping",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#cluster-mapping",
    "title": "hands on exercise 9",
    "section": "",
    "text": "groups &lt;- as.factor(cutree(hclust_ward, k=6))\n\n(retain the 6 as suggested earlier on by optimal cluster count where cluster count != 1)\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\n\nqtm(shan_sf_cluster, \"CLUSTER\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#spatially-constrained-clustering-skater-approach",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#spatially-constrained-clustering-skater-approach",
    "title": "hands on exercise 9",
    "section": "",
    "text": "First, we need to convert shan_sf into SpatialPolygonsDataFrame. This is because SKATER function only support sp objects such as SpatialPolygonDataFrame.\n\nshan_sp &lt;- as_Spatial(shan_sf)\n\n\nshan.nb &lt;- poly2nb(shan_sp)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\n\ncoords &lt;- st_coordinates(\n  st_centroid(st_geometry(shan_sf)))\n\n\nplot(st_geometry(shan_sf), \n     border=grey(.5))\nplot(shan.nb,\n     coords, \n     col=\"blue\", \n     add=TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#minimum-spanning-tree",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#minimum-spanning-tree",
    "title": "hands on exercise 9",
    "section": "",
    "text": "lcosts &lt;- nbcosts(shan.nb, shan_ict)\n\n\nshan.w &lt;- nb2listw(shan.nb, \n                   lcosts, \n                   style=\"B\")\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n\n\n\nshan.mst &lt;- mstree(shan.w)\n\n\nclass(shan.mst)\n\n[1] \"mst\"    \"matrix\"\n\n\n\ndim(shan.mst)\n\n[1] 54  3\n\n\n\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]   54   48  47.79331\n[2,]   54   17 109.08506\n[3,]   54   45 127.42203\n[4,]   45   52 146.78891\n[5,]   52   13 110.55197\n[6,]   13   28  92.79567\n\n\n\nplot(st_geometry(shan_sf), \n                 border=gray(.5))\nplot.mst(shan.mst, \n         coords, \n         col=\"blue\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)\n\n\n\n\n\n\n\n\n\nclust6 &lt;- spdep::skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\n\n\nstr(clust6)\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 52 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 25 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 1458\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\n\nccs6 &lt;- clust6$groups\nccs6\n\n [1] 3 3 6 3 3 3 3 3 3 3 2 1 1 1 2 1 1 1 2 4 1 2 5 1 1 1 2 1 2 2 1 2 2 1 1 3 1 2\n[39] 2 2 2 2 2 4 1 3 2 1 1 1 2 1 2 1 1\n\n\n\ntable(ccs6)\n\nccs6\n 1  2  3  4  5  6 \n22 18 11  2  1  1 \n\n\nplot the pruned tree based off mst:\n\nplot(st_geometry(shan_sf), \n     border=gray(.5))\nplot(clust6, \n     coords, \n     cex.lab=.7,\n     groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"pink\"),\n     cex.circles=0.005, \n     add=TRUE)\n\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter\nWarning in segments(coords[id1, 1], coords[id1, 2], coords[id2, 1], coords[id2,\n: \"add\" is not a graphical parameter"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#cluster-visualation-through-chloropeth",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#cluster-visualation-through-chloropeth",
    "title": "hands on exercise 9",
    "section": "",
    "text": "groups_mat &lt;- as.matrix(clust6$groups)\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\n\n\n\n\n\n\nhclust.map &lt;- qtm(shan_sf_cluster,\n                  \"CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\nshclust.map &lt;- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(hclust.map, shclust.map,\n             asp=NA, ncol=2)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#spatially-constrained-clustering-clustgeo-method",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#spatially-constrained-clustering-clustgeo-method",
    "title": "hands on exercise 9",
    "section": "",
    "text": "To perform non-spatially constrained hierarchical clustering, we only need to provide the function a dissimilarity matrix.\n\nnongeo_cluster &lt;- hclustgeo(proxmat)\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n\n\n\ngroups &lt;- as.factor(cutree(nongeo_cluster, k=6))\n\n\nshan_sf_ngeo_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\n\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\n\ndist &lt;- st_distance(shan_sf, shan_sf)\ndistmat &lt;- as.dist(dist)\n\n\ncr &lt;- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclustG &lt;- hclustgeo(proxmat, distmat, alpha = 0.2)\n\n\ngroups &lt;- as.factor(cutree(clustG, k=6))\n\n\nshan_sf_Gcluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\n\nqtm(shan_sf_Gcluster, \"CLUSTER\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#clustering-variable",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#clustering-variable",
    "title": "hands on exercise 9",
    "section": "",
    "text": "ggplot(data = shan_sf_ngeo_cluster,\n       aes(x = CLUSTER, y = RADIO_PR)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nCluster 3 displays the highest mean Radio Ownership Per Thousand Household.\n\nggparcoord(data = shan_sf_ngeo_cluster, \n           columns = c(17:21), \n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\nThe parallel coordinate plot above reveals that households in Cluster 4 townships tend to own the highest number of TV and mobile-phone. On the other hand, households in Cluster 5 tends to own the lowest of all the five ICT.\nThe scale argument of ggparcoor() provide several methods to scale the clustering variables.\n\nstd: univariately, subtract mean and divide by standard deviation.\nrobust: univariately, subtract median and divide by median absolute deviation.\nuniminmax: univariately, scale so the minimum of the variable is zero, and the maximum is one.\nglobalminmax: no scaling is done; the range of the graphs is defined by the global minimum and the global maximum.\ncenter: use uniminmax to standardize vertical height, then center each variable at a value specified by the scaleSummary param.\ncenterObs: use uniminmax to standardize vertical height, then center each variable at the value of the observation specified by the centerObsID param\n\n\nshan_sf_ngeo_cluster %&gt;% \n  st_set_geometry(NULL) %&gt;%\n  group_by(CLUSTER) %&gt;%\n  summarise(mean_RADIO_PR = mean(RADIO_PR),\n            mean_TV_PR = mean(TV_PR),\n            mean_LLPHONE_PR = mean(LLPHONE_PR),\n            mean_MPHONE_PR = mean(MPHONE_PR),\n            mean_COMPUTER_PR = mean(COMPUTER_PR))\n\n# A tibble: 6 × 6\n  CLUSTER mean_RADIO_PR mean_TV_PR mean_LLPHONE_PR mean_MPHONE_PR\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n1 1               221.        521.            44.2           246.\n2 2               237.        402.            23.9           134.\n3 3               300.        611.            52.2           392.\n4 4               196.        744.            99.0           651.\n5 5               124.        224.            38.0           132.\n6 6                98.6       499.            74.5           468.\n# ℹ 1 more variable: mean_COMPUTER_PR &lt;dbl&gt;"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex11.html",
    "href": "Hands-on_Ex/Hands-on_Ex11.html",
    "title": "hands on ex 11",
    "section": "",
    "text": "pacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)\n\n\n\n\n\n\n\nmpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\n\n\n\n\nmpsz_svy21 &lt;- st_transform(mpsz, 3414)\n\n\nst_crs(mpsz_svy21)\n\n\nst_bbox(mpsz_svy21) #view extent\n\n\n\n\n\n\n\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\n\nglimpse(condo_resale)\n\n\nhead(condo_resale$LONGITUDE) #see the data in XCOORD column\n\n\nhead(condo_resale$LATITUDE) #see the data in YCOORD column\n\n\nsummary(condo_resale)\n\n\n\n\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %&gt;%\n  st_transform(crs=3414)\n\n\n\n\n\n\n\n\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nThe figure above reveals a right skewed distribution. This means that more condominium units were transacted at relative lower prices.\n\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nThe distribution is relatively less skewed after the transformation.\n\n\n\n\nAREA_SQM &lt;- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE &lt;- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)\n\n\n\n\n\ntmap_mode(\"view\")\n\ntm_shape(mpsz_svy21)+\n  tm_polygons() +  \n  tmap_options(check.and.fix = TRUE) \ntm_shape(condo_resale.sf) +  \n  tmap_options(check.and.fix = TRUE) +\n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\n\ncondo.slr &lt;- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\n\nsummary(condo.slr)\n\nThe output report reveals that the SELLING_PRICE can be explained by using the formula:\n  *y = -258121.1 + 14719x1*\nThe R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince p-value is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.\nThe Coefficients: section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\n\n\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\n\ncondo.mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\n\n\n\n\ncondo.mlr1 &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n\n\n\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %&gt;% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\nols_vif_tol(condo.mlr1)\n\n\n\n\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\n\nols_plot_resid_hist(condo.mlr1)\n\n\nols_test_normality(condo.mlr1)\n\n\n\n\n\nmlr.output &lt;- as.data.frame(condo.mlr1$residuals)\n\n\ncondo_resale.res.sf &lt;- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %&gt;%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\n\ncondo_resale.sp &lt;- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\n\ntmap_mode(\"view\")\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\ntmap_mode(\"plot\")\n\nnb &lt;- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\n\nnb_lw &lt;- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\n\nlm.morantest(condo.mlr1, nb_lw)\n\n\n\n\n\n\n\n\n\n\nThere are two possible approaches can be uused to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using approach argeement.\n\nbw.fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\n\n\n\n\ngwr.fixed &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                         FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\n\ngwr.fixed\n\nThe report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the globel multiple linear regression model of 42967.1.\n\n\n\n\n\n\n\nbw.adaptive &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\n\n\n\n\ngwr.adaptive &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale.sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\n\ngwr.adaptive\n\n\n\n\n\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:\nCondition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.\n\nLocal R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\n\nPredicted: these are the estimated (or fitted) y values 3. computed by GWR.\n\nResiduals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produce by using these values.\n\nCoefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.\nThey are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called SDF of the output list.\n\n\n\n\ncondo_resale.sf.adaptive &lt;- st_as_sf(gwr.adaptive$SDF) %&gt;%\n  st_transform(crs=3414)\n\n\ncondo_resale.sf.adaptive.svy21 &lt;- st_transform(condo_resale.sf.adaptive, 3414)\ncondo_resale.sf.adaptive.svy21  \n\n\ngwr.adaptive.output &lt;- as.data.frame(gwr.adaptive$SDF)\ncondo_resale.sf.adaptive &lt;- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\n\nglimpse(condo_resale.sf.adaptive)\n\n\n\n\n\ntmap_mode(\"view\")\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\ntmap_mode(\"view\")\nAREA_SQM_SE &lt;- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV &lt;- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\n\n\n\ntm_shape(mpsz_svy21[mpsz_svy21$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex11.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex11.html#getting-started",
    "title": "hands on ex 11",
    "section": "",
    "text": "pacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex11.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex11.html#geospatial-data-wrangling",
    "title": "hands on ex 11",
    "section": "",
    "text": "mpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\n\n\n\n\nmpsz_svy21 &lt;- st_transform(mpsz, 3414)\n\n\nst_crs(mpsz_svy21)\n\n\nst_bbox(mpsz_svy21) #view extent"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex11.html#aspatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex11.html#aspatial-data-wrangling",
    "title": "hands on ex 11",
    "section": "",
    "text": "condo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\n\nglimpse(condo_resale)\n\n\nhead(condo_resale$LONGITUDE) #see the data in XCOORD column\n\n\nhead(condo_resale$LATITUDE) #see the data in YCOORD column\n\n\nsummary(condo_resale)\n\n\n\n\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %&gt;%\n  st_transform(crs=3414)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex11.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex11.html#exploratory-data-analysis-eda",
    "title": "hands on ex 11",
    "section": "",
    "text": "ggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nThe figure above reveals a right skewed distribution. This means that more condominium units were transacted at relative lower prices.\n\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nThe distribution is relatively less skewed after the transformation.\n\n\n\n\nAREA_SQM &lt;- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE &lt;- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)\n\n\n\n\n\ntmap_mode(\"view\")\n\ntm_shape(mpsz_svy21)+\n  tm_polygons() +  \n  tmap_options(check.and.fix = TRUE) \ntm_shape(condo_resale.sf) +  \n  tmap_options(check.and.fix = TRUE) +\n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex11.html#hedonic-pricing-modelling-in-r",
    "href": "Hands-on_Ex/Hands-on_Ex11.html#hedonic-pricing-modelling-in-r",
    "title": "hands on ex 11",
    "section": "",
    "text": "condo.slr &lt;- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\n\nsummary(condo.slr)\n\nThe output report reveals that the SELLING_PRICE can be explained by using the formula:\n  *y = -258121.1 + 14719x1*\nThe R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince p-value is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.\nThe Coefficients: section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\n\n\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\n\ncondo.mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\n\n\n\n\ncondo.mlr1 &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n\n\n\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %&gt;% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\nols_vif_tol(condo.mlr1)\n\n\n\n\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\n\nols_plot_resid_hist(condo.mlr1)\n\n\nols_test_normality(condo.mlr1)\n\n\n\n\n\nmlr.output &lt;- as.data.frame(condo.mlr1$residuals)\n\n\ncondo_resale.res.sf &lt;- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %&gt;%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\n\ncondo_resale.sp &lt;- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\n\ntmap_mode(\"view\")\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\ntmap_mode(\"plot\")\n\nnb &lt;- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\n\nnb_lw &lt;- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\n\nlm.morantest(condo.mlr1, nb_lw)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex11.html#building-hedonic-pricing-models-using-gwmodel",
    "href": "Hands-on_Ex/Hands-on_Ex11.html#building-hedonic-pricing-models-using-gwmodel",
    "title": "hands on ex 11",
    "section": "",
    "text": "There are two possible approaches can be uused to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using approach argeement.\n\nbw.fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\n\n\n\n\ngwr.fixed &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                         FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\n\ngwr.fixed\n\nThe report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the globel multiple linear regression model of 42967.1.\n\n\n\n\n\n\n\nbw.adaptive &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\n\n\n\n\ngwr.adaptive &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale.sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\n\ngwr.adaptive\n\n\n\n\n\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:\nCondition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.\n\nLocal R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\n\nPredicted: these are the estimated (or fitted) y values 3. computed by GWR.\n\nResiduals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produce by using these values.\n\nCoefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.\nThey are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called SDF of the output list.\n\n\n\n\ncondo_resale.sf.adaptive &lt;- st_as_sf(gwr.adaptive$SDF) %&gt;%\n  st_transform(crs=3414)\n\n\ncondo_resale.sf.adaptive.svy21 &lt;- st_transform(condo_resale.sf.adaptive, 3414)\ncondo_resale.sf.adaptive.svy21  \n\n\ngwr.adaptive.output &lt;- as.data.frame(gwr.adaptive$SDF)\ncondo_resale.sf.adaptive &lt;- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\n\nglimpse(condo_resale.sf.adaptive)\n\n\n\n\n\ntmap_mode(\"view\")\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\ntmap_mode(\"view\")\nAREA_SQM_SE &lt;- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV &lt;- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\n\n\n\ntm_shape(mpsz_svy21[mpsz_svy21$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02.html",
    "title": "In Class Exercise 2: IS415-GAA",
    "section": "",
    "text": "The code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tidyverse)\n\n\n\nTwo data sets will be used in this in class exercise.\n\nGEOSPATIAL: Master Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in SHP and KML format [ data.gov.sg ]\nGEOSPATIAL: Master Plan 2019 Subzone Boundary (No Sea) in KML format.\n\nThe code chunk below imports shapefile for MP14.\n\nmpsz14_shp &lt;- st_read(dsn = \"data/MasterPlan2014SubzoneBoundaryWebSHP\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\jechaxu\\IS415-GAA\\In-class_Ex\\data\\MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nclass(mpsz14_shp)\n\n[1] \"sf\"         \"data.frame\"\n\n\nThe original KML file provided by data.gov.sg was corrupted and thus was unable to be read using sf.\nTo resolve this, we rewrite over the file. We also rename the file to a more readable file name.\n\nst_write(mpsz14_shp,\n         \"data/MP14_SUBZONE_WEB_PL.kml\",\n          delete_dsn = TRUE)\n\nThe code chunk below imports KML file into R for MP14.\n\nmpsz14_kml &lt;- st_read(\"data/MP14_SUBZONE_WEB_PL.kml\")\n\nThe code chunks below imports MP19 in SHP and KML.\n\nmpsz19_shp &lt;- st_read(dsn = \"data/MPSZ-2019\", \n                  layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\jechaxu\\IS415-GAA\\In-class_Ex\\data\\MPSZ-2019' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz19_kml &lt;- st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\jechaxu\\IS415-GAA\\In-class_Ex\\data\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\npreschool &lt;- st_read(\"data/PreSchoolsLocation.kml\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\jechaxu\\IS415-GAA\\In-class_Ex\\data\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nst_crs(mpsz19_shp)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\npopdata &lt;- read.csv(\"data/respopagesextod2023.csv\")\n\n\n\n\n\npopdata2023 &lt;- popdata  %&gt;%\n  group_by(PA, SZ, AG)  %&gt;%\n  summarise(`POP`=sum(`Pop`))  %&gt;%\n  ungroup()  %&gt;%\n  pivot_wider(names_from = AG,\n              values_from = POP)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n  colnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\"\n\n\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate(YOUNG = rowSums(.[3:6]) \n         + rowSums(.[14])) %&gt;%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13]) \n         + rowSums(.[15]))%&gt;%\n  mutate(`AGED`=rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n  /`ECONOMY ACTIVE`) %&gt;%\n    select(`PA`, `SZ`, `YOUNG`, \n         `ECONOMY ACTIVE`, `AGED`, \n         `TOTAL`, `DEPENDENCY`)\n\nchange to all uppercase so a left join is possible\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper))\n\n\nmpsz_pop2023 &lt;- left_join(mpsz19_shp, popdata2023,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\npop2023_mpsz &lt;- left_join(popdata2023, mpsz19_shp, \n                          by = c(\"SZ\" = \"SUBZONE_N\"))\n\nthe difference between the left join code chunks is which one you are keeping – ‘subzone_n’ column or ‘sz’ column"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#getting-started",
    "href": "In-class_Ex/In-class_Ex02.html#getting-started",
    "title": "In Class Exercise 2: IS415-GAA",
    "section": "",
    "text": "The code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tidyverse)\n\n\n\nTwo data sets will be used in this in class exercise.\n\nGEOSPATIAL: Master Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in SHP and KML format [ data.gov.sg ]\nGEOSPATIAL: Master Plan 2019 Subzone Boundary (No Sea) in KML format.\n\nThe code chunk below imports shapefile for MP14.\n\nmpsz14_shp &lt;- st_read(dsn = \"data/MasterPlan2014SubzoneBoundaryWebSHP\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\jechaxu\\IS415-GAA\\In-class_Ex\\data\\MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nclass(mpsz14_shp)\n\n[1] \"sf\"         \"data.frame\"\n\n\nThe original KML file provided by data.gov.sg was corrupted and thus was unable to be read using sf.\nTo resolve this, we rewrite over the file. We also rename the file to a more readable file name.\n\nst_write(mpsz14_shp,\n         \"data/MP14_SUBZONE_WEB_PL.kml\",\n          delete_dsn = TRUE)\n\nThe code chunk below imports KML file into R for MP14.\n\nmpsz14_kml &lt;- st_read(\"data/MP14_SUBZONE_WEB_PL.kml\")\n\nThe code chunks below imports MP19 in SHP and KML.\n\nmpsz19_shp &lt;- st_read(dsn = \"data/MPSZ-2019\", \n                  layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\jechaxu\\IS415-GAA\\In-class_Ex\\data\\MPSZ-2019' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz19_kml &lt;- st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\jechaxu\\IS415-GAA\\In-class_Ex\\data\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\npreschool &lt;- st_read(\"data/PreSchoolsLocation.kml\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\jechaxu\\IS415-GAA\\In-class_Ex\\data\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nst_crs(mpsz19_shp)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\npopdata &lt;- read.csv(\"data/respopagesextod2023.csv\")\n\n\n\n\n\npopdata2023 &lt;- popdata  %&gt;%\n  group_by(PA, SZ, AG)  %&gt;%\n  summarise(`POP`=sum(`Pop`))  %&gt;%\n  ungroup()  %&gt;%\n  pivot_wider(names_from = AG,\n              values_from = POP)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n  colnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\"\n\n\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate(YOUNG = rowSums(.[3:6]) \n         + rowSums(.[14])) %&gt;%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13]) \n         + rowSums(.[15]))%&gt;%\n  mutate(`AGED`=rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n  /`ECONOMY ACTIVE`) %&gt;%\n    select(`PA`, `SZ`, `YOUNG`, \n         `ECONOMY ACTIVE`, `AGED`, \n         `TOTAL`, `DEPENDENCY`)\n\nchange to all uppercase so a left join is possible\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper))\n\n\nmpsz_pop2023 &lt;- left_join(mpsz19_shp, popdata2023,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\npop2023_mpsz &lt;- left_join(popdata2023, mpsz19_shp, \n                          by = c(\"SZ\" = \"SUBZONE_N\"))\n\nthe difference between the left join code chunks is which one you are keeping – ‘subzone_n’ column or ‘sz’ column"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04.html",
    "title": "In-class_Ex04",
    "section": "",
    "text": "For the purpose of this study, 6 R packages will be used.\nThey are sf, raster, spatstat, sparr, tmap, tidyverse.\n\npacman::p_load(sf, st, tidyverse, raster, tmap, spatstat, sparr, dplyr)\n\n\n\n\nThe file is in ESRI shapefile format.\n\nkbb &lt;- st_read(dsn=\"data/rawdata\",\n               layer=\"Kepulauan_Bangka_Belitung\")\n\nNext, we import the forest fire data which is in CSV format.\n\nfire_sf &lt;- read_csv(\"data/rawdata/forestfires.csv\") %&gt;%\n  st_as_sf(coords =c(\"longitude\", \"latitude\"),\n           crs = 4326) %&gt;%\nst_transform(crs = 32748)\n\nRows: 741 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): satellite, instrument, daynight\ndbl  (11): latitude, longitude, brightness, scan, track, acq_time, confidenc...\ndate  (1): acq_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nfire_sf &lt;- fire_sf %&gt;%\n  mutate(DayofYear = yday(acq_date)) %&gt;%\n  mutate(Month_num = month(acq_date)) %&gt;%\n  mutate(Month_fac = month(acq_date,\n                           label = TRUE,\n                           abbr = FALSE))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html#getting-started",
    "href": "In-class_Ex/In-class_Ex04.html#getting-started",
    "title": "In-class_Ex04",
    "section": "",
    "text": "For the purpose of this study, 6 R packages will be used.\nThey are sf, raster, spatstat, sparr, tmap, tidyverse.\n\npacman::p_load(sf, st, tidyverse, raster, tmap, spatstat, sparr, dplyr)\n\n\n\n\nThe file is in ESRI shapefile format.\n\nkbb &lt;- st_read(dsn=\"data/rawdata\",\n               layer=\"Kepulauan_Bangka_Belitung\")\n\nNext, we import the forest fire data which is in CSV format.\n\nfire_sf &lt;- read_csv(\"data/rawdata/forestfires.csv\") %&gt;%\n  st_as_sf(coords =c(\"longitude\", \"latitude\"),\n           crs = 4326) %&gt;%\nst_transform(crs = 32748)\n\nRows: 741 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): satellite, instrument, daynight\ndbl  (11): latitude, longitude, brightness, scan, track, acq_time, confidenc...\ndate  (1): acq_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nfire_sf &lt;- fire_sf %&gt;%\n  mutate(DayofYear = yday(acq_date)) %&gt;%\n  mutate(Month_num = month(acq_date)) %&gt;%\n  mutate(Month_fac = month(acq_date,\n                           label = TRUE,\n                           abbr = FALSE))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html#data-wrangling",
    "href": "In-class_Ex/In-class_Ex04.html#data-wrangling",
    "title": "In-class_Ex04",
    "section": "Data Wrangling",
    "text": "Data Wrangling\nif there are z entities, you most likely will have to drop it (it will cause issues to this exercise in this case)\nThe revised code chunk is as shown below.\n\nkbb_sf &lt;- st_read(dsn=\"data/rawdata\",\n               layer=\"Kepulauan_Bangka_Belitung\") %&gt;%\nst_union() %&gt;%\n  st_zm(drop = TRUE, what = \"ZM\") %&gt;%\n  st_transform(crs = 32748)\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `C:\\jechaxu\\IS415-GAA\\In-class_Ex\\data\\rawdata' using driver `ESRI Shapefile'\nSimple feature collection with 298 features and 27 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nst_as_s2(): dropping Z and/or M coordinate\n\n\n\nConverting OWIN\n\nkbb_owin &lt;- as.owin(kbb_sf)\nkbb_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n\n\nclass() is used to confirm if the output is indeed an owin object\n\nclass(kbb_owin)\n\n[1] \"owin\""
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html#overall-plot",
    "href": "In-class_Ex/In-class_Ex04.html#overall-plot",
    "title": "In-class_Ex04",
    "section": "Overall Plot",
    "text": "Overall Plot\nalways polygon first, followed by dot then line\n\ntm_shape(kbb_sf) +\n  tm_polygons() +\ntm_shape(fire_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\n\ntm_shape(kbb_sf) +\n  tm_polygons() +\ntm_shape(fire_sf) +\n  tm_dots(size = 0.1) +\ntm_facets(by = \"Month_fac\",\n          free.coords = FALSE,\n          drop.units = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html#computing-stkde-by-month",
    "href": "In-class_Ex/In-class_Ex04.html#computing-stkde-by-month",
    "title": "In-class_Ex04",
    "section": "Computing STKDE by month",
    "text": "Computing STKDE by month\n\nfire_month &lt;- fire_sf %&gt;%\n  dplyr::select(Month_num)\n\n\nfire_month_ppp &lt;- as.ppp(fire_month)\nfire_month_ppp\n\nMarked planar point pattern: 741 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n\n\n\nsummary(fire_month_ppp)\n\nMarked planar point pattern:  741 points\nAverage intensity 2.49258e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n                    (174200 x 170600 units)\nWindow area = 29728200000 square units\n\n\n\nany(duplicated(fire_month_ppp))\n\n[1] FALSE\n\n\n\nfire_month_owin &lt;- fire_month_ppp[kbb_owin]\nsummary(fire_month_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.424519e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: polygonal boundary\n2 separate polygons (no holes)\n           vertices        area relative.area\npolygon 1     47493 11533600000      1.00e+00\npolygon 2       256      306427      2.66e-05\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533900000 square units\nFraction of frame area: 0.334\n\n\n\nComputing Spatio-Temporal KDE\n\nst_kde &lt;- spattemp.density(fire_month_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 0.0304 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [1.233458e-27, 8.202976e-10]\n\n\n\ntims &lt;- c(7, 8, 9, 10, 11, 12)\npar(mfcol=c(2,3))\nfor (i in tims){\n  plot(st_kde, i,\n       override.par = FALSE,\n       fix.range = TRUE,\n       main = paste(\"KDE at month\", i))\n}\n\n\n\n\n\n\n\n\nfire_yday_ppp &lt;- fire_sf %&gt;% select(DayofYear)\nkde_yday &lt;- spattemp.density( fire_yday_owin) summary(kde_yday)\nplot(kde_yday)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06.html",
    "title": "In Class Exercise 6",
    "section": "",
    "text": "Getting Started\n\npacman::p_load(sf, tmap, sfdep, tidyverse)\n\n\nhunan &lt;- st_read(dsn = \"data\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source `C:\\jechaxu\\IS415-GAA\\In-class_Ex\\data' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nhunan2012 &lt;- read_csv(\"data/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nhunan &lt;- left_join(hunan,hunan2012)%&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\nderivings queens contiguity\n\nwm_q &lt;- hunan %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before=1)\n\n\nmoranI &lt;- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\n\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\nPerforming Global Moran’s I test\n\nglobal_moran_test(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nPerforming Global Moran’I permutation test\n\nset.seed(1234)\n\n\nglobal_moran_perm(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\nlisa &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\nlisa_sig &lt;- lisa  %&gt;%\n  filter(p_ii &lt; 0.05)\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\nwm_idw &lt;- hunan %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wts = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\n\nHCSA &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\nHCSA\n\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 19\n   gi_star cluster   e_gi     var_gi std_dev p_value p_sim p_folded_sim skewness\n     &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.0416 Low     0.0114 0.00000641  0.0493 9.61e-1  0.7          0.35    0.875\n 2 -0.333  Low     0.0106 0.00000384 -0.0941 9.25e-1  1            0.5     0.661\n 3  0.281  High    0.0126 0.00000751 -0.151  8.80e-1  0.9          0.45    0.640\n 4  0.411  High    0.0118 0.00000922  0.264  7.92e-1  0.6          0.3     0.853\n 5  0.387  High    0.0115 0.00000956  0.339  7.34e-1  0.62         0.31    1.07 \n 6 -0.368  High    0.0118 0.00000591 -0.583  5.60e-1  0.72         0.36    0.594\n 7  3.56   High    0.0151 0.00000731  2.61   9.01e-3  0.06         0.03    1.09 \n 8  2.52   High    0.0136 0.00000614  1.49   1.35e-1  0.2          0.1     1.12 \n 9  4.56   High    0.0144 0.00000584  3.53   4.17e-4  0.04         0.02    1.23 \n10  1.16   Low     0.0104 0.00000370  1.82   6.86e-2  0.12         0.06    0.416\n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis &lt;dbl&gt;, nb &lt;nb&gt;, wts &lt;list&gt;, NAME_2 &lt;chr&gt;,\n#   ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;, ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;,\n#   geometry &lt;POLYGON [°]&gt;\n\n\n\n# HCSA_sig &lt;- HCSA %&gt;%\n#  filter(p_sim &lt; 0.05)\n# tmap_mode(\"plot\")\n#tm_shape(HCSA) +\n#  tm_polygons() +\n#  tm_borders(alpha = 0.5) +\n#tm_shape(HCSA_sig) +\n#  tm_fill(\"gi_star\") +\n#  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "Welcome to IS415 Geospatial Analytics and Applications.\nIn this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "Take-home_Ex/2/Take-home_Ex02.html",
    "href": "Take-home_Ex/2/Take-home_Ex02.html",
    "title": "Hands On Exercise 2",
    "section": "",
    "text": "Drug abuse is associated with significant negative health, financial and social consequences. Yet, illicit drug consumption remains highly prevalent and continues to be a growing problem worldwide.\nThe geopolitics of Thailand which is near the Golden Triangle of Indochina, the largest drug production site in Asia, and the constant transportation infrastructure development made Thailand became market and transit routes for drug trafficking to the third countries.\nIn Thailand, drug abuse is one of the major social issue. There are about 2.7 million youths using drugs in Thailand. Among youths aged between 15 and 19 years, there are about 300,000 who have needs for drug treatment. Most of Thai youths involved with drugs are vocational-school students, which nearly doubles in number compared to secondary-school students."
  },
  {
    "objectID": "Take-home_Ex/2/Take-home_Ex02.html#loading-packages-into-r",
    "href": "Take-home_Ex/2/Take-home_Ex02.html#loading-packages-into-r",
    "title": "Hands On Exercise 2",
    "section": "2.1 Loading packages into R",
    "text": "2.1 Loading packages into R\n\npacman::p_load(sf, st, tidyverse, raster, tmap, tmaptools, ggplot2, spatstat, sfdep)"
  },
  {
    "objectID": "Take-home_Ex/2/Take-home_Ex02.html#importing-the-datasets",
    "href": "Take-home_Ex/2/Take-home_Ex02.html#importing-the-datasets",
    "title": "Hands On Exercise 2",
    "section": "2.2 Importing the datasets",
    "text": "2.2 Importing the datasets\nFor the purpose of this take-home exercise, two data sets shall be used, they are:\n\nThailand Drug Offenses [2017-2022] at Kaggle.\nThailand - Subnational Administrative Boundaries at HDX. You are required to use the province boundary data set.\n\n\n2.2.1 Importing Thailand Drug Offenses (csv file)\nThe dataset, which we downloaded from Kaggle, is in csv format. The codes chunk below uses read_csv() function of readr package to import the dataset into R as a tibble data frame called drug_offences.\nThe data has also been transformed such it only contains cases of drug use.\n\ndrug_offences &lt;- read_csv(\"data/thai_drug_offenses_2017_2022.csv\")\n\n\n\n2.2.2 Importing Thailand Subnational Administrative Boundaries (shp)\n\nthailand_sf &lt;- read_sf(dsn = \"data\", \n                 layer = \"tha_admbnda_adm1_rtsd_20220121\") %&gt;%\n  st_as_sf(coords =c(\n    \"longitude\", \"latitude\"),\n           crs = 4326) %&gt;%\n  st_transform(crs = 24047)\n\n\nthailand_sf"
  },
  {
    "objectID": "Take-home_Ex/2/Take-home_Ex02.html#geospatial-data-wrangling",
    "href": "Take-home_Ex/2/Take-home_Ex02.html#geospatial-data-wrangling",
    "title": "Hands On Exercise 2",
    "section": "2.3 Geospatial Data Wrangling",
    "text": "2.3 Geospatial Data Wrangling\n\n2.3.1 Fixing province names\nThere is a mismatch of the province names between the datasets we are importing. We resolve this by changing the names of provinces in the drug offenses dataset to align.\n\nLoburi -&gt; Lop Buri\nBuogkan -&gt; Bueng Kan\n\n\ndrug_offences &lt;- drug_offences %&gt;% \n                  mutate(province_en = replace(province_en, province_en == 'buogkan', 'Bueng Kan')) %&gt;%\n                  mutate(province_en = replace(province_en, province_en == 'Loburi', 'Lop Buri'))\ndrug_offences\n\n\n\n2.3.2 Performing relational join\nThe code chunk below will be used to update the attribute table of thailand_sf’s SpatialPolygonsDataFrame with the attribute fields of drug_offenses dataframe. This is performed by using left_join() of dplyr package.\n\ndrug_offences_thailand &lt;- thailand_sf %&gt;%\n  left_join(drug_offences,\n            by = c(\"ADM1_EN\" = \"province_en\",\n                  \"ADM1_TH\" = \"province_th\")) %&gt;%\n  dplyr::select(1:2, 17:20)\n\n\ndrug_offences_thailand\n\n\ndrug_offences_thailand_sf &lt;- st_as_sf(drug_offences_thailand)\n\nst_crs(drug_offences_thailand_sf) &lt;- st_crs(thailand_sf)\n\nprint(st_crs(drug_offences_thailand_sf))\n\n\n\n2.3.3 Visualising Regional Development Indicator\nWe prepare a basemap and a choropleth map showing the distribution of drug offences by using qtm() of tmap package.\nDue to the large size of the dataset, we split the drug offences occurrences by their fiscal year to make it more convenient to process.\n\ndrug_offence_list &lt;- split(drug_offences_thailand, drug_offences_thailand$fiscal_year)\n\nIn the chunk of code below, we create a list to store the plots for each of the drug offences occurring during their respective fiscal year.\n\ntmap_mode(\"plot\")\n\n\nplot_list &lt;- list()\n\n# Loop through the list and create a plot for each year, storing them in plot_list\nfor (year in names(drug_offence_list)) {\n  p &lt;- tm_shape(drug_offence_list[[year]]) +\n      tm_fill(\"no_cases\",\n              n = 5,\n              style = \"quantile\",\n              title = \"Number of Cases\") +\n      tm_borders(alpha = 0.5) +\n      tm_layout(main.title = paste(\"EQC\", year),\n                legend.outside = TRUE,\n                legend.outside.position = \"right\")\n  \n  # Store the plot in the list\n  plot_list[[year]] &lt;- p\n}\n\n\ntmap_arrange(plotlist = plot_list, \n             ncol = 2, \n             nrow = 3)\n\nIt can be seen that drug offenses were most prevalent in 2017-2019, however tapered off in 2020. The most probable reason would likely due to Covid-19 resulting in the nationwide lockdown, which may hinder police reports and access to drugs from dealers.\nCases were also much more prevalent in the Southern area of Thailand, in comparison to the Northen provinces."
  },
  {
    "objectID": "Take-home_Ex/2/Take-home_Ex02.html#global-measures-of-spatial-autocorrelation",
    "href": "Take-home_Ex/2/Take-home_Ex02.html#global-measures-of-spatial-autocorrelation",
    "title": "Hands On Exercise 2",
    "section": "3.1 Global Measures of Spatial Autocorrelation",
    "text": "3.1 Global Measures of Spatial Autocorrelation\n\n3.1.1 Computing Contiguity Spatial Weights\nWe need to first construct a spatial weight of the study area, used to define the neighbourhood relationships between the provinces in Thailand.\nAs the dataset we are working with takes a significant time to process due to its large size, we choose to analyse only one fiscal year for efficiency. In this case, we have taken 2019 as it is the most prevalent before 2020 occurred.\n\ndrug_offence_list[[3]]\n\nWe then filter it such that we only address the drug use cases for now, to reduce the size of the dataset.\n\ndrug_use_2019 &lt;- drug_offence_list[[3]] %&gt;%\n  filter(types_of_drug_offenses == \"drug_use_cases\")\n\nWe now generate the neighbours list.\n\nwm_q_druguse_2019 &lt;- drug_use_2019 %&gt;%\n  mutate(nb = st_contiguity(geometry))\n\nThe dataset has Phuket as a province with no neighbors. The code chunk below manually fills it in using Phuket’s nearest neighbour.\n\nempty_index &lt;- 67 \nnearest_index &lt;- 68\n\nwm_q_druguse_2019$nb[[empty_index]] &lt;- as.integer(nearest_index)\n\n\nwm_q_druguse_2019 &lt;- wm_q_druguse_2019 %&gt;%\n  mutate(wt = st_weights(nb,\n                         style = \"W\"),\n         .before=1)\n\n\n\n3.1.2 Moran’s I test\nThe code chunk below performs Moran’s I statistical testing using moran.test() of sfdep.\n\nmoranI_druguse_2019 &lt;- global_moran(wm_q_druguse_2019$no_cases,\n                       wm_q_druguse_2019$nb,\n                       wm_q_druguse_2019$wt)\n\nglimpse(moranI_druguse_2019)\n\nPerforming Global Moran’s I test\n\nglobal_moran_test(wm_q_druguse_2019$no_cases,\n                  wm_q_druguse_2019$nb,\n                  wm_q_druguse_2019$wt)\n\n\n\n3.1.3 Monte Carlo simulation\nNext, global_moran_perm() is used to perform Monte Carlo simulation.\n\nglobal_moran_perm(wm_q_druguse_2019$no_cases,\n                  wm_q_druguse_2019$nb,\n                  wm_q_druguse_2019$wt,\n                  nsim = 99)\n\nThe statistical report shows that the p-value is larger than alpha value of 0.05. Hence, we have enough statistical evidence to prove that spatial distribution of drug use cases are not independent from geographical reasons.\nBecause the Moran’s I statistics is greater than 0. We can infer that the spatial distribution shows sign of clustering."
  },
  {
    "objectID": "Take-home_Ex/2/Take-home_Ex02.html#local-measures-of-spatial-autocorrelation",
    "href": "Take-home_Ex/2/Take-home_Ex02.html#local-measures-of-spatial-autocorrelation",
    "title": "Hands On Exercise 2",
    "section": "3.2 Local Measures of Spatial Autocorrelation",
    "text": "3.2 Local Measures of Spatial Autocorrelation\n\n3.2.1 Local Indicators of Spatial Association (LISA)\n\nlisa_druguse_2019 &lt;- wm_q_druguse_2019 %&gt;% \n  mutate(local_moran = local_moran(\n    no_cases, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n\ntmap_mode(\"plot\")\n\nThe output of local_moran() is a sf dataframe containing the following:\n\nii: local moran statistic\neii: expectation of local moran statistic\nvar_ii: variance of local moran statistic\nz_ii: standard deviate of local moran statistic\nskewness: the output of e1071::skewness() for the permutation samples underlying the standard deviates\nkurtosis: For localmoran_perm, the output of e1071::kurtosis() for the permutation samples underlying the standard deviates.\n\nIn this code chunk below, tmap functions are used prepare a choropleth map by using value in the ii field.\n\ntm_shape(lisa_druguse_2019) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of number of drug cases\",\n            main.title.size = 0.8)\n\nIn lisa sf data.frame, we can find three fields contain the LISA categories. They are mean, median and pysal. In general, classification in mean will be used as shown in the code chunk below.\n\nlisa_sig_druguse_2019 &lt;- lisa_druguse_2019  %&gt;%\n  filter(p_ii &lt; 0.05)\ntmap_mode(\"plot\")\n\n\ntm_shape(lisa_druguse_2019) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_druguse_2019) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n\nWe will need to derive a spatial weight matrix before we can compute local Gi* statistics\n\nwm_idw_druguse_2019 &lt;- wm_q_druguse_2019 %&gt;%\n  mutate(nb = include_self(\n    st_contiguity(geometry)),\n    wts = st_inverse_distance(nb, \n                              geometry, \n                              scale = 1,\n                              alpha = 1),\n         .before = 1)\n\nWe will now compute the local Gi* by using the code chunk below.\n\nHCSA_druguse_2019 &lt;- wm_idw_druguse_2019 %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    no_cases, nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\nIn the code chunk below, tmap functions are used to plot the local Gi* (i.e. gi_star) at the province level.\n\ntmap_mode(\"plot\")\ntm_shape(HCSA_druguse_2019) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\n\n3.2.1.1 P-value of HCSA\nIn the code chunk below, tmap functions are used to plot the p-values of local Gi* (i.e. p_sim) at the province level.\n\ntmap_mode(\"plot\")\ntm_shape(HCSA_druguse_2019) +\n  tm_fill(\"p_sim\") + \n  tm_borders(alpha = 0.5)\n\n\n\n3.2.1.2 Visualising local HCSA\n\ntmap_mode(\"plot\")\n\n\ndruguse_map1 &lt;- tm_shape(HCSA_druguse_2019) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of GDPPC\",\n            main.title.size = 0.8)\n\ndruguse_map2 &lt;- tm_shape(HCSA_druguse_2019) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(druguse_map1, druguse_map2, ncol = 2)\n\n\n\n3.2.1.3 Visualising hot spot and cold spot areas\n\ntmap_mode(\"plot\")\n\n\nHCSA_sig_druguse_2019 &lt;- HCSA_druguse_2019  %&gt;%\n  filter(p_sim &lt; 0.05)\n\ntm_shape(HCSA_druguse_2019) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig_druguse_2019) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4)\n\nThe figure indicates a cluster of high drug use cases around the capital Bangkok. This suggests that factors unique to Bangkok, such as socioeconomic conditions or accessibility to drug supply may contribute to higher occurrences."
  },
  {
    "objectID": "Take-home_Ex/2/Take-home_Ex02.html#local-measures-of-spatial-autocorrelation-1",
    "href": "Take-home_Ex/2/Take-home_Ex02.html#local-measures-of-spatial-autocorrelation-1",
    "title": "Hands On Exercise 2",
    "section": "4.2 Local Measures of Spatial Autocorrelation",
    "text": "4.2 Local Measures of Spatial Autocorrelation\n\n4.2.1 Local Indicators of Spatial Association (LISA)\n\nlisa_poss_2019 &lt;- wm_q_poss_2019 %&gt;% \n  mutate(local_moran = local_moran(\n    no_cases, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n\ntmap_mode(\"plot\")\n\nIn this code chunk below, tmap functions are used prepare a choropleth map by using value in the ii field.\n\ntm_shape(lisa_poss_2019) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of number of drug cases\",\n            main.title.size = 0.8)\n\nIn lisa sf data.frame, we can find three fields contain the LISA categories. They are mean, median and pysal. In general, classification in mean will be used as shown in the code chunk below.\n\nlisa_sig_poss_2019 &lt;- lisa_poss_2019  %&gt;%\n  filter(p_ii &lt; 0.05)\ntmap_mode(\"plot\")\n\n\ntm_shape(lisa_poss_2019) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_poss_2019) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n\nWe will need to derive a spatial weight matrix before we can compute local Gi* statistics\n\nwm_idw_poss_2019 &lt;- wm_q_poss_2019 %&gt;%\n  mutate(nb = include_self(\n    st_contiguity(geometry)),\n    wts = st_inverse_distance(nb, \n                              geometry, \n                              scale = 1,\n                              alpha = 1),\n         .before = 1)\n\nWe will now compute the local Gi* by using the code chunk below.\n\nHCSA_poss_2019 &lt;- wm_idw_poss_2019 %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    no_cases, nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\nIn the code chunk below, tmap functions are used to plot the local Gi* (i.e. gi_star) at the province level.\n\ntmap_mode(\"plot\")\ntm_shape(HCSA_poss_2019) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\n\n4.2.1.1 P-value of HCSA\nIn the code chunk below, tmap functions are used to plot the p-values of local Gi* (i.e. p_sim) at the province level.\n\ntmap_mode(\"plot\")\ntm_shape(HCSA_poss_2019) +\n  tm_fill(\"p_sim\") + \n  tm_borders(alpha = 0.5)\n\n\n\n4.2.1.2 Visualising local HCSA\n\ntmap_mode(\"plot\")\nposs_map1 &lt;- tm_shape(HCSA_poss_2019) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of GDPPC\",\n            main.title.size = 0.8)\n\nposs_map2 &lt;- tm_shape(HCSA_poss_2019) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(poss_map1, poss_map2, ncol = 2)\n\n\n\n4.2.1.3 Visualising hot spot and cold spot areas\n\nHCSA_sig_poss_2019 &lt;- HCSA_poss_2019  %&gt;%\n  filter(p_sim &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(HCSA_poss_2019) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig_poss_2019) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4)\n\nThe map indicates clusters of high drug possession cases in the northern and southern regions of Thailand, such as Samut Prakan and Chiang Mai. Samut Prakan has several transportation hubs, including Suvarnabhumi Airport. This could facilitate the movement of drugs into and out of the province. As for Chiang Mai, it has an influx of tourists which can be a reason for higher cases of drug possession."
  },
  {
    "objectID": "Take-home_Ex/2/Take-home_Ex02.html#local-measures-of-spatial-autocorrelation-2",
    "href": "Take-home_Ex/2/Take-home_Ex02.html#local-measures-of-spatial-autocorrelation-2",
    "title": "Hands On Exercise 2",
    "section": "5.2 Local Measures of Spatial Autocorrelation",
    "text": "5.2 Local Measures of Spatial Autocorrelation\n\n5.2.1 Local Indicators of Spatial Association (LISA)\n\nlisa_import_2019 &lt;- wm_q_import_2019 %&gt;% \n  mutate(local_moran = local_moran(\n    no_cases, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n\ntmap_mode(\"plot\")\n\nIn this code chunk below, tmap functions are used prepare a choropleth map by using value in the ii field.\n\ntm_shape(lisa_import_2019) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of import cases\",\n            main.title.size = 0.8)\n\nIn lisa sf data.frame, we can find three fields contain the LISA categories. They are mean, median and pysal. In general, classification in mean will be used as shown in the code chunk below.\n\nlisa_sig_import_2019 &lt;- lisa_import_2019  %&gt;%\n  filter(p_ii &lt; 0.05)\ntmap_mode(\"plot\")\n\n\ntm_shape(lisa_import_2019) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_import_2019) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n\nWe will need to derive a spatial weight matrix before we can compute local Gi* statistics\n\nwm_idw_import_2019 &lt;- wm_q_import_2019 %&gt;%\n  mutate(nb = include_self(\n    st_contiguity(geometry)),\n    wts = st_inverse_distance(nb, \n                              geometry, \n                              scale = 1,\n                              alpha = 1),\n         .before = 1)\n\nWe will now compute the local Gi* by using the code chunk below.\n\nHCSA_import_2019 &lt;- wm_idw_import_2019 %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    no_cases, nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\n\nHCSA_import_2019\n\nIn the code chunk below, tmap functions are used to plot the local Gi* (i.e. gi_star) at the province level.\n\ntmap_mode(\"plot\")\ntm_shape(HCSA_import_2019) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\n\n3.2.1.1 P-value of HCSA\nIn the code chunk below, tmap functions are used to plot the p-values of local Gi* (i.e. p_sim) at the province level.\n\ntmap_mode(\"plot\")\ntm_shape(HCSA_import_2019) +\n  tm_fill(\"p_sim\") + \n  tm_borders(alpha = 0.5)\n\n\n\n3.2.1.2 Visualising local HCSA\n\ntmap_mode(\"plot\")\nimport_map1 &lt;- tm_shape(HCSA_import_2019) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of GDPPC\",\n            main.title.size = 0.8)\n\nimport_map2 &lt;- tm_shape(HCSA_import_2019) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(import_map1, import_map2, ncol = 2)\n\n\n\n3.2.1.3 Visualising hot spot and cold spot areas\n\nHCSA_sig_import_2019 &lt;- HCSA_import_2019  %&gt;%\n  filter(p_sim &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(HCSA_import_2019) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig_import_2019) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4)\n\nPhatthalung, Songkhla, and Satun are considered transportation hubs in southern Thailand. They are connected via railway lines, ferries, and airports, which may be a reason why drug imports are very high there."
  },
  {
    "objectID": "Take-home_Ex/THE_3/Take-home_Ex03.html",
    "href": "Take-home_Ex/THE_3/Take-home_Ex03.html",
    "title": "take home exercise 3",
    "section": "",
    "text": "This study investigates the spatial distribution and evolution of crime in Malaysia over recent years. By employing advanced spatial analysis techniques, we aim to identify hotspots, coldspots, and emerging trends in crime patterns. Our analysis utilizes a comprehensive dataset of crime incidents, including location, type, and date of occurrence.\nThe exercise will focus only on one page consisting of all portions that I am responsible for. This includes:\n\nGlobal Spatial Autocorrelation (Moran’s I)\nLocal Spatial Autocorrelation (Local Moran’s I - LISA Map)"
  },
  {
    "objectID": "Take-home_Ex/THE_3/Take-home_Ex03.html#datasets-being-used",
    "href": "Take-home_Ex/THE_3/Take-home_Ex03.html#datasets-being-used",
    "title": "take home exercise 3",
    "section": "3.1 Datasets being used",
    "text": "3.1 Datasets being used\nThere are three datasets being used in this exercise.\n\nMalaysia – Crime by District and Crime Type from data.gov.my in csv format.\nMalaysia - Population Table: Administrative Districts from data.gov.my in csv format.\nMalaysia - Subnational Administrative Boundaries with included administrative regions in shapefile format.\n\n\ncrime_df &lt;- read_csv(\"data/aspatial/crime_district.csv\")\n\nRows: 19152 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): state, district, category, type\ndbl  (1): crimes\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npopulation_df &lt;- read_csv(\"data/aspatial/population_district.csv\")\n\nRows: 319200 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (5): state, district, sex, age, ethnicity\ndbl  (1): population\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNext, we import the administrative regions of Malaysia.\n\nmys_sf &lt;- read_sf(dsn = \"data/geospatial/mys_adm_unhcr_20210211_shp\", \n                 layer = \"mys_admbnda_adm2_unhcr_20210211\") %&gt;%\n          st_transform(crs = 3168)"
  },
  {
    "objectID": "Take-home_Ex/THE_3/Take-home_Ex03.html#wrangling",
    "href": "Take-home_Ex/THE_3/Take-home_Ex03.html#wrangling",
    "title": "take home exercise 3",
    "section": "3.2 Wrangling",
    "text": "3.2 Wrangling\n\n3.2.1 Data Preparation\nWe first identify the states in each dataset to pick out any inconsistencies to resolve.\n\nprint(\"Unique states in crime_df:\")\n\n[1] \"Unique states in crime_df:\"\n\nunique(crime_df$state)\n\n [1] \"Malaysia\"          \"Johor\"             \"Kedah\"            \n [4] \"Kelantan\"          \"Melaka\"            \"Negeri Sembilan\"  \n [7] \"Pahang\"            \"Perak\"             \"Perlis\"           \n[10] \"Pulau Pinang\"      \"Sabah\"             \"Sarawak\"          \n[13] \"Selangor\"          \"Terengganu\"        \"W.P. Kuala Lumpur\"\n\nprint(\"Unique states in population_df:\")\n\n[1] \"Unique states in population_df:\"\n\nunique(crime_df$state)\n\n [1] \"Malaysia\"          \"Johor\"             \"Kedah\"            \n [4] \"Kelantan\"          \"Melaka\"            \"Negeri Sembilan\"  \n [7] \"Pahang\"            \"Perak\"             \"Perlis\"           \n[10] \"Pulau Pinang\"      \"Sabah\"             \"Sarawak\"          \n[13] \"Selangor\"          \"Terengganu\"        \"W.P. Kuala Lumpur\"\n\nprint(\"Unique states in mys_sf:\")\n\n[1] \"Unique states in mys_sf:\"\n\nunique(mys_sf$ADM1_EN)\n\n [1] \"Johor\"             \"Kedah\"             \"Kelantan\"         \n [4] \"W.P. Kuala Lumpur\" \"W.P. Labuan\"       \"Melaka\"           \n [7] \"Negeri Sembilan\"   \"Pahang\"            \"Perak\"            \n[10] \"Perlis\"            \"Pulau Pinang\"      \"Sabah\"            \n[13] \"Sarawak\"           \"Terengganu\"        \"W.P. Putrajaya\"   \n[16] \"Selangor\"         \n\n\nWe then convert the state and district columns to upper case for matching.\n\ncrime_df &lt;- crime_df %&gt;%\n              mutate(year = year(date),\n                     state = toupper(state),\n                     district = toupper(district))\ncrime_df\n\n# A tibble: 19,152 × 7\n   state    district category type           date       crimes  year\n   &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;          &lt;date&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 MALAYSIA ALL      assault  all            2016-01-01  22327  2016\n 2 MALAYSIA ALL      assault  all            2017-01-01  21366  2017\n 3 MALAYSIA ALL      assault  all            2018-01-01  16902  2018\n 4 MALAYSIA ALL      assault  all            2019-01-01  16489  2019\n 5 MALAYSIA ALL      assault  all            2020-01-01  13279  2020\n 6 MALAYSIA ALL      assault  all            2021-01-01  11495  2021\n 7 MALAYSIA ALL      assault  all            2022-01-01  10348  2022\n 8 MALAYSIA ALL      assault  all            2023-01-01  10453  2023\n 9 MALAYSIA ALL      assault  causing_injury 2016-01-01   5531  2016\n10 MALAYSIA ALL      assault  causing_injury 2017-01-01   5024  2017\n# ℹ 19,142 more rows\n\n\n\npopulation_df &lt;- population_df %&gt;%\n              mutate(year = year(date),\n                     state = toupper(state),\n                     district = toupper(district))\npopulation_df\n\n# A tibble: 319,200 × 8\n   state district   date       sex   age     ethnicity        population  year\n   &lt;chr&gt; &lt;chr&gt;      &lt;date&gt;     &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;                 &lt;dbl&gt; &lt;dbl&gt;\n 1 JOHOR BATU PAHAT 2020-01-01 both  overall overall               495.   2020\n 2 JOHOR BATU PAHAT 2020-01-01 both  overall bumi_malay            311.   2020\n 3 JOHOR BATU PAHAT 2020-01-01 both  overall bumi_other              5.1  2020\n 4 JOHOR BATU PAHAT 2020-01-01 both  overall chinese               140.   2020\n 5 JOHOR BATU PAHAT 2020-01-01 both  overall indian                  6.9  2020\n 6 JOHOR BATU PAHAT 2020-01-01 both  overall other_citizen           1.8  2020\n 7 JOHOR BATU PAHAT 2020-01-01 both  overall other_noncitizen       30.2  2020\n 8 JOHOR BATU PAHAT 2020-01-01 both  0-4     overall                30.3  2020\n 9 JOHOR BATU PAHAT 2020-01-01 both  0-4     bumi_malay             21.3  2020\n10 JOHOR BATU PAHAT 2020-01-01 both  0-4     bumi_other              0.5  2020\n# ℹ 319,190 more rows\n\n\n\nmys_sf &lt;- mys_sf %&gt;%\n          mutate(ADM1_EN = toupper(ADM1_EN),\n                 ADM2_EN = toupper(ADM2_EN))\n\nmys_sf\n\nSimple feature collection with 144 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 184853.1 ymin: 94420.8 xmax: 2380932 ymax: 829136\nProjected CRS: Kertau (RSO) / RSO Malaya (m)\n# A tibble: 144 × 15\n   ADM2_EN  ADM2_PCODE ADM2_REF ADM2ALT1EN ADM2ALT2EN ADM1_EN ADM1_PCODE ADM0_EN\n * &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;  \n 1 BATU PA… MY0101     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 2 JOHOR B… MY0102     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 3 KLUANG   MY0103     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 4 KOTA TI… MY0104     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 5 KULAIJA… MY0105     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 6 LEDANG   MY0106     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 7 MERSING  MY0107     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 8 MUAR     MY0108     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 9 PONTIAN  MY0109     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n10 SEGAMAT  MY0110     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n# ℹ 134 more rows\n# ℹ 7 more variables: ADM0_PCODE &lt;chr&gt;, date &lt;date&gt;, validOn &lt;date&gt;,\n#   validTo &lt;date&gt;, Shape_Leng &lt;dbl&gt;, Shape_Area &lt;dbl&gt;,\n#   geometry &lt;MULTIPOLYGON [m]&gt;\n\n\n\n\n3.2.2 Checking for Mismatch (State)\n\n# Assuming you have two character vectors:\nstate_crime &lt;- unique(crime_df$state)\nstate_sf &lt;- unique(mys_sf$ADM1_EN)\n\n# Find states in crime_df that are not in mys_sf\nmissing_in_sf &lt;- setdiff(state_crime, state_sf)\n\n# Find states in mys_sf that are not in crime_df\nmissing_in_crime &lt;- setdiff(state_sf, state_crime)\n\n# Print the mismatches\nprint(\"States in crime_df not found in mys_sf:\")\n\n[1] \"States in crime_df not found in mys_sf:\"\n\nprint(missing_in_sf)\n\n[1] \"MALAYSIA\"\n\nprint(\"States in mys_sf not found in crime_df:\")\n\n[1] \"States in mys_sf not found in crime_df:\"\n\nprint(missing_in_crime)\n\n[1] \"W.P. LABUAN\"    \"W.P. PUTRAJAYA\"\n\n\n\n\n3.2.3 Cleaning (State)\nIn this case study, for ease of analysis, we choose to focus on West Malaysia, and thus will be filtering out Sarawak, Sabah and Labuan, which are not the focus of our current analysis.\n\nmys_sf &lt;- mys_sf %&gt;%\n          filter(ADM1_EN != 'W.P. LABUAN' & ADM1_EN != 'SABAH' & ADM1_EN != 'SARAWAK') %&gt;%\n          mutate(ADM1_EN = replace(ADM1_EN, ADM1_EN == 'W.P. KUALA LUMPUR', 'KUALA LUMPUR'),\n                 ADM1_EN = replace(ADM1_EN, ADM1_EN == 'W.P. PUTRAJAYA', 'KUALA LUMPUR'))\n\nmys_sf\n\nSimple feature collection with 87 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 184853.1 ymin: 139843.3 xmax: 728635.8 ymax: 744607.2\nProjected CRS: Kertau (RSO) / RSO Malaya (m)\n# A tibble: 87 × 15\n   ADM2_EN  ADM2_PCODE ADM2_REF ADM2ALT1EN ADM2ALT2EN ADM1_EN ADM1_PCODE ADM0_EN\n * &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;  \n 1 BATU PA… MY0101     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 2 JOHOR B… MY0102     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 3 KLUANG   MY0103     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 4 KOTA TI… MY0104     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 5 KULAIJA… MY0105     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 6 LEDANG   MY0106     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 7 MERSING  MY0107     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 8 MUAR     MY0108     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n 9 PONTIAN  MY0109     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n10 SEGAMAT  MY0110     &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt;       JOHOR   MY01       Malays…\n# ℹ 77 more rows\n# ℹ 7 more variables: ADM0_PCODE &lt;chr&gt;, date &lt;date&gt;, validOn &lt;date&gt;,\n#   validTo &lt;date&gt;, Shape_Leng &lt;dbl&gt;, Shape_Area &lt;dbl&gt;,\n#   geometry &lt;MULTIPOLYGON [m]&gt;\n\n\n\ncrime_df &lt;- crime_df %&gt;%\n              filter(state != 'MALAYSIA' & state != 'SABAH' & state != 'SARAWAK' & \n                     district != 'ALL' & type != 'all') %&gt;%\n              mutate(state = replace(state, state == 'W.P. KUALA LUMPUR', 'KUALA LUMPUR'))\ncrime_df\n\n# A tibble: 10,368 × 7\n   state district   category type           date       crimes  year\n   &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;          &lt;date&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 JOHOR BATU PAHAT assault  causing_injury 2016-01-01     39  2016\n 2 JOHOR BATU PAHAT assault  causing_injury 2017-01-01     41  2017\n 3 JOHOR BATU PAHAT assault  causing_injury 2018-01-01     28  2018\n 4 JOHOR BATU PAHAT assault  causing_injury 2019-01-01     41  2019\n 5 JOHOR BATU PAHAT assault  causing_injury 2020-01-01     43  2020\n 6 JOHOR BATU PAHAT assault  causing_injury 2021-01-01     22  2021\n 7 JOHOR BATU PAHAT assault  causing_injury 2022-01-01     19  2022\n 8 JOHOR BATU PAHAT assault  causing_injury 2023-01-01     22  2023\n 9 JOHOR BATU PAHAT assault  murder         2016-01-01      6  2016\n10 JOHOR BATU PAHAT assault  murder         2017-01-01      0  2017\n# ℹ 10,358 more rows\n\n\n\npopulation_df &lt;- population_df %&gt;%\n          filter(state != 'SABAH' & state != 'SARAWAK' & state != 'W.P. LABUAN' &\n                 sex == \"both\" & age == \"overall\" & ethnicity == \"overall\" ) %&gt;%\n          mutate(state = replace(state, state == 'W.P. KUALA LUMPUR', 'KUALA LUMPUR'),\n                 state = replace(state, state == 'W.P. PUTRAJAYA', 'KUALA LUMPUR')) %&gt;%\n          dplyr::select(state, district, year, population)\npopulation_df\n\n# A tibble: 276 × 4\n   state district     year population\n   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n 1 JOHOR BATU PAHAT   2020      495. \n 2 JOHOR JOHOR BAHRU  2020     1711. \n 3 JOHOR KLUANG       2020      324. \n 4 JOHOR KOTA TINGGI  2020      222. \n 5 JOHOR KULAI        2020      330. \n 6 JOHOR MERSING      2020       78.2\n 7 JOHOR MUAR         2020      315. \n 8 JOHOR PONTIAN      2020      173. \n 9 JOHOR SEGAMAT      2020      198. \n10 JOHOR TANGKAK      2020      163. \n# ℹ 266 more rows\n\n\n\n\n3.2.4 Crime (State-District)\n\n3.2.4.1 Checking for Mismatch in crime_df and mys_sf\n\ncrime_df &lt;- crime_df %&gt;% mutate(state_district = paste(state, district, sep = \"-\"))\nmys_sf &lt;- mys_sf %&gt;% mutate(state_district = paste(ADM1_EN, ADM2_EN, sep = \"-\"))\n\n\n# Assuming you have two character vectors:\nstate_district_crime &lt;- unique(crime_df$state_district)\nstate_district_sf &lt;- unique(mys_sf$state_district)\n\n# Find mismatches\nmissing_in_sf &lt;- setdiff(state_district_crime, state_district_sf)\nmissing_in_crime &lt;- setdiff(state_district_sf, state_district_crime)\n\n# Print the mismatches\nprint(\"State-District combinations in crime_df not found in mys_sf:\")\n\n[1] \"State-District combinations in crime_df not found in mys_sf:\"\n\nprint(missing_in_sf)\n\n [1] \"JOHOR-ISKANDAR PUTERI\"               \"JOHOR-JOHOR BAHRU SELATAN\"          \n [3] \"JOHOR-JOHOR BAHRU UTARA\"             \"JOHOR-NUSAJAYA\"                     \n [5] \"JOHOR-SERI ALAM\"                     \"KEDAH-BANDAR BHARU\"                 \n [7] \"NEGERI SEMBILAN-NILAI\"               \"PAHANG-CAMERON HIGHLAND\"            \n [9] \"PAHANG-KUALA LIPIS\"                  \"PERAK-BATU GAJAH\"                   \n[11] \"PERAK-GERIK\"                         \"PERAK-IPOH\"                         \n[13] \"PERAK-MANJUNG\"                       \"PERAK-PENGKALAN HULU\"               \n[15] \"PERAK-SELAMA\"                        \"PERAK-SUNGAI SIPUT\"                 \n[17] \"PERAK-TAIPING\"                       \"PERAK-TANJONG MALIM\"                \n[19] \"PERAK-TAPAH\"                         \"PERLIS-ARAU\"                        \n[21] \"PERLIS-KANGAR\"                       \"PERLIS-PADANG BESAR\"                \n[23] \"PULAU PINANG-SEBERANG PERAI SELATAN\" \"PULAU PINANG-SEBERANG PERAI TENGAH\" \n[25] \"PULAU PINANG-SEBERANG PERAI UTARA\"   \"SELANGOR-AMPANG JAYA\"               \n[27] \"SELANGOR-HULU SELANGOR\"              \"SELANGOR-KAJANG\"                    \n[29] \"SELANGOR-KLANG SELATAN\"              \"SELANGOR-KLANG UTARA\"               \n[31] \"SELANGOR-PETALING JAYA\"              \"SELANGOR-SERDANG\"                   \n[33] \"SELANGOR-SG. BULOH\"                  \"SELANGOR-SHAH ALAM\"                 \n[35] \"SELANGOR-SUBANG JAYA\"                \"SELANGOR-SUNGAI BULOH\"              \n[37] \"KUALA LUMPUR-BRICKFIELDS\"            \"KUALA LUMPUR-CHERAS\"                \n[39] \"KUALA LUMPUR-DANG WANGI\"             \"KUALA LUMPUR-SENTUL\"                \n[41] \"KUALA LUMPUR-WANGSA MAJU\"           \n\nprint(\"State-District combinations in mys_sf not found in crime_df:\")\n\n[1] \"State-District combinations in mys_sf not found in crime_df:\"\n\nprint(missing_in_crime)\n\n [1] \"JOHOR-JOHOR BAHRU\"             \"KEDAH-POKOK SENA\"             \n [3] \"KUALA LUMPUR-WP. KUALA LUMPUR\" \"PAHANG-LIPIS\"                 \n [5] \"PERAK-BATANG PADANG\"           \"PERAK-ULU PERAK\"              \n [7] \"PERAK-KINTA\"                   \"PERAK-LARUT DAN MATANG\"       \n [9] \"PERAK-MANJUNG (DINDING)\"       \"PERLIS-PERLIS\"                \n[11] \"PULAU PINANG-S.P.SELATAN\"      \"PULAU PINANG-S.P. TENGAH\"     \n[13] \"PULAU PINANG-S.P. UTARA\"       \"SELANGOR-ULU LANGAT\"          \n[15] \"SELANGOR-ULU SELANGOR\"         \"SELANGOR-KLANG\"               \n[17] \"SELANGOR-PETALING\"            \n\n\n\n\n3.2.4.2 Cleaning\n\ncrime_df &lt;- crime_df %&gt;%\n  mutate(district = case_when(\n    state == \"JOHOR\" & district %in% c(\"ISKANDAR PUTERI\", \"NUSAJAYA\", \"JOHOR BAHRU SELATAN\", \"JOHOR BAHRU UTARA\", \"SERI ALAM\") ~ \"JOHOR BAHRU\",\n    state == \"NEGERI SEMBILAN\" & district == \"NILAI\" ~ \"SEREMBAN\",\n    state == \"KEDAH\" & district == \"BANDAR BHARU\" ~ \"BANDAR BAHARU\",\n    state == \"PAHANG\" & district == \"CAMERON HIGHLAND\" ~ \"CAMERON HIGHLANDS\",\n    state == \"PAHANG\" & district == \"KUALA LIPIS\" ~ \"LIPIS\",\n    state == \"PERAK\" & district  %in% c(\"BATU GAJAH\", \"IPOH\") ~ \"KINTA\",\n    state == \"PERAK\" & district == \"GERIK\" ~ \"ULU PERAK\",\n    state == \"PERAK\" & district == \"MANJUNG\" ~ \"MANJUNG (DINDING)\",\n    state == \"PERAK\" & district == \"PENGKALAN HULU\" ~ \"ULU PERAK\",\n    state == \"PERAK\" & district %in% c(\"SELAMA\", \"TAIPING\") ~ \"LARUT DAN MATANG\",\n    state == \"PERAK\" & district == \"SUNGAI SIPUT\" ~ \"KUALA KANGSAR\",\n    state == \"PERAK\" & district %in% c(\"TANJONG MALIM\", \"TAPAH\") ~ \"BATANG PADANG\",\n    state == \"PERLIS\" & district %in% c(\"ARAU\", \"KANGAR\", \"PADANG BESAR\") ~ \"PERLIS\",\n    state == \"PULAU PINANG\" & district == \"SEBERANG PERAI SELATAN\" ~ \"S.P.SELATAN\",\n    state == \"PULAU PINANG\" & district == \"SEBERANG PERAI TENGAH\" ~ \"S.P. TENGAH\",\n    state == \"PULAU PINANG\" & district == \"SEBERANG PERAI UTARA\" ~ \"S.P. UTARA\",\n    state == \"SELANGOR\" & district == \"AMPANG JAYA\" ~ \"GOMBAK\",\n    state == \"SELANGOR\" & district == \"HULU SELANGOR\" ~ \"ULU SELANGOR\",\n    state == \"SELANGOR\" & district == \"KAJANG\" ~ \"ULU LANGAT\",\n    state == \"SELANGOR\" & district %in% c(\"KLANG SELATAN\", \"KLANG UTARA\") ~ \"KLANG\",\n    state == \"SELANGOR\" & district %in% c(\"PETALING JAYA\", \"SERDANG\", \"SG. BULOH\", \"SHAH ALAM\", \"SUBANG JAYA\", \"SUNGAI BULOH\") ~ \"PETALING\",\n    state == \"KUALA LUMPUR\" & district %in% c(\"BRICKFIELDS\", \"CHERAS\", \"DANG WANGI\", \"SENTUL\", \"WANGSA MAJU\") ~ \"WP. KUALA LUMPUR\",\n    TRUE ~ district\n  )) %&gt;%\n  group_by(state, district, year, category, type) %&gt;%\n  summarise(crimes = sum(crimes))\n\n`summarise()` has grouped output by 'state', 'district', 'year', 'category'.\nYou can override using the `.groups` argument.\n\n\n\ntm_shape(mys_sf) +\n  tm_polygons() +\n  tm_text(\"ADM2_EN\", size = 0.3)\n\n\n\n\n\n\n\n\n\n\n3.2.4.3 Visualizing Crime Distribution\n\ncrime_df_mys &lt;- crime_df %&gt;%\n  filter(year &gt;= 2019 & year &lt;= 2022) %&gt;%\n  left_join(mys_sf, by = c(\"state\" = \"ADM1_EN\", \"district\" = \"ADM2_EN\")) %&gt;%\n  dplyr::select(state, district, year, category, type, crimes, Shape_Leng, Shape_Area, geometry)\n\ncrime_df_mys &lt;- st_as_sf(crime_df_mys)\ncrime_df_mys\n\nSimple feature collection with 4128 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 184853.1 ymin: 139843.3 xmax: 728635.8 ymax: 744607.2\nProjected CRS: Kertau (RSO) / RSO Malaya (m)\n# A tibble: 4,128 × 9\n# Groups:   state, district, year, category [688]\n   state district    year category type             crimes Shape_Leng Shape_Area\n   &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;             &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 JOHOR BATU PAHAT  2019 assault  causing_injury       41       1.86      0.161\n 2 JOHOR BATU PAHAT  2019 assault  murder                3       1.86      0.161\n 3 JOHOR BATU PAHAT  2019 assault  rape                 29       1.86      0.161\n 4 JOHOR BATU PAHAT  2019 assault  robbery_gang_ar…      0       1.86      0.161\n 5 JOHOR BATU PAHAT  2019 assault  robbery_gang_un…     37       1.86      0.161\n 6 JOHOR BATU PAHAT  2019 assault  robbery_solo_ar…      0       1.86      0.161\n 7 JOHOR BATU PAHAT  2019 assault  robbery_solo_un…     29       1.86      0.161\n 8 JOHOR BATU PAHAT  2019 property break_in            157       1.86      0.161\n 9 JOHOR BATU PAHAT  2019 property theft_other         127       1.86      0.161\n10 JOHOR BATU PAHAT  2019 property theft_vehicle_l…      4       1.86      0.161\n# ℹ 4,118 more rows\n# ℹ 1 more variable: geometry &lt;MULTIPOLYGON [m]&gt;\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ncrime_df_mys_grp &lt;- crime_df_mys %&gt;%\n  summarize(total_crimes = sum(crimes))\n\n`summarise()` has grouped output by 'state', 'district', 'year'. You can\noverride using the `.groups` argument.\n\nchoro &lt;- tm_shape(crime_df_mys_grp) +\n  tm_fill(\"total_crimes\", \n          style = \"pretty\", \n          palette = \"Blues\",\n          title = \"Crimes\") +\n  tm_layout(main.title = \"Distribution of crime in West Malaysia\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\nchoro\n\n\n\n\n\n\n\n\n\n\n\n3.2.5 Population (State-District)\n\n3.2.5.1 Check for Mismatch\nThe year 2019 is missing from the population data set, hence we make the assumption that the population did not experience any drastic increase or decrease, and will thus map population from year 2020 -&gt; 2019.\n\npopulation_row &lt;- population_df %&gt;%\n  filter(year == 2020) %&gt;%\n  mutate(year = 2019) \npopulation_df &lt;- bind_rows(population_df, population_row) %&gt;% \n  mutate(state_district = paste(state, district, sep = \"-\"))\nunique(population_df$year)\n\n[1] 2020 2021 2022 2019\n\n\n\nstate_district_population &lt;- unique(population_df$state_district)\n\nmissing_in_sf &lt;- setdiff(state_district_population, state_district_sf)\nmissing_in_population &lt;- setdiff(state_district_sf, state_district_population)\n\nprint(\"State-District combinations in population_df not found in mys_sf:\")\n\n[1] \"State-District combinations in population_df not found in mys_sf:\"\n\nprint(missing_in_sf)\n\n [1] \"JOHOR-KULAI\"                         \"JOHOR-TANGKAK\"                      \n [3] \"KELANTAN-KECIL LOJING\"               \"PERAK-BAGAN DATUK\"                  \n [5] \"PERAK-HULU PERAK\"                    \"PERAK-MANJUNG\"                      \n [7] \"PERAK-MUALLIM\"                       \"PERAK-SELAMA\"                       \n [9] \"PULAU PINANG-SEBERANG PERAI SELATAN\" \"PULAU PINANG-SEBERANG PERAI TENGAH\" \n[11] \"PULAU PINANG-SEBERANG PERAI UTARA\"   \"TERENGGANU-KUALA NERUS\"             \n[13] \"KUALA LUMPUR-W.P. KUALA LUMPUR\"      \"PAHANG-CAMERON HIGHLAND\"            \n[15] \"PULAU PINANG-SP SELATAN\"             \"PULAU PINANG-SP TENGAH\"             \n[17] \"PULAU PINANG-SP UTARA\"              \n\nprint(\"State-District combinations in mys_sf not found in population_df:\")\n\n[1] \"State-District combinations in mys_sf not found in population_df:\"\n\nprint(missing_in_population)\n\n[1] \"JOHOR-KULAIJAYA\"               \"JOHOR-LEDANG\"                 \n[3] \"KUALA LUMPUR-WP. KUALA LUMPUR\" \"PERAK-ULU PERAK\"              \n[5] \"PERAK-MANJUNG (DINDING)\"       \"PULAU PINANG-S.P.SELATAN\"     \n[7] \"PULAU PINANG-S.P. TENGAH\"      \"PULAU PINANG-S.P. UTARA\"      \n\n\n\n\n3.2.5.2 Cleaning\n\npopulation_df &lt;- population_df %&gt;%\n  mutate(district = case_when(\n    state == \"JOHOR\" & district == \"KULAI\" ~ \"KULAIJAYA\",\n    state == \"JOHOR\" & district == \"TANGKAK\" ~ \"LEDANG\",\n    state == \"KELANTAN\" & district == \"KECIL LOJING\" ~ \"GUA MUSANG\",\n    state == \"PAHANG\" & district == \"CAMERON HIGHLAND\" ~ \"CAMERON HIGHLANDS\",\n    state == \"PERAK\" & district == \"HULU PERAK\" ~ \"ULU PERAK\",\n    state == \"PERAK\" & district == \"BAGAN DATUK\" ~ \"HILIR PERAK\",\n    state == \"PERAK\" & district == \"MANJUNG\" ~ \"MANJUNG (DINDING)\",\n    state == \"PERAK\" & district == \"MUALLIM\" ~ \"BATANG PADANG\",\n    state == \"PERAK\" & district == \"SELAMA\" ~ \"LARUT DAN MATANG\",\n    state == \"PULAU PINANG\" & district == \"SEBERANG PERAI SELATAN\" ~ \"S.P.SELATAN\",\n    state == \"PULAU PINANG\" & district == \"SEBERANG PERAI TENGAH\" ~ \"S.P. TENGAH\",\n    state == \"PULAU PINANG\" & district == \"SEBERANG PERAI UTARA\" ~ \"S.P. UTARA\",\n    state == \"PULAU PINANG\" & district == \"SP SELATAN\" ~ \"S.P.SELATAN\",\n    state == \"PULAU PINANG\" & district == \"SP TENGAH\" ~ \"S.P. TENGAH\",\n    state == \"PULAU PINANG\" & district == \"SP UTARA\" ~ \"S.P. UTARA\",\n    state == \"KUALA LUMPUR\" & district == \"W.P. KUALA LUMPUR\" ~ \"WP. KUALA LUMPUR\",\n    state == \"TERENGGANU\" & district == \"KUALA NERUS\" ~ \"KUALA TERENGGANU\",\n    TRUE ~ district\n  )) %&gt;%\n  group_by(state, district, year) %&gt;%\n  summarise(population = sum(population))\n\n`summarise()` has grouped output by 'state', 'district'. You can override using\nthe `.groups` argument.\n\npopulation_df\n\n# A tibble: 348 × 4\n# Groups:   state, district [87]\n   state district     year population\n   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n 1 JOHOR BATU PAHAT   2019       495.\n 2 JOHOR BATU PAHAT   2020       495.\n 3 JOHOR BATU PAHAT   2021       497.\n 4 JOHOR BATU PAHAT   2022       498.\n 5 JOHOR JOHOR BAHRU  2019      1711.\n 6 JOHOR JOHOR BAHRU  2020      1711.\n 7 JOHOR JOHOR BAHRU  2021      1715.\n 8 JOHOR JOHOR BAHRU  2022      1724.\n 9 JOHOR KLUANG       2019       324.\n10 JOHOR KLUANG       2020       324.\n# ℹ 338 more rows\n\n\n\npopulation_df_mys &lt;- population_df %&gt;%\n  left_join(mys_sf, by = c(\"state\" = \"ADM1_EN\", \"district\" = \"ADM2_EN\")) %&gt;%\n  dplyr::select(state, district, year, population, geometry)\n\npopulation_df_mys &lt;- st_as_sf(population_df_mys)\npopulation_df_mys\n\nSimple feature collection with 348 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 184853.1 ymin: 139843.3 xmax: 728635.8 ymax: 744607.2\nProjected CRS: Kertau (RSO) / RSO Malaya (m)\n# A tibble: 348 × 5\n# Groups:   state, district [87]\n   state district     year population                                   geometry\n   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;                         &lt;MULTIPOLYGON [m]&gt;\n 1 JOHOR BATU PAHAT   2019       495. (((556714.6 192051.6, 556664.6 192111.5, …\n 2 JOHOR BATU PAHAT   2020       495. (((556714.6 192051.6, 556664.6 192111.5, …\n 3 JOHOR BATU PAHAT   2021       497. (((556714.6 192051.6, 556664.6 192111.5, …\n 4 JOHOR BATU PAHAT   2022       498. (((556714.6 192051.6, 556664.6 192111.5, …\n 5 JOHOR JOHOR BAHRU  2019      1711. (((664760.7 157664.3, 664668.2 157664.3, …\n 6 JOHOR JOHOR BAHRU  2020      1711. (((664760.7 157664.3, 664668.2 157664.3, …\n 7 JOHOR JOHOR BAHRU  2021      1715. (((664760.7 157664.3, 664668.2 157664.3, …\n 8 JOHOR JOHOR BAHRU  2022      1724. (((664760.7 157664.3, 664668.2 157664.3, …\n 9 JOHOR KLUANG       2019       324. (((583499.3 195230.8, 581600.3 195991.2, …\n10 JOHOR KLUANG       2020       324. (((583499.3 195230.8, 581600.3 195991.2, …\n# ℹ 338 more rows\n\n\n\n\n\n3.2.6 Joining\n\n3.2.6.1 Join with Population Data\n\ncrime_df_mys &lt;- crime_df %&gt;% \n  filter(year &gt;= 2019 & year &lt;= 2022) %&gt;%\n  left_join(population_df, by = c(\"state\", \"district\", \"year\")) %&gt;%\n  mutate(crimes_pc = crimes/population) %&gt;%\n  dplyr::select(state, district, year, category, type, crimes, crimes_pc, population)\n\n\n\n3.2.6.2 Create for Pokok Sena District\nUnfortunately, the crime dataset we have sourced did not contain any information on the crimes in Pokok Sena District, possibility due to the scarce population in the area. To resolve this, we have taken the mean of the crime per capita in the neighbouring districts in Kedah State to apply to Pokok Sena.\n\npokok_sena_rows &lt;- crime_df_mys %&gt;%\n  filter(state == \"KEDAH\") %&gt;%\n  group_by(state, year, category, type) %&gt;%\n  summarise(crimes = mean(crimes),\n            crimes_pc = mean(crimes_pc),\n            population = mean(population)) %&gt;% \n  mutate(district = \"POKOK SENA\")\n\n`summarise()` has grouped output by 'state', 'year', 'category'. You can\noverride using the `.groups` argument.\n\npokok_sena_rows\n\n# A tibble: 48 × 8\n# Groups:   state, year, category [8]\n   state  year category type                crimes crimes_pc population district\n   &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;   \n 1 KEDAH  2019 assault  causing_injury      29.8    0.140          189. POKOK S…\n 2 KEDAH  2019 assault  murder               1.82   0.0129         189. POKOK S…\n 3 KEDAH  2019 assault  rape                13.2    0.0752         189. POKOK S…\n 4 KEDAH  2019 assault  robbery_gang_armed   0.182  0.00155        189. POKOK S…\n 5 KEDAH  2019 assault  robbery_gang_unar…  25.3    0.0992         189. POKOK S…\n 6 KEDAH  2019 assault  robbery_solo_armed   0.182  0.000410       189. POKOK S…\n 7 KEDAH  2019 assault  robbery_solo_unar…  14.7    0.0590         189. POKOK S…\n 8 KEDAH  2019 property break_in           103.     0.440          189. POKOK S…\n 9 KEDAH  2019 property theft_other         86.9    0.479          189. POKOK S…\n10 KEDAH  2019 property theft_vehicle_lor…   7.09   0.0202         189. POKOK S…\n# ℹ 38 more rows\n\ncrime_df_mys &lt;- bind_rows(crime_df_mys, pokok_sena_rows)\n\n\n\n2.3.6.3 Join with District Boundary\n\ncrime_df_mys &lt;- crime_df_mys %&gt;%\n  left_join(mys_sf, by = c(\"state\" = \"ADM1_EN\", \"district\" = \"ADM2_EN\")) %&gt;%\n  dplyr::select(state, district, year, category, type, crimes, crimes_pc, population, geometry)\n\ncrime_df_mys &lt;- st_as_sf(crime_df_mys)\ncrime_df_mys\n\nSimple feature collection with 4176 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 184853.1 ymin: 139843.3 xmax: 728635.8 ymax: 744607.2\nProjected CRS: Kertau (RSO) / RSO Malaya (m)\n# A tibble: 4,176 × 9\n# Groups:   state, district, year, category [696]\n   state district    year category type              crimes crimes_pc population\n   &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 JOHOR BATU PAHAT  2019 assault  causing_injury        41   0.0828        495.\n 2 JOHOR BATU PAHAT  2019 assault  murder                 3   0.00606       495.\n 3 JOHOR BATU PAHAT  2019 assault  rape                  29   0.0586        495.\n 4 JOHOR BATU PAHAT  2019 assault  robbery_gang_arm…      0   0             495.\n 5 JOHOR BATU PAHAT  2019 assault  robbery_gang_una…     37   0.0747        495.\n 6 JOHOR BATU PAHAT  2019 assault  robbery_solo_arm…      0   0             495.\n 7 JOHOR BATU PAHAT  2019 assault  robbery_solo_una…     29   0.0586        495.\n 8 JOHOR BATU PAHAT  2019 property break_in             157   0.317         495.\n 9 JOHOR BATU PAHAT  2019 property theft_other          127   0.256         495.\n10 JOHOR BATU PAHAT  2019 property theft_vehicle_lo…      4   0.00808       495.\n# ℹ 4,166 more rows\n# ℹ 1 more variable: geometry &lt;MULTIPOLYGON [m]&gt;\n\n\n\n\n\n3.2.7 Visualizing the distribution of crime\n\ncrime_df_mys_grp &lt;- crime_df_mys %&gt;%\n  group_by(state, district) %&gt;%\n  summarize(total_crimes_pc = sum(crimes_pc)/4)\n\n`summarise()` has grouped output by 'state'. You can override using the\n`.groups` argument.\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nchoro &lt;- tm_shape(crime_df_mys_grp) +\n  tm_fill(\"total_crimes_pc\", \n          n = 5,\n          style = \"equal\", \n          palette = \"Blues\",\n          title = \"Crime per Capita in West Malaysia\") +\n  tm_layout(main.title = \"Crime per Capita Distribution\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2, position = c(\"right\", \"top\")) +\n  tm_grid(alpha =0.2)\n\n\nchoro"
  },
  {
    "objectID": "Take-home_Ex/THE_3/Take-home_Ex03.html#global-measures-of-spatial-autocorrelation",
    "href": "Take-home_Ex/THE_3/Take-home_Ex03.html#global-measures-of-spatial-autocorrelation",
    "title": "take home exercise 3",
    "section": "3.4 Global Measures of Spatial Autocorrelation",
    "text": "3.4 Global Measures of Spatial Autocorrelation\n\n3.4.1 Computing Contiguity Spatial Weights\nWe now generate the neighbours list.\n\nmys_nb_q &lt;- st_contiguity(crime_df_mys_grp, queen=TRUE)\n\nWarning in spdep::poly2nb(geometry, queen = queen, ...): some observations have no neighbours;\nif this seems unexpected, try increasing the snap argument.\n\n\nWarning in spdep::poly2nb(geometry, queen = queen, ...): neighbour object has 3 sub-graphs;\nif this sub-graph count seems unexpected, try increasing the snap argument.\n\n# Langkawi has no immediate neighbours, hence its neighbour has to be manually added.\nmys_nb_q[[17]] &lt;- as.integer(c(18))\nmys_nb_q[[18]] &lt;- as.integer(sort(unique(c(mys_nb_q[[18]], 17))))\n\nmys_wm_rs &lt;- st_weights(mys_nb_q, style=\"W\")\n\nwm_q &lt;- crime_df_mys_grp %&gt;%\n  ungroup() %&gt;%\n  mutate(nb = mys_nb_q,\n         wt = mys_wm_rs,\n         .before = 1) \n\n\n\n3.4.2 Moran’s I test\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep. The primary goal of the test is to determine whether the spatial autocorrelation is positive, negative or non-existent.\nNull Hypothesis \\(H_0:I\\leq E[I]\\). This suggests that there is either no spatial autocorrelation (\\(I=E[I]\\)). or negative spatial autocorrelation (\\(I&lt;E[I]\\)).\nAlternative Hypothesis \\(H_0:I&gt; E[I]\\). This indicates the presence of positive spatial autocorrelation.\n\nmoranI &lt;- global_moran(wm_q$total_crimes_pc,\n                        wm_q$nb,\n                        wm_q$wt)\n\n\nglobal_moran_test(wm_q$total_crimes_pc,\n                  wm_q$nb,\n                  wm_q$wt,\n                  alternative = \"greater\")\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 3.9166, p-value = 4.491e-05\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.275786031      -0.011627907       0.005385229 \n\n\nBased on the Moran’s I test, we can conclude that there is evidence of significant positive spatial autocorrelation in the crime data. This suggests that the distribution of crime in Malaysia is not random and that there are clusters of high and low crime rates.\n\nThe Moran’s I statistic is positive (0.271500147), suggesting a positive spatial autocorrelation in the crime data. This means that areas with similar crime rates tend to be located near each other.\nThe standard deviate of 3.8061 indicates the significance of the Moran’s I statistic. A higher standard deviate suggests a stronger spatial pattern.\nThe p-value of 7.058e-05 is less than the significance level of 0.05, indicating that the observed spatial pattern is statistically significant. This means that it is unlikely to have occurred by chance.\n\n\n3.4.2.1 Performing Global Moran’s I permutation test\n\nset.seed(123)\n\ngmoranMC &lt;- global_moran_perm(wm_q$total_crimes_pc,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 999)\ngmoranMC\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.27579, observed rank = 999, p-value = 0.002\nalternative hypothesis: two.sided\n\n\n\nWe can observe that the Moran’s I statistic is 0.2715 with a p-value &lt; 2.2e-16, which is similar to our previous result using moran.test(). It confirms that our result is stable.\n\n\n\n3.4.2.2 Visualising Monte Carlo Moran’s I\n\nhist(gmoranMC$res, main=\"Histogram of Simulation Results\", xlab=\"Monte-Carlo Results\", ylab=\"Frequency\")\n\nabline(v = gmoranMC$statistic, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n3.4.3 Geary’s C test\nThe code chunk below performs Global Geary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\nglobal_c_test(wm_q$total_crimes_pc,\n                  wm_q$nb,\n                  wm_q$wt,\n                  alternative = \"greater\")\n\n\n    Geary C test under randomisation\n\ndata:  x \nweights: listw   \n\nGeary C statistic standard deviate = 4.1574, p-value = 1.609e-05\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n      0.645478034       1.000000000       0.007271778 \n\n\nThe calculated Geary’s C statistic of 0.649379732 deviates from the expected value of 1, indicating a potential spatial pattern in the data. The associated p-value of 2.155e-05 is statistically significant at the 0.05 level, further supporting the conclusion that the observed spatial pattern is unlikely to be due to random chance. Therefore, we reject the null hypothesis of no spatial autocorrelation.\n\n3.4.3.1 Monte Carlo Geary’s C\n\nset.seed(123)\n\nbperm &lt;- global_c_perm(wm_q$total_crimes_pc,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.64548, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nIt can be seen that the results are similar to the previous output of the code chunk. Hence our result is statistically significant.\n\n\n3.4.3.2 Visualising the Monte Carlo Geary’s C\n\nhist(bperm$res, \n     freq=TRUE, breaks=20, \n     xlab=\"Simulated Geary c\")\n\nabline(v=1, col=\"red\")"
  },
  {
    "objectID": "Take-home_Ex/THE_3/Take-home_Ex03.html#local-measures-of-spatial-autocorrelation",
    "href": "Take-home_Ex/THE_3/Take-home_Ex03.html#local-measures-of-spatial-autocorrelation",
    "title": "take home exercise 3",
    "section": "3.5 Local Measures of Spatial Autocorrelation",
    "text": "3.5 Local Measures of Spatial Autocorrelation\n\n3.5.1 Computing Local Moran’s I\nTo compute local Moran’s I, the local_moran() function of sfdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\n\nlisa &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    total_crimes_pc, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nlisa\n\nSimple feature collection with 87 features and 17 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 184853.1 ymin: 139843.3 xmax: 728635.8 ymax: 744607.2\nProjected CRS: Kertau (RSO) / RSO Malaya (m)\n# A tibble: 87 × 18\n        ii      eii  var_ii   z_ii   p_ii p_ii_sim p_folded_sim skewness\n     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.931   0.0733  0.224    1.81  0.0699     0.02         0.01   -0.776\n 2 -0.639   0.00450 0.437   -0.974 0.330      0.24         0.12    0.978\n 3  0.319  -0.0136  0.0529   1.44  0.148      0.04         0.02   -1.11 \n 4  0.0148 -0.00278 0.00580  0.230 0.818      0.96         0.48   -0.785\n 5  0.0716 -0.0366  0.0961   0.349 0.727      0.92         0.46   -0.596\n 6  0.779  -0.0610  0.334    1.46  0.146      0.1          0.05   -0.625\n 7  0.163   0.0101  0.0281   0.912 0.362      0.34         0.17   -0.331\n 8  1.21   -0.0341  0.646    1.55  0.121      0.04         0.02   -0.858\n 9  0.260   0.0210  0.249    0.479 0.632      0.76         0.38   -0.603\n10  0.352  -0.0139  0.0349   1.96  0.0502     0.02         0.01   -0.764\n# ℹ 77 more rows\n# ℹ 10 more variables: kurtosis &lt;dbl&gt;, mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;,\n#   nb &lt;nb&gt;, wt &lt;list&gt;, state &lt;chr&gt;, district &lt;chr&gt;, total_crimes_pc &lt;dbl&gt;,\n#   geometry &lt;MULTIPOLYGON [m]&gt;\n\n\n\n3.5.1.1 Visualising Local Moran’s I\n\ntm_shape(lisa)+\n  tm_fill(\"ii\", \n          palette = c(\"#b7dce9\",\"#e1ecbb\",\"#f5f3a6\",\n                      \"#f8d887\",\"#ec9a64\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)\n\n\n\n\n\n\n\n\n\n\n3.5.1.2 Visualising Local Moran’s I p-value\n\ntm_shape(lisa)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#b7dce9\",\"#c9e3d2\",\"#f5f3a6\",\"#ec9a64\",\"#d21b1c\"),\n          title = \"p-value\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)\n\n\n\n\n\n\n\n\n\n\n3.5.1.3 Visualising Statistically Significant Local Spatial Autocorrelation Map\nFrom the p-value map above, it appears that not every district exhibits a statistically significant Local Moran’s value. We will thus filter out to focus our analysis will focus solely on districts with statistically significant values.\n\nlisa_sig &lt;- lisa  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\n\ntm_shape(lisa)+\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6)+\ntm_shape(lisa_sig)+\n  tm_fill(\"ii\", \n          palette = c(\"#b7dce9\",\"#e1ecbb\",\"#f5f3a6\",\n                      \"#f8d887\",\"#ec9a64\",\"#d21b1c\"),\n          title = \"Local Moran's I (p &lt; 0.05)\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\n\n\n3.5.2 LISA Classification\nSpecific to our study, we may infer LISA classifications as below.\nHigh-Low Outliers: districts with a high value of crime per capita, surrounded by districts with low values of crime per capita\n\nLow-High Outliers: districts with a low value of crime per capita, surrounded by neighbouring districts with high values of crime per capita\n\nHigh-High Clusters: districts with a high value of crime per capita, surrounded by neighbouring districts with high values of crime per capita\n\nLow-Low Clusters: districts with a low value of crime per capita, surrounded by neighbouring districts with low values of crime per capita\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nstudy_area_lisa &lt;- tm_shape(lisa)+\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6)+\ntm_shape(lisa_sig)+\n  tm_fill(\"mean\", \n          palette = c(\"#b7dce9\",\"#ec9a64\",\"#e1ecbb\", \"#d21b1c\"),\n          title = \"LISA class\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)\n\nstudy_area_lisa\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "Take-home_Ex/THE_3/Take-home_Ex03.html#hot-and-cold-spots-analysis-hcsa",
    "href": "Take-home_Ex/THE_3/Take-home_Ex03.html#hot-and-cold-spots-analysis-hcsa",
    "title": "take home exercise 3",
    "section": "3.6 Hot and Cold Spots Analysis (HCSA)",
    "text": "3.6 Hot and Cold Spots Analysis (HCSA)\nThe Gi and Gi* measures are typically reported as a z-score where high values indicate a high-high cluster, and negative z-scores indicate a low-low cluster. There are no high-low and low-high classifications like the local Moran.\n\nwm_idw &lt;- crime_df_mys_grp %&gt;%\n  ungroup() %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There were 2 warnings in `stopifnot()`.\nThe first warning was:\nℹ In argument: `nb = include_self(st_contiguity(geometry))`.\nCaused by warning in `spdep::poly2nb()`:\n! some observations have no neighbours;\nif this seems unexpected, try increasing the snap argument.\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n\nNext, we will calculate local using local_gstart_perm() function.\n\nHCSA &lt;- wm_idw %&gt;% \n  mutate(local_Gi_star = local_gstar_perm(\n    total_crimes_pc, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi_star)\n\n\ntmap_mode(\"plot\")  \n\ntmap mode set to plotting\n\ntm_shape(HCSA)+\n  tm_fill(\"gi_star\", \n          palette = c(\"#57bfc0\", \"#7977f3\",\"#f8d673\",\"#f8b675\",\"#f67774\"),\n          title = \"Gi*\",\n          midpoint = 0) +\n  tm_borders(col = \"black\", alpha = 0.6)\n\n\n\n\n\n\n\n\nSimilar to what we did for the LISA map, we choose to narrow our focus onto districts with statistically significant Gi* values.\n\nHCSA_sig &lt;- HCSA  %&gt;%\n  filter(p_sim &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_polygons() +\ntm_shape(HCSA_sig)+\n  tm_fill(\"gi_star\", \n          palette = c(\"#57bfc0\", \"#7977f3\",\"#f8d673\",\"#f8b675\",\"#f67774\"),\n          title = \"Gi*\",\n          midpoint = 0,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)\n\n\n\n\n\n\n\n\n\nset.seed(123)\n\nthree_hotspots &lt;- (head((HCSA_sig[HCSA_sig$gi_star &gt; 2,]), 3)$district)\nthree_coldspots &lt;-  (head((HCSA_sig[HCSA_sig$gi_star &gt; -2,]), 3)$district)\n\nthree_hotspots\n\n[1] \"WP. KUALA LUMPUR\" \"S.P. UTARA\"       \"GOMBAK\"          \n\nthree_coldspots\n\n[1] \"BATU PAHAT\" \"MUAR\"       \"JELI\""
  }
]