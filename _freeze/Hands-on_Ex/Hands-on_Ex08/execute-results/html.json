{
  "hash": "e54bad564fed683dd450bcb4d2f68a0c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hands On Exercise 8\"\nauthor: \"Jenna Cheo\"\ndate: \"October 9, 2024\"\ndate-modified: \"last-modified\"\nformat: html\neditor: visual\nexecute: \n  freeze: true\n  eval: false\n---\n\n\n# Geographical Segmentation with Spatially Constrained Clustering Techniques\n\n## Getting Started\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(BiocManager, spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)\n```\n:::\n\n\n## Data Import and Preparation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_sf <- st_read(dsn = \"data/geospatial\", \n                   layer = \"myanmar_township_boundaries\") %>%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %>%\n  select(c(2:7))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_sf\n```\n:::\n\n\n### Importing aspatial data into R environment\n\n\n::: {.cell}\n\n```{.r .cell-code}\nict <- read_csv (\"data/aspatial/Shan-ICT.csv\")\nsummary(ict)\n```\n:::\n\n\n### Derive new variables using **dplyr** package\n\nThe unit of measurement of the values are number of household. Using these values directly will be bias by the underlying total number of households. In general, the townships with relatively higher total number of households will also have higher number of households owning radio, TV, etc.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nict_derived <- ict %>%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %>%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %>%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %>%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %>%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %>%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %>%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\nsummary(ict_derived)\n```\n:::\n\n\n## Exploratory Data Analysis (EDA)\n\n### EDA using statistical graphics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n```\n:::\n\n\nBoxplot is useful to detect if there are outliers.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n```\n:::\n\n\nBoxplot is useful to detect if there are outliers.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n```\n:::\n\n\nIn the figure below, multiple histograms are plotted to reveal the distribution of the selected variables in the *ict_derived* data.frame.\n\nThe code chunks below are used to create the data visualisation. They consist of two main parts. First, we will create the individual histograms using the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nradio <- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ntv <- ggplot(data=ict_derived, \n             aes(x= `TV_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nllphone <- ggplot(data=ict_derived, \n             aes(x= `LLPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nmphone <- ggplot(data=ict_derived, \n             aes(x= `MPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ncomputer <- ggplot(data=ict_derived, \n             aes(x= `COMPUTER_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ninternet <- ggplot(data=ict_derived, \n             aes(x= `INTERNET_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n```\n:::\n\n\nNext, the [*ggarrange()*](https://rpkgs.datanovia.com/ggpubr/reference/ggarrange.html) function of [**ggpubr**](https://rpkgs.datanovia.com/ggpubr/index.html) package is used to group these histograms together.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)\n```\n:::\n\n\n### EDA using choropleth map\n\n#### Joining geospatial data with aspatial data\n\nBefore we can prepare the choropleth map, we need to combine both the geospatial data object (i.e. *shan_sf*) and aspatial data.frame object (i.e. *ict_derived*) into one. This will be performed by using the [*left_join*](https://dplyr.tidyverse.org/reference/join.tbl_df.html) function of **dplyr** package. The *shan_sf* simple feature data.frame will be used as the base data object and the *ict_derived* data.frame will be used as the join table.\n\nThe code chunks below is used to perform the task. The unique identifier used to join both data objects is *TS_PCODE*.\n\nCombining both datasets.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_sf <- left_join(shan_sf, \n                     ict_derived, by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n  \nwrite_rds(shan_sf, \"data/rds/shan_sf.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_sf <- read_rds(\"data/rds/shan_sf.rds\")\n```\n:::\n\n\n#### Preparing a choropleth map\n\nTo have a quick look at the distribution of Radio penetration rate of Shan State at township level, a choropleth map will be prepared.\n\nThe code chunks below are used to prepare the choroplethby using the *qtm()* function of **tmap** package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqtm(shan_sf, \"RADIO_PR\")\n```\n:::\n\n\nWe will create two choropleth maps, one for the total number of households (i.e. TT_HOUSEHOLDS.map) and one for the total number of household with Radio (RADIO.map) to reveal the distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTT_HOUSEHOLDS.map <- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map <- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp=NA, ncol=2)\n```\n:::\n\n\nThe choropleth maps above clearly show that townships with relatively larger number ot households are also showing relatively higher number of radio ownership.\n\nPlotting the choropleth maps showing the dsitribution of total number of households and Radio penetration rate.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntm_shape(shan_sf) +\n    tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n                style=\"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins=0, asp=0)\n```\n:::\n\n\n## Correlation Analysis\n\nBefore we perform cluster analysis, it is important for us to ensure that the cluster variables are not highly correlated.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncluster_vars.cor = cor(ict_derived[,12:17])\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n```\n:::\n\n\nThe above shows that COMPUTER_PR and INTERNET_PR are highly correlated. This suggest that only one of them should be used in the cluster analysis.\n\n## Hierarchy Cluster Analysis\n\nExtracting clustering variables\n\nThe code chunk below will be used to extract the clustering variables from the *shan_sf* simple feature object into data.frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncluster_vars <- shan_sf %>%\n  st_set_geometry(NULL) %>%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n```\n:::\n\n\nRemoved INTERNET_PR because it is highly correlated with COMPUTER_PR.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrow.names(cluster_vars) <- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrow.names(cluster_vars) <- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_ict <- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n```\n:::\n\n\n### Data Standardisation\n\nMultiple variables will be used in cluster analysis. In order to avoid the a result biased toward variables with large values, it is useful to standardise the input variables before performing cluster analysis.\n\n### Min-Max standardisation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_ict.std <- normalize(shan_ict)\nsummary(shan_ict.std)\n```\n:::\n\n\n### Z-score standardisation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_ict.z <- scale(shan_ict)\ndescribe(shan_ict.z)\n```\n:::\n\n\nNotice the mean and standard deviation of the Z-score standardised clustering variables are 0 and 1 respectively.\n\n**Note:** [*describe()*](https://www.rdocumentation.org/packages/Hmisc/versions/4.4-0/topics/describe) of [**psych**](https://cran.r-project.org/web/packages/psych/index.html) package is used here instead of *summary()* of Base R because the earlier provides standard deviation.\n\n***Warning: Z-score standardisation method should only be used if we would assume all variables come from some normal distribution.***\n\n### Visualising the standardised clustering variables\n\nIt is also a good practice to visualise their distribution graphical.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr <- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df <- as.data.frame(shan_ict.std)\ns <- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df <- as.data.frame(shan_ict.z)\nz <- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nr <- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df <- as.data.frame(shan_ict.std)\ns <- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df <- as.data.frame(shan_ict.z)\nz <- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n```\n:::\n\n\n### Computing distance/proximity matrix\n\n*dist()* supports six distance proximity calculations, they are: **euclidean, maximum, manhattan, canberra, binary and minkowski**. The default is *euclidean* proximity matrix.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nproxmat <- dist(shan_ict, method = 'euclidean')\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nproxmat\n```\n:::\n\n\n### Computing hierarchical clustering\n\n*hclust()* employed agglomeration method to compute the cluster. Eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC).\n\nThe code chunk below performs hierarchical cluster analysis using ward.D method. The hierarchical clustering output is stored in an object of class **hclust** which describes the tree produced by the clustering process.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhclust_ward <- hclust(proxmat, method = 'ward.D')\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(hclust_ward, cex = 0.6)\n```\n:::\n\n\n### Selecting the optimal clustering algorithm\n\nOne of the challenge in performing hierarchical clustering is to identify stronger clustering structures. The issue can be resolved using use [*agnes()*](https://www.rdocumentation.org/packages/cluster/versions/2.1.0/topics/agnes) function of [**cluster**](https://cran.r-project.org/web/packages/cluster/) package. It functions like *hclus()*, however, with the *agnes()* function you can also get the agglomerative coefficient, which measures the amount of clustering structure found (values closer to 1 suggest strong clustering structure).\n\nThe code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) <- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac <- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n```\n:::\n\n\nWard’s method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward’s method will be used.\n\n### Determining Optimal Clusters\n\nAnother technical challenge face by data analyst in performing clustering analysis is to determine the optimal clusters to retain.\n\nThere are [three](https://statweb.stanford.edu/~gwalther/gap) commonly used methods to determine the optimal clusters, they are:\n\n-   [Elbow Method](https://en.wikipedia.org/wiki/Elbow_method_(clustering))\n\n-   [Average Silhouette Method](https://www.sciencedirect.com/science/article/pii/0377042787901257?via%3Dihub)\n\n-   [Gap Statistic Method](http://www.web.stanford.edu/~hastie/Papers/gap.pdf)\n\n#### Gap Statistic Method\n\nThe [**gap statistic**](http://www.web.stanford.edu/~hastie/Papers/gap.pdf) compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(12345)\ngap_stat <- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_gap_stat(gap_stat)\n```\n:::\n\n\nReferencing to the gap statistic graph above, the recommended number of cluster to retain is 1. However, the 6-cluster gives the largest gap statistic and should be the next best cluster to pick.\n\n### Interpreting the dendrograms\n\nIn the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.\n\nThe height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Note that, conclusions about the proximity of two observations can be drawn only based on the height where branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.\n\nIt’s also possible to draw the dendrogram with a border around the selected clusters by using [*rect.hclust()*](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/rect.hclust.html) of R stats. The argument *border* is used to specify the border colors for the rectangles.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n```\n:::\n\n\n### Visually-driven hierarchical clustering analysis\n\nWith **heatmaply**, we are able to build both highly interactive cluster heatmap or static cluster heatmap.\n\n#### Transforming the data frame into a matrix\n\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_ict_mat <- data.matrix(shan_ict)\n```\n:::\n\n\n#### Plotting interactive cluster heatmap using *heatmaply()*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )\n```\n:::\n\n\n### Mapping the clusters formed\n\n[*cutree()*](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/cutree.html) of R Base will be used in the code chunk below to derive a 6-cluster model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngroups <- as.factor(cutree(hclust_ward, k=6))\n```\n:::\n\n\nThe output is called *groups*. It is a *list* object.\n\nIn order to visualise the clusters, the *groups* object need to be appended onto *shan_sf* simple feature object.\n\nThe code chunk below form the join in three steps:\n\n-   the *groups* list object will be converted into a matrix;\n\n-   *cbind()* is used to append *groups* matrix onto shan_sf to produce an output simple feature object called `shan_sf_cluster`; and\n\n-   *rename* of **dplyr** package is used to rename *as.matrix.groups* field as *CLUSTER*.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_sf_cluster <- cbind(shan_sf, as.matrix(groups)) %>%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nqtm(shan_sf_cluster, \"CLUSTER\")\n```\n:::\n\n\nThe choropleth map above reveals the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}